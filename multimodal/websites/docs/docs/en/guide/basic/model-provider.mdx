# Model Provider Configuration

Tarko Agent Server supports flexible multi-model configuration, allowing you to use different AI models within the same application and switch between them dynamically at runtime.

## Configuration Overview

The model configuration system supports two primary approaches:

1. **Agent-level configuration** via `AgentOptions.model` - supports single model configuration
2. **Server-level configuration** via `server.models` - supports multiple model configurations

These configurations are merged at runtime to provide a unified model selection interface.

## Configuration Scenarios

### Single Model Configuration

Configure a single model through `AgentOptions.model`:

```typescript
const agentOptions = {
  model: {
    id: "gpt-4",
    provider: "openai",
    displayName: "GPT-4"
  },
  workspace: "/path/to/workspace"
}
```

**Behavior:**
- UI displays static model information: `GPT-4 â€¢ openai`
- No model selector dropdown
- All sessions use the configured model

### Multiple Models Configuration

Configure multiple models through `server.models`:

```typescript
const serverOptions = {
  workspace: "/path/to/workspace",
  server: {
    models: [
      { id: "gpt-4", provider: "openai", displayName: "GPT-4" },
      { id: "claude-3-opus", provider: "anthropic", displayName: "Claude 3 Opus" },
      { id: "gemini-pro", provider: "google", displayName: "Gemini Pro" }
    ]
  }
}
```

**Behavior:**
- UI displays model selector dropdown
- Default selection: first model in `server.models`
- Users can switch between available models
- Each session remembers its selected model

### Hybrid Configuration (Recommended)

Combine both approaches for maximum flexibility:

```typescript
const config = {
  model: { 
    id: "gpt-3.5-turbo", 
    provider: "openai", 
    displayName: "GPT-3.5 Turbo" 
  },
  workspace: "/path/to/workspace",
  server: {
    models: [
      { id: "gpt-4", provider: "openai", displayName: "GPT-4" },
      { id: "claude-3-sonnet", provider: "anthropic", displayName: "Claude 3 Sonnet" }
    ]
  }
}
```

**Behavior:**
- Available models: `[gpt-3.5-turbo, gpt-4, claude-3-sonnet]` (merged and deduplicated)
- Default model: `gpt-3.5-turbo` (`AgentOptions.model` takes priority)
- UI displays selector with all available models



## API Reference

### Get Available Models

```http
GET /api/v1/models
```

**Response:**
```json
{
  "models": [
    {
      "provider": "openai",
      "models": ["gpt-4", "gpt-3.5-turbo"]
    },
    {
      "provider": "anthropic", 
      "models": ["claude-3-opus"]
    }
  ]
}
```

### Update Session Model

```http
POST /api/v1/sessions/model
Content-Type: application/json

{
  "sessionId": "session-123",
  "model": {
    "id": "claude-3-opus",
    "provider": "anthropic",
    "displayName": "Claude 3 Opus"
  }
}
```

**Response:**
```json
{
  "success": true,
  "sessionInfo": {
    "id": "session-123",
    "metadata": {
      "modelConfig": {
        "id": "claude-3-opus",
        "provider": "anthropic",
        "displayName": "Claude 3 Opus"
      }
    }
  }
}
```

## Best Practices

1. **Use hybrid configuration** for production deployments to provide both default and alternative models
2. **Validate model availability** before deploying configuration changes
3. **Monitor model usage** through session metadata to understand user preferences
4. **Handle fallbacks gracefully** when configured models become unavailable
5. **Cache model lists** on the frontend to reduce API calls during model switching