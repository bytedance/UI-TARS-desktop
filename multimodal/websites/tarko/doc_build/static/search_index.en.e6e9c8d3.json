[{"title":"Agent Server API","content":"#\n\nComplete API reference for the Tarko Agent Server.\n\n\nComing Soon#\n\nThis section is under development. Check back soon for detailed API\ndocumentation including:\n\n * Server constructor options\n * HTTP endpoints\n * WebSocket events\n * Configuration interfaces\n * Response schemas\n\nFor now, see Server Guide for usage examples.","routePath":"/api/agent-server","lang":"en","toc":[{"text":"Coming Soon","id":"coming-soon","depth":2,"charIndex":55}],"frontmatter":{"title":"Agent Server API","description":"Complete API reference for Tarko Agent Server"},"version":""},{"title":"Agent API","content":"#\n\n\nIntroduction#\n\n@tarko/agent is an event-stream driven meta agent framework for building\neffective multimodal Agents.\n\n\nWhen to use?#\n\nThis Agent SDK provides a low-level programmatic API, useful when you want to\nbuild an AI agent from scratch, e.g.\n\n * MCP Agent: Connect to mcp client\n * GUI Agent: Build a gui agent\n * Custom Agents: Build specialized agents for specific domains\n\n\nInstall#\n\nnpm install @tarko/agent\n\n\n\nFeatures#\n\n * Tool Integration: Effortlessly create and call tools within agent responses.\n * Event-stream driven: Standard Event Stream protocol driver to build Context\n   and UI more efficiently.\n * Native Streaming: Native streaming allows you to understand the Agent's\n   output in real time.\n * Multimodal analysis: Automatically analysis multimodal tool result allowing\n   you to focus more on building Agents.\n * Strong extension capabilities: Rich lifecycle design allows you to implement\n   more high-level Agents.\n * Multiple model providers: Supports multiple models, and supports advance\n   configuration and runtime selection.\n * Multiple tool call engines: The multiple tool call engine allows you to more\n   easily access tool calling capabilities\n\n\nQuick Start#\n\nCreate a index.ts:\n\n\n\nconst locationTool = new Tool({\n  id: 'getCurrentLocation',\n  description: \"Get user's current location\",\n  parameters: z.object({}),\n  function: async () => {\n    return { location: 'Boston' };\n  },\n});\n\nconst weatherTool = new Tool({\n  id: 'getWeather',\n  description: 'Get weather information for a specified location',\n  parameters: z.object({\n    location: z.string().describe('Location name, such as city name'),\n  }),\n  function: async (input) => {\n    const { location } = input;\n    return {\n      location,\n      temperature: '70Â°F (21Â°C)',\n      condition: 'Sunny',\n      precipitation: '10%',\n      humidity: '45%',\n      wind: '5 mph',\n    };\n  },\n});\n\nconst agent = new Agent({\n  tools: [locationTool, weatherTool],\n});\n\nasync function main() {\n  const response = await agent.run({\n    input: \"How's the weather today?\",\n  });\n  console.log(response);\n}\n\nmain();\n\n\nExecute it:\n\nnpx tsx index.ts\n\n\nOutput:\n\n{\n  \"id\": \"5c38c0a1-ccbe-48f0-8b97-ae78a4d9407e\",\n  \"type\": \"assistant_message\",\n  \"timestamp\": 1750188571248,\n  \"content\": \"The weather in Boston today is sunny with a temperature of 70Â°F (21Â°C). There's a 10% chance of precipitation, humidity is at 45%, and the wind is blowing at 5 mph.\",\n  \"finishReason\": \"stop\",\n  \"messageId\": \"msg_1750188570877_ics24k3x\"\n}\n\n\n\nAPI#\n\n\nAgent#\n\nDefine a Agent instance:\n\nconst agent = new Agent({\n  /* AgentOptions */\n});\n\n\nAgent Options#\n\n * tools: Array of tools available to the agent\n * systemPrompt: System prompt for the agent\n * modelProvider: Configuration for the LLM provider\n * stream: Enable streaming responses (default: false)\n * maxIterations: Maximum number of iterations (default: 10)\n\n\nTool#\n\nDefine a Tool instance:\n\n\n\nconst locationTool = new Tool({\n  id: 'getCurrentLocation',\n  description: \"Get user's current location\",\n  parameters: z.object({}),\n  function: async () => {\n    return { location: 'Boston' };\n  },\n});\n\n\nTool Options#\n\n * id: Unique identifier for the tool\n * description: Description of what the tool does\n * parameters: Zod schema for tool parameters\n * function: Async function that implements the tool logic\n\n\nGuide#\n\n\nStreaming Mode#\n\nIn above basic example, if you enable stream: true:\n\nasync function main() {\n  const stream = await agent.run({\n    input: \"How's the weather today?\",\n    stream: true,\n  });\n\n  for await (const chunk of stream) {\n    console.log(JSON.stringify(chunk));\n  }\n}\n\n\nYou will get streaming outputs with different event types:\n\n * assistant_message: Complete assistant messages\n * tool_call: Tool execution events\n * tool_result: Tool execution results\n * assistant_streaming_message: Streaming message chunks\n\n\nEvent Types#\n\nAssistantMessage#\n\ninterface AssistantMessage {\n  id: string;\n  type: 'assistant_message';\n  timestamp: number;\n  content: string;\n  toolCalls?: ToolCall[];\n  finishReason: 'stop' | 'tool_calls' | 'length';\n  messageId: string;\n}\n\n\nToolCall#\n\ninterface ToolCallEvent {\n  id: string;\n  type: 'tool_call';\n  timestamp: number;\n  toolCallId: string;\n  name: string;\n  arguments: any;\n  startTime: number;\n  tool: ToolDefinition;\n}\n\n\nToolResult#\n\ninterface ToolResult {\n  id: string;\n  type: 'tool_result';\n  timestamp: number;\n  toolCallId: string;\n  name: string;\n  content: any;\n  elapsedMs: number;\n}\n\n\nStreamingMessage#\n\ninterface StreamingMessage {\n  id: string;\n  type: 'assistant_streaming_message';\n  timestamp: number;\n  content: string;\n  isComplete: boolean;\n  messageId: string;\n}\n\n\n\nError Handling#\n\ntry {\n  const response = await agent.run({\n    input: \"How's the weather today?\",\n  });\n} catch (error) {\n  console.error('Agent execution failed:', error);\n}\n\n\n\nAdvanced Configuration#\n\nconst agent = new Agent({\n  tools: [weatherTool, locationTool],\n  systemPrompt: 'You are a helpful weather assistant.',\n  modelProvider: {\n    apiKey: process.env.OPENAI_API_KEY,\n    baseURL: 'https://api.openai.com/v1',\n    model: 'gpt-4',\n    temperature: 0.7,\n    maxTokens: 1000,\n  },\n  maxIterations: 5,\n  stream: true,\n});\n\n\nFor more advanced usage patterns, see the Agent Hooks documentation.","routePath":"/api/agent","lang":"en","toc":[{"text":"Introduction","id":"introduction","depth":2,"charIndex":3},{"text":"When to use?","id":"when-to-use","depth":2,"charIndex":122},{"text":"Install","id":"install","depth":2,"charIndex":387},{"text":"Features","id":"features","depth":2,"charIndex":425},{"text":"Quick Start","id":"quick-start","depth":2,"charIndex":1190},{"text":"API","id":"api","depth":2,"charIndex":2513},{"text":"Agent","id":"agent","depth":3,"charIndex":2520},{"text":"Agent Options","id":"agent-options","depth":4,"charIndex":2607},{"text":"Tool","id":"tool","depth":3,"charIndex":2887},{"text":"Tool Options","id":"tool-options","depth":4,"charIndex":3127},{"text":"Guide","id":"guide","depth":2,"charIndex":3337},{"text":"Streaming Mode","id":"streaming-mode","depth":3,"charIndex":3346},{"text":"Event Types","id":"event-types","depth":3,"charIndex":3869},{"text":"AssistantMessage","id":"assistantmessage","depth":4,"charIndex":3883},{"text":"ToolCall","id":"toolcall","depth":4,"charIndex":4115},{"text":"ToolResult","id":"toolresult","depth":4,"charIndex":4313},{"text":"StreamingMessage","id":"streamingmessage","depth":4,"charIndex":4486},{"text":"Error Handling","id":"error-handling","depth":3,"charIndex":4676},{"text":"Advanced Configuration","id":"advanced-configuration","depth":3,"charIndex":4855}],"frontmatter":{"title":"Agent API","description":"Complete API reference for @tarko/agent"},"version":""},{"title":"Context Engineering API","content":"#\n\nComplete API reference for Tarko Context Engineering.\n\n\nComing Soon#\n\nThis section is under development. Check back soon for detailed API\ndocumentation including:\n\n * Context Engineering configuration\n * Compression strategies\n * Windowing algorithms\n * Persistence options\n * Custom implementations\n\nFor now, see Context Engineering Guide for usage examples.","routePath":"/api/context-engineering","lang":"en","toc":[{"text":"Coming Soon","id":"coming-soon","depth":2,"charIndex":58}],"frontmatter":{"title":"Context Engineering API","description":"Complete API reference for Tarko Context Engineering"},"version":""},{"title":"Agent Hooks API","content":"#\n\n\nIntroduction#\n\nAgent Hooks provide a powerful way to extend and customize the behavior of your\nAgents throughout their execution lifecycle. The BaseAgent class exposes a\ncomprehensive set of hooks that allow you to intercept, modify, and react to\nvarious events during Agent execution.\n\n\nOverview#\n\nHOOK                        DESCRIPTION\ninitialize()                Called during Agent initialization\nonDispose()                 Called during Agent disposal\nonPrepareRequest()          Before preparing LLM request\nonLLMRequest()              Before sending request to LLM\nonLLMResponse()             After receiving response from LLM\nonLLMStreamingResponse()    For streaming responses from LLM\nonProcessToolCalls()        Intercept tool call processing\nonBeforeToolCall()          Before executing a tool\nonAfterToolCall()           After executing a tool\nonToolCallError()           When tool execution fails\nonEachAgentLoopStart()      Start of each Agent loop iteration\nonEachAgentLoopEnd()        End of each Agent loop iteration\nonBeforeLoopTermination()   Before Agent loop terminates\nonAgentLoopEnd()            When entire Agent loop completes\n\n\nHooks API#\n\n\ninitialize()#\n\nCalled during Agent initialization to perform setup operations.\n\nclass CustomAgent extends BaseAgent {\n  async initialize(): Promise<void> {\n    // Perform time-consuming setup operations\n    await this.connectToDatabase();\n    await this.loadConfiguration();\n    console.log('Agent initialized successfully');\n  }\n}\n\n\n\nonDispose()#\n\nCalled during Agent disposal to clean up resources.\n\nclass CustomAgent extends BaseAgent {\n  protected async onDispose(): Promise<void> {\n    // Clean up resources\n    await this.closeConnections();\n    this.clearTimers();\n    console.log('Agent disposed successfully');\n  }\n}\n\n\n\nonPrepareRequest()#\n\nCalled before preparing the LLM request, allowing dynamic modification of system\nprompt and tools.\n\nclass CustomAgent extends BaseAgent {\n  onPrepareRequest(context: PrepareRequestContext): PrepareRequestResult {\n    let { systemPrompt, tools } = context;\n    \n    // Modify system prompt based on context\n    if (context.iteration > 3) {\n      systemPrompt += '\\n\\nNote: You are in iteration ' + context.iteration + \n        '. Please focus on providing a concise final answer.';\n    }\n    \n    // Filter tools based on current state\n    const filteredTools = tools.filter(tool => {\n      // Disable expensive tools in later iterations\n      if (context.iteration > 5 && tool.name.includes('search')) {\n        return false;\n      }\n      return true;\n    });\n    \n    return {\n      systemPrompt,\n      tools: filteredTools,\n    };\n  }\n}\n\n\n\nonLLMRequest()#\n\nTriggered before sending a request to the LLM, allowing you to inspect or log\nthe request payload.\n\nclass CustomAgent extends BaseAgent {\n  async onLLMRequest(id: string, payload: LLMRequestHookPayload): Promise<void> {\n    console.log(`Sending request to LLM for session ${id}`);\n    console.log(`Model: ${payload.model}`);\n    console.log(`Messages: ${payload.messages.length}`);\n    \n    // Log token usage for monitoring\n    this.logTokenUsage(payload);\n  }\n}\n\n\n\nonLLMResponse()#\n\nTriggered after receiving a response from the LLM, allowing you to process the\nresponse.\n\nclass CustomAgent extends BaseAgent {\n  async onLLMResponse(id: string, payload: LLMResponseHookPayload): Promise<void> {\n    console.log(`Received response for session ${id}`);\n    \n    // Track response metrics\n    this.trackResponseTime(payload.elapsedMs);\n    this.trackTokenUsage(payload.usage);\n    \n    // Custom response processing\n    if (payload.response.choices[0]?.finish_reason === 'length') {\n      console.warn('Response truncated due to length limit');\n    }\n  }\n}\n\n\n\nonLLMStreamingResponse()#\n\nTriggered for streaming responses from the LLM.\n\nclass CustomAgent extends BaseAgent {\n  onLLMStreamingResponse(id: string, payload: LLMStreamingResponseHookPayload): void {\n    // Process streaming chunks\n    console.log(`Streaming chunk for session ${id}: ${payload.chunk}`);\n    \n    // Update UI or send real-time updates\n    this.updateStreamingUI(payload.chunk);\n  }\n}\n\n\n\nonProcessToolCalls()#\n\nIntercepts tool call processing, essential for testing and mocking.\n\nclass TestAgent extends BaseAgent {\n  onProcessToolCalls(\n    id: string,\n    toolCalls: ChatCompletionMessageToolCall[]\n  ): ToolCallResult[] | undefined {\n    // Mock tool calls for testing\n    if (this.isTestMode) {\n      return toolCalls.map(call => ({\n        toolCallId: call.id,\n        content: this.getMockResult(call.function.name),\n      }));\n    }\n    \n    // Return undefined for normal execution\n    return undefined;\n  }\n}\n\n\n\nonBeforeToolCall()#\n\nCalled before executing a tool, allowing you to modify arguments or add\nvalidation.\n\nclass CustomAgent extends BaseAgent {\n  async onBeforeToolCall(\n    id: string,\n    toolCall: { toolCallId: string; name: string },\n    args: any\n  ): Promise<any> {\n    console.log(`Executing tool: ${toolCall.name}`);\n    \n    // Add validation\n    if (toolCall.name === 'fileOperation' && !this.hasFilePermission()) {\n      throw new Error('Insufficient permissions for file operations');\n    }\n    \n    // Modify arguments\n    if (toolCall.name === 'searchWeb') {\n      args.maxResults = Math.min(args.maxResults || 10, 5);\n    }\n    \n    return args;\n  }\n}\n\n\n\nonAfterToolCall()#\n\nCalled after executing a tool, allowing you to modify results or add\npost-processing.\n\nclass CustomAgent extends BaseAgent {\n  async onAfterToolCall(\n    id: string,\n    toolCall: { toolCallId: string; name: string },\n    result: any\n  ): Promise<any> {\n    console.log(`Tool ${toolCall.name} completed`);\n    \n    // Post-process results\n    if (toolCall.name === 'imageAnalysis') {\n      result.confidence = this.calculateConfidence(result);\n    }\n    \n    // Log tool usage\n    this.logToolUsage(toolCall.name, result);\n    \n    return result;\n  }\n}\n\n\n\nonToolCallError()#\n\nCalled when a tool execution results in an error, allowing you to handle or\ntransform errors.\n\nclass CustomAgent extends BaseAgent {\n  async onToolCallError(\n    id: string,\n    toolCall: { toolCallId: string; name: string },\n    error: any\n  ): Promise<any> {\n    console.error(`Tool ${toolCall.name} failed:`, error);\n    \n    // Provide fallback responses\n    if (toolCall.name === 'weatherAPI') {\n      return 'Weather information is currently unavailable. Please try again later.';\n    }\n    \n    // Transform error messages\n    if (error.code === 'RATE_LIMIT') {\n      return 'Service is temporarily busy. Please wait a moment and try again.';\n    }\n    \n    return `Error: ${error.message || error}`;\n  }\n}\n\n\n\nonEachAgentLoopStart()#\n\nCalled at the beginning of each Agent loop iteration.\n\nclass CustomAgent extends BaseAgent {\n  async onEachAgentLoopStart(sessionId: string): Promise<void> {\n    console.log(`Starting loop iteration ${this.getCurrentLoopIteration()} for session ${sessionId}`);\n    \n    // Inject dynamic context\n    this.updateContextForIteration();\n    \n    // Check resource limits\n    if (this.getCurrentLoopIteration() > this.maxIterations * 0.8) {\n      console.warn('Approaching maximum iteration limit');\n    }\n  }\n}\n\n\n\nonEachAgentLoopEnd()#\n\nCalled at the end of each Agent loop iteration.\n\nclass CustomAgent extends BaseAgent {\n  async onEachAgentLoopEnd(context: EachAgentLoopEndContext): Promise<void> {\n    console.log(`Completed iteration ${context.iteration} for session ${context.sessionId}`);\n    \n    // Log iteration metrics\n    this.logIterationMetrics(context);\n    \n    // Check if we should continue\n    if (this.shouldTerminateEarly(context)) {\n      this.requestLoopTermination();\n    }\n  }\n}\n\n\n\nonBeforeLoopTermination()#\n\nCalled before the Agent loop terminates, allowing you to control termination\nconditions.\n\nclass CustomAgent extends BaseAgent {\n  onBeforeLoopTermination(\n    id: string,\n    finalEvent: AgentEventStream.AssistantMessageEvent\n  ): LoopTerminationCheckResult {\n    // Ensure specific tools were called\n    const requiredTools = ['validateResult', 'saveToDatabase'];\n    const calledTools = this.getCalledToolsInSession(id);\n    \n    const allRequiredToolsCalled = requiredTools.every(tool => \n      calledTools.includes(tool)\n    );\n    \n    if (!allRequiredToolsCalled) {\n      console.log('Required tools not called, continuing loop');\n      return { finished: false };\n    }\n    \n    // Check response quality\n    if (finalEvent.content.length < 50) {\n      console.log('Response too short, requesting more detail');\n      return { finished: false };\n    }\n    \n    return { finished: true };\n  }\n}\n\n\n\nonAgentLoopEnd()#\n\nCalled when the entire Agent loop completes.\n\nclass CustomAgent extends BaseAgent {\n  async onAgentLoopEnd(id: string): Promise<void> {\n    console.log(`Agent loop completed for session ${id}`);\n    \n    // Cleanup session resources\n    this.cleanupSession(id);\n    \n    // Send completion notifications\n    await this.notifyCompletion(id);\n  }\n}\n\n\n\nHook Execution Order#\n\nflowchart TD\n    A[Agent Start] --> B[initialize]\n    B --> C[Agent Loop Start]\n    C --> D[onEachAgentLoopStart]\n    D --> E[onPrepareRequest]\n    E --> F[onLLMRequest]\n    F --> G[LLM Call]\n    G --> H[onLLMResponse / onLLMStreamingResponse]\n    H --> I{Tools Called?}\n    I -->|Yes| J[onProcessToolCalls]\n    J --> K[onBeforeToolCall]\n    K --> L[Tool Execution]\n    L --> M{Tool Success?}\n    M -->|Yes| N[onAfterToolCall]\n    M -->|No| O[onToolCallError]\n    N --> P[onEachAgentLoopEnd]\n    O --> P\n    I -->|No| P\n    P --> Q{Continue Loop?}\n    Q -->|Yes| D\n    Q -->|No| R[onBeforeLoopTermination]\n    R --> S{Should Terminate?}\n    S -->|Yes| T[onAgentLoopEnd]\n    S -->|No| D\n    T --> U[Agent End]\n    U --> V[onDispose]\n    V --> W[Complete]\n\n\n\nType Definitions#\n\n\nPrepareRequestContext#\n\ninterface PrepareRequestContext {\n  systemPrompt: string;\n  tools: Tool[];\n  iteration: number;\n  sessionId: string;\n  messages: Message[];\n}\n\n\n\nPrepareRequestResult#\n\ninterface PrepareRequestResult {\n  systemPrompt: string;\n  tools: Tool[];\n}\n\n\n\nLLMRequestHookPayload#\n\ninterface LLMRequestHookPayload {\n  model: string;\n  messages: Message[];\n  tools?: Tool[];\n  temperature?: number;\n  maxTokens?: number;\n}\n\n\n\nLLMResponseHookPayload#\n\ninterface LLMResponseHookPayload {\n  response: ChatCompletion;\n  elapsedMs: number;\n  usage?: TokenUsage;\n}\n\n\n\nEachAgentLoopEndContext#\n\ninterface EachAgentLoopEndContext {\n  sessionId: string;\n  iteration: number;\n  elapsedMs: number;\n  lastMessage: Message;\n}\n\n\n\nLoopTerminationCheckResult#\n\ninterface LoopTerminationCheckResult {\n  finished: boolean;\n  reason?: string;\n}\n\n\nFor more information on using hooks in practice, see the Agent Hooks Guide.","routePath":"/api/hooks","lang":"en","toc":[{"text":"Introduction","id":"introduction","depth":2,"charIndex":3},{"text":"Overview","id":"overview","depth":2,"charIndex":291},{"text":"Hooks API","id":"hooks-api","depth":2,"charIndex":1160},{"text":"`initialize()`","id":"initialize","depth":3,"charIndex":-1},{"text":"`onDispose()`","id":"ondispose","depth":3,"charIndex":-1},{"text":"`onPrepareRequest()`","id":"onpreparerequest","depth":3,"charIndex":-1},{"text":"`onLLMRequest()`","id":"onllmrequest","depth":3,"charIndex":-1},{"text":"`onLLMResponse()`","id":"onllmresponse","depth":3,"charIndex":-1},{"text":"`onLLMStreamingResponse()`","id":"onllmstreamingresponse","depth":3,"charIndex":-1},{"text":"`onProcessToolCalls()`","id":"onprocesstoolcalls","depth":3,"charIndex":-1},{"text":"`onBeforeToolCall()`","id":"onbeforetoolcall","depth":3,"charIndex":-1},{"text":"`onAfterToolCall()`","id":"onaftertoolcall","depth":3,"charIndex":-1},{"text":"`onToolCallError()`","id":"ontoolcallerror","depth":3,"charIndex":-1},{"text":"`onEachAgentLoopStart()`","id":"oneachagentloopstart","depth":3,"charIndex":-1},{"text":"`onEachAgentLoopEnd()`","id":"oneachagentloopend","depth":3,"charIndex":-1},{"text":"`onBeforeLoopTermination()`","id":"onbeforelooptermination","depth":3,"charIndex":-1},{"text":"`onAgentLoopEnd()`","id":"onagentloopend","depth":3,"charIndex":-1},{"text":"Hook Execution Order","id":"hook-execution-order","depth":2,"charIndex":8993},{"text":"Type Definitions","id":"type-definitions","depth":2,"charIndex":9773},{"text":"PrepareRequestContext","id":"preparerequestcontext","depth":3,"charIndex":9793},{"text":"PrepareRequestResult","id":"preparerequestresult","depth":3,"charIndex":9962},{"text":"LLMRequestHookPayload","id":"llmrequesthookpayload","depth":3,"charIndex":10064},{"text":"LLMResponseHookPayload","id":"llmresponsehookpayload","depth":3,"charIndex":10231},{"text":"EachAgentLoopEndContext","id":"eachagentloopendcontext","depth":3,"charIndex":10367},{"text":"LoopTerminationCheckResult","id":"loopterminationcheckresult","depth":3,"charIndex":10521}],"frontmatter":{"title":"Agent Hooks API","description":"Complete API reference for Tarko Agent Hooks"},"version":""},{"title":"Tool Call Engine API","content":"#\n\nComplete API reference for the Tarko Tool Call Engine.\n\n\nComing Soon#\n\nThis section is under development. Check back soon for detailed API\ndocumentation including:\n\n * Tool Call Engine interfaces\n * Tool creation utilities\n * Parser configurations\n * Error handling types\n * Custom engine implementation\n\nFor now, see Tool Call Engine Guide for usage examples.","routePath":"/api/tool-call-engine","lang":"en","toc":[{"text":"Coming Soon","id":"coming-soon","depth":2,"charIndex":59}],"frontmatter":{"title":"Tool Call Engine API","description":"Complete API reference for Tarko Tool Call Engine"},"version":""},{"title":"Custom Hooks","content":"#\n\nLearn how to extend agent behavior with custom hooks.\n\n\nComing Soon#\n\nThis section is under development. Check back soon for detailed examples of:\n\n * Hook composition patterns\n * Plugin development\n * Monitoring and analytics hooks\n * Performance optimization hooks\n * Error handling and recovery hooks\n\nFor now, see Agent Hooks Guide for basic hook usage.","routePath":"/examples/custom-hooks","lang":"en","toc":[{"text":"Coming Soon","id":"coming-soon","depth":2,"charIndex":58}],"frontmatter":{"title":"Custom Hooks","description":"Extend agent behavior with custom hooks"},"version":""},{"title":"Custom Tools","content":"#\n\nLearn how to build advanced custom tools for your Tarko agents.\n\n\nComing Soon#\n\nThis section is under development. Check back soon for detailed examples of:\n\n * Advanced tool patterns\n * Tool composition\n * Streaming tools\n * Tool validation and error handling\n * Tool testing strategies\n\nFor now, see Getting Started Examples for basic tool creation.","routePath":"/examples/custom-tools","lang":"en","toc":[{"text":"Coming Soon","id":"coming-soon","depth":2,"charIndex":68}],"frontmatter":{"title":"Custom Tools","description":"Build advanced custom tools for your Tarko agents"},"version":""},{"title":"Getting Started Examples","content":"#\n\nThis page provides practical examples to help you get started with Tarko\nquickly.\n\n\nBasic Agent#\n\nCreate a simple agent with basic functionality:\n\n\n\n// Create a simple greeting tool\nconst greetingTool = createTool({\n  name: 'greet_user',\n  description: 'Greet a user with their name',\n  parameters: {\n    type: 'object',\n    properties: {\n      name: {\n        type: 'string',\n        description: 'The user\\'s name'\n      }\n    },\n    required: ['name']\n  },\n  handler: async ({ name }) => {\n    return `Hello, ${name}! Nice to meet you!`;\n  }\n});\n\n// Create the agent\nconst agent = new Agent({\n  name: 'GreetingBot',\n  description: 'A friendly greeting assistant',\n  systemPrompt: 'You are a friendly assistant that helps users with greetings.',\n  tools: [greetingTool],\n  modelProvider: {\n    apiKey: process.env.OPENAI_API_KEY,\n    baseURL: 'https://api.openai.com/v1',\n    model: 'gpt-4'\n  }\n});\n\nexport default agent;\n\n\n\nWeather Agent#\n\nBuild an agent that can fetch weather information:\n\n\n\n// Weather tool with real API integration\nconst weatherTool = createTool({\n  name: 'get_weather',\n  description: 'Get current weather information for a location',\n  parameters: {\n    type: 'object',\n    properties: {\n      location: {\n        type: 'string',\n        description: 'City name or coordinates (e.g., \"New York\" or \"40.7128,-74.0060\")'\n      },\n      units: {\n        type: 'string',\n        enum: ['metric', 'imperial'],\n        default: 'metric',\n        description: 'Temperature units'\n      }\n    },\n    required: ['location']\n  },\n  handler: async ({ location, units = 'metric' }) => {\n    const apiKey = process.env.OPENWEATHER_API_KEY;\n    if (!apiKey) {\n      throw new Error('OpenWeather API key not configured');\n    }\n\n    try {\n      const response = await fetch(\n        `https://api.openweathermap.org/data/2.5/weather?q=${encodeURIComponent(location)}&appid=${apiKey}&units=${units}`\n      );\n      \n      if (!response.ok) {\n        throw new Error(`Weather API error: ${response.statusText}`);\n      }\n      \n      const data = await response.json();\n      \n      const temperature = Math.round(data.main.temp);\n      const description = data.weather[0].description;\n      const humidity = data.main.humidity;\n      const windSpeed = data.wind.speed;\n      const unitSymbol = units === 'metric' ? 'Â°C' : 'Â°F';\n      const speedUnit = units === 'metric' ? 'm/s' : 'mph';\n      \n      return `Weather in ${data.name}, ${data.sys.country}:\nðŸŒ¡ï¸ Temperature: ${temperature}${unitSymbol}\nðŸŒ¤ï¸ Condition: ${description}\nðŸ’§ Humidity: ${humidity}%\nðŸ’¨ Wind Speed: ${windSpeed} ${speedUnit}`;\n    } catch (error) {\n      return `Sorry, I couldn't fetch weather data for \"${location}\". Please check the location name and try again.`;\n    }\n  }\n});\n\nconst weatherAgent = new Agent({\n  name: 'WeatherBot',\n  description: 'A helpful weather assistant',\n  systemPrompt: `You are a weather assistant that provides current weather information for any location.\nUse the get_weather tool to fetch real-time weather data when users ask about weather conditions.\nAlways be helpful and provide clear, formatted weather information.`,\n  tools: [weatherTool],\n  modelProvider: {\n    apiKey: process.env.OPENAI_API_KEY,\n    baseURL: 'https://api.openai.com/v1',\n    model: 'gpt-4'\n  }\n});\n\nexport default weatherAgent;\n\n\n\nCalculator Agent#\n\nCreate an agent with mathematical capabilities:\n\n\n\n// Safe math evaluation tool\nconst calculatorTool = createTool({\n  name: 'calculate',\n  description: 'Perform mathematical calculations safely',\n  parameters: {\n    type: 'object',\n    properties: {\n      expression: {\n        type: 'string',\n        description: 'Mathematical expression (e.g., \"2 + 3 * 4\", \"sqrt(16)\", \"sin(pi/2)\")'\n      }\n    },\n    required: ['expression']\n  },\n  validate: ({ expression }) => {\n    // Basic validation for safety\n    const allowedPattern = /^[0-9+\\-*/().\\s,sqrt,sin,cos,tan,log,ln,pi,e]+$/i;\n    if (!allowedPattern.test(expression)) {\n      throw new Error('Expression contains invalid characters. Only numbers, basic operators, and common math functions are allowed.');\n    }\n    return true;\n  },\n  handler: async ({ expression }) => {\n    try {\n      // Replace common math functions and constants\n      let safeExpression = expression\n        .replace(/pi/gi, 'Math.PI')\n        .replace(/e(?![0-9])/gi, 'Math.E')\n        .replace(/sqrt\\(/gi, 'Math.sqrt(')\n        .replace(/sin\\(/gi, 'Math.sin(')\n        .replace(/cos\\(/gi, 'Math.cos(')\n        .replace(/tan\\(/gi, 'Math.tan(')\n        .replace(/log\\(/gi, 'Math.log10(')\n        .replace(/ln\\(/gi, 'Math.log(');\n      \n      // Use Function constructor for safer evaluation\n      const result = new Function('return ' + safeExpression)();\n      \n      if (typeof result !== 'number' || !isFinite(result)) {\n        throw new Error('Invalid calculation result');\n      }\n      \n      return `${expression} = ${result}`;\n    } catch (error) {\n      return `Error calculating \"${expression}\": ${error.message}`;\n    }\n  }\n});\n\n// Unit conversion tool\nconst unitConverterTool = createTool({\n  name: 'convert_units',\n  description: 'Convert between different units of measurement',\n  parameters: {\n    type: 'object',\n    properties: {\n      value: {\n        type: 'number',\n        description: 'The numeric value to convert'\n      },\n      fromUnit: {\n        type: 'string',\n        description: 'Source unit (e.g., \"celsius\", \"fahrenheit\", \"meters\", \"feet\", \"kg\", \"lbs\")'\n      },\n      toUnit: {\n        type: 'string',\n        description: 'Target unit'\n      }\n    },\n    required: ['value', 'fromUnit', 'toUnit']\n  },\n  handler: async ({ value, fromUnit, toUnit }) => {\n    const conversions: Record<string, Record<string, (v: number) => number>> = {\n      // Temperature\n      celsius: {\n        fahrenheit: (c) => (c * 9/5) + 32,\n        kelvin: (c) => c + 273.15\n      },\n      fahrenheit: {\n        celsius: (f) => (f - 32) * 5/9,\n        kelvin: (f) => ((f - 32) * 5/9) + 273.15\n      },\n      kelvin: {\n        celsius: (k) => k - 273.15,\n        fahrenheit: (k) => ((k - 273.15) * 9/5) + 32\n      },\n      // Length\n      meters: {\n        feet: (m) => m * 3.28084,\n        inches: (m) => m * 39.3701,\n        kilometers: (m) => m / 1000\n      },\n      feet: {\n        meters: (ft) => ft / 3.28084,\n        inches: (ft) => ft * 12,\n        kilometers: (ft) => ft / 3280.84\n      },\n      // Weight\n      kg: {\n        lbs: (kg) => kg * 2.20462,\n        grams: (kg) => kg * 1000\n      },\n      lbs: {\n        kg: (lbs) => lbs / 2.20462,\n        grams: (lbs) => (lbs / 2.20462) * 1000\n      }\n    };\n    \n    const fromKey = fromUnit.toLowerCase();\n    const toKey = toUnit.toLowerCase();\n    \n    if (!conversions[fromKey] || !conversions[fromKey][toKey]) {\n      return `Conversion from ${fromUnit} to ${toUnit} is not supported. Available conversions: temperature (celsius, fahrenheit, kelvin), length (meters, feet, inches, kilometers), weight (kg, lbs, grams).`;\n    }\n    \n    const result = conversions[fromKey][toKey](value);\n    return `${value} ${fromUnit} = ${result.toFixed(4)} ${toUnit}`;\n  }\n});\n\nconst calculatorAgent = new Agent({\n  name: 'MathBot',\n  description: 'A mathematical assistant for calculations and unit conversions',\n  systemPrompt: `You are a helpful mathematical assistant that can:\n1. Perform calculations using the calculate tool\n2. Convert between different units using the convert_units tool\n\nAlways use the appropriate tool for mathematical operations and unit conversions.\nProvide clear explanations of your calculations when helpful.`,\n  tools: [calculatorTool, unitConverterTool],\n  modelProvider: {\n    apiKey: process.env.OPENAI_API_KEY,\n    baseURL: 'https://api.openai.com/v1',\n    model: 'gpt-4'\n  }\n});\n\nexport default calculatorAgent;\n\n\n\nFile System Agent#\n\nBuild an agent that can interact with the file system:\n\n\n\n\n\n// File reading tool\nconst readFileTool = createTool({\n  name: 'read_file',\n  description: 'Read the contents of a text file',\n  parameters: {\n    type: 'object',\n    properties: {\n      filePath: {\n        type: 'string',\n        description: 'Path to the file to read'\n      }\n    },\n    required: ['filePath']\n  },\n  handler: async ({ filePath }) => {\n    try {\n      // Basic security check - prevent directory traversal\n      const resolvedPath = path.resolve(filePath);\n      const workingDir = process.cwd();\n      \n      if (!resolvedPath.startsWith(workingDir)) {\n        throw new Error('Access denied: File is outside working directory');\n      }\n      \n      const content = await fs.readFile(resolvedPath, 'utf-8');\n      return `File content of ${filePath}:\\n\\n${content}`;\n    } catch (error) {\n      return `Error reading file ${filePath}: ${error.message}`;\n    }\n  }\n});\n\n// Directory listing tool\nconst listDirectoryTool = createTool({\n  name: 'list_directory',\n  description: 'List files and directories in a given path',\n  parameters: {\n    type: 'object',\n    properties: {\n      dirPath: {\n        type: 'string',\n        description: 'Path to the directory to list',\n        default: '.'\n      }\n    }\n  },\n  handler: async ({ dirPath = '.' }) => {\n    try {\n      const resolvedPath = path.resolve(dirPath);\n      const workingDir = process.cwd();\n      \n      if (!resolvedPath.startsWith(workingDir)) {\n        throw new Error('Access denied: Directory is outside working directory');\n      }\n      \n      const items = await fs.readdir(resolvedPath, { withFileTypes: true });\n      \n      const files = items.filter(item => item.isFile()).map(item => item.name);\n      const dirs = items.filter(item => item.isDirectory()).map(item => item.name);\n      \n      let result = `Contents of ${dirPath}:\\n\\n`;\n      \n      if (dirs.length > 0) {\n        result += `ðŸ“ Directories (${dirs.length}):\\n${dirs.map(d => `  ${d}/`).join('\\n')}\\n\\n`;\n      }\n      \n      if (files.length > 0) {\n        result += `ðŸ“„ Files (${files.length}):\\n${files.map(f => `  ${f}`).join('\\n')}`;\n      }\n      \n      if (dirs.length === 0 && files.length === 0) {\n        result += 'Directory is empty.';\n      }\n      \n      return result;\n    } catch (error) {\n      return `Error listing directory ${dirPath}: ${error.message}`;\n    }\n  }\n});\n\n// File writing tool\nconst writeFileTool = createTool({\n  name: 'write_file',\n  description: 'Write content to a file',\n  parameters: {\n    type: 'object',\n    properties: {\n      filePath: {\n        type: 'string',\n        description: 'Path where to write the file'\n      },\n      content: {\n        type: 'string',\n        description: 'Content to write to the file'\n      }\n    },\n    required: ['filePath', 'content']\n  },\n  handler: async ({ filePath, content }) => {\n    try {\n      const resolvedPath = path.resolve(filePath);\n      const workingDir = process.cwd();\n      \n      if (!resolvedPath.startsWith(workingDir)) {\n        throw new Error('Access denied: File is outside working directory');\n      }\n      \n      // Ensure directory exists\n      const dir = path.dirname(resolvedPath);\n      await fs.mkdir(dir, { recursive: true });\n      \n      await fs.writeFile(resolvedPath, content, 'utf-8');\n      return `Successfully wrote ${content.length} characters to ${filePath}`;\n    } catch (error) {\n      return `Error writing file ${filePath}: ${error.message}`;\n    }\n  }\n});\n\nconst fileSystemAgent = new Agent({\n  name: 'FileBot',\n  description: 'A file system assistant for reading, writing, and managing files',\n  systemPrompt: `You are a helpful file system assistant that can:\n1. Read file contents using read_file\n2. List directory contents using list_directory\n3. Write files using write_file\n\nAlways be careful with file operations and provide clear feedback about what you're doing.\nFor security, you can only access files within the current working directory.`,\n  tools: [readFileTool, listDirectoryTool, writeFileTool],\n  modelProvider: {\n    apiKey: process.env.OPENAI_API_KEY,\n    baseURL: 'https://api.openai.com/v1',\n    model: 'gpt-4'\n  }\n});\n\nexport default fileSystemAgent;\n\n\n\nRunning the Examples#\n\n\nEnvironment Setup#\n\nCreate a .env file with your API keys:\n\n# .env file\n# OpenAI API Key (required for all examples)\nOPENAI_API_KEY=your_openai_api_key_here\n\n# OpenWeather API Key (required for weather agent)\nOPENWEATHER_API_KEY=your_openweather_api_key_here\n\n# Optional: Use different model provider\n# MODEL_PROVIDER=anthropic\n# ANTHROPIC_API_KEY=your_anthropic_key_here\n\n\n\nUsing with CLI#\n\nSave any of the examples as a .ts file and run:\n\n# Run the weather agent\nnpx tarko run weather-agent.ts\n\n# Run with custom port\nnpx tarko run calculator-agent.ts --port 3001\n\n# Run in development mode with hot reload\nnpx tarko dev file-system-agent.ts\n\n\n\nProgrammatic Usage#\n\n\n\nasync function main() {\n  // Start a conversation\n  const response = await weatherAgent.query('What\\'s the weather like in Tokyo?');\n  console.log(response);\n  \n  // Continue the conversation\n  const followUp = await weatherAgent.query('How about in London?');\n  console.log(followUp);\n}\n\nmain().catch(console.error);\n\n\n\nTesting Examples#\n\n\n\n\ndescribe('Calculator Agent', () => {\n  it('should perform basic calculations', async () => {\n    const response = await calculatorAgent.query('What is 15 * 7?');\n    expect(response).toContain('105');\n  });\n  \n  it('should convert units', async () => {\n    const response = await calculatorAgent.query('Convert 100 fahrenheit to celsius');\n    expect(response).toContain('37.7778');\n  });\n});\n\n\n\nNext Steps#\n\n * Custom Tools - Learn to build more advanced tools\n * Server Integration - Deploy agents as servers\n * Custom Hooks - Add custom behavior with hooks\n\n\nCommon Issues#\n\n\nAPI Key Not Found#\n\nMake sure your .env file is in the project root and contains the required API\nkeys.\n\n\nFile Access Denied#\n\nThe file system agent only allows access to files within the current working\ndirectory for security reasons.\n\n\nTool Call Failures#\n\nCheck your internet connection and API key validity. Tools will provide error\nmessages to help debug issues.","routePath":"/examples/getting-started","lang":"en","toc":[{"text":"Basic Agent","id":"basic-agent","depth":2,"charIndex":86},{"text":"Weather Agent","id":"weather-agent","depth":2,"charIndex":929},{"text":"Calculator Agent","id":"calculator-agent","depth":2,"charIndex":3324},{"text":"File System Agent","id":"file-system-agent","depth":2,"charIndex":7784},{"text":"Running the Examples","id":"running-the-examples","depth":2,"charIndex":12030},{"text":"Environment Setup","id":"environment-setup","depth":3,"charIndex":12054},{"text":"Using with CLI","id":"using-with-cli","depth":3,"charIndex":12429},{"text":"Programmatic Usage","id":"programmatic-usage","depth":3,"charIndex":12701},{"text":"Testing Examples","id":"testing-examples","depth":3,"charIndex":13045},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":13463},{"text":"Common Issues","id":"common-issues","depth":2,"charIndex":13629},{"text":"API Key Not Found","id":"api-key-not-found","depth":3,"charIndex":13646},{"text":"File Access Denied","id":"file-access-denied","depth":3,"charIndex":13752},{"text":"Tool Call Failures","id":"tool-call-failures","depth":3,"charIndex":13884}],"frontmatter":{"title":"Getting Started Examples","description":"Practical examples to get started with Tarko"},"version":""},{"title":"Protocol Integration","content":"#\n\nLearn how to integrate with Tarko's Agent Protocol.\n\n\nComing Soon#\n\nThis section is under development. Check back soon for detailed examples of:\n\n * Event stream integration\n * Custom UI development\n * Protocol extensions\n * Real-time communication\n * Third-party integrations\n\nFor now, see Agent Protocol Guide for basic protocol usage.","routePath":"/examples/protocol-integration","lang":"en","toc":[{"text":"Coming Soon","id":"coming-soon","depth":2,"charIndex":56}],"frontmatter":{"title":"Protocol Integration","description":"Integrate with Tarko's Agent Protocol"},"version":""},{"title":"Server Integration","content":"#\n\nLearn how to deploy Tarko agents as production servers.\n\n\nComing Soon#\n\nThis section is under development. Check back soon for detailed examples of:\n\n * Production server deployment\n * Docker containerization\n * Load balancing and scaling\n * Monitoring and logging\n * Authentication and security\n\nFor now, see Server Guide for basic server usage.","routePath":"/examples/server-integration","lang":"en","toc":[{"text":"Coming Soon","id":"coming-soon","depth":2,"charIndex":60}],"frontmatter":{"title":"Server Integration","description":"Deploy Tarko agents as production servers"},"version":""},{"title":"Agent Hooks","content":"#\n\nTarko's Agent Hooks system provides powerful extension points throughout the\nagent lifecycle, allowing you to customize behavior, add monitoring, implement\ncustom logic, and integrate with external systems.\n\n\nOverview#\n\nAgent Hooks are callback functions that execute at specific points during agent\noperation:\n\n * Lifecycle Hooks: Agent startup, shutdown, session management\n * Message Hooks: Before/after message processing\n * Tool Hooks: Tool call execution and result processing\n * Context Hooks: Context engineering operations\n * Error Hooks: Error handling and recovery\n\n\nBasic Hook Usage#\n\n\nDefining Hooks#\n\n\n\nconst agent = new Agent({\n  hooks: {\n    // Lifecycle hooks\n    onStart: async (agent) => {\n      console.log('Agent started:', agent.name);\n    },\n    \n    onStop: async (agent) => {\n      console.log('Agent stopped:', agent.name);\n    },\n    \n    // Message hooks\n    beforeMessage: async (message, context) => {\n      console.log('Processing message:', message.content);\n      return message; // Return modified message or original\n    },\n    \n    afterMessage: async (message, response, context) => {\n      console.log('Message processed. Response length:', response.length);\n    },\n    \n    // Tool hooks\n    beforeToolCall: async (toolCall, context) => {\n      console.log('Calling tool:', toolCall.function.name);\n      return toolCall; // Can modify tool call\n    },\n    \n    afterToolCall: async (toolCall, result, context) => {\n      console.log('Tool completed:', toolCall.function.name, 'Success:', result.success);\n    }\n  }\n});\n\n\n\nHook Context#\n\nAll hooks receive a context object with useful information:\n\ninterface HookContext {\n  agent: Agent;\n  sessionId: string;\n  messages: Message[];\n  agentState: any;\n  user?: UserInfo;\n  metadata: Record<string, any>;\n  \n  // Utility methods\n  emit: (event: AgentEvent) => void;\n  getState: (key: string) => any;\n  setState: (key: string, value: any) => void;\n  callTool: (name: string, args: any) => Promise<any>;\n}\n\n\n\nLifecycle Hooks#\n\n\nAgent Lifecycle#\n\nconst agent = new Agent({\n  hooks: {\n    // Called when agent starts\n    onStart: async (agent) => {\n      console.log(`Agent ${agent.name} starting...`);\n      \n      // Initialize external services\n      await initializeDatabase();\n      await connectToMetrics();\n      \n      // Set initial state\n      agent.setState('startTime', Date.now());\n    },\n    \n    // Called when agent stops\n    onStop: async (agent) => {\n      const startTime = agent.getState('startTime');\n      const uptime = Date.now() - startTime;\n      \n      console.log(`Agent ${agent.name} stopping. Uptime: ${uptime}ms`);\n      \n      // Cleanup resources\n      await closeDatabase();\n      await disconnectFromMetrics();\n    },\n    \n    // Called on agent errors\n    onError: async (error, context) => {\n      console.error('Agent error:', error.message);\n      \n      // Send error to monitoring service\n      await sendErrorToMonitoring(error, context);\n      \n      // Attempt recovery\n      if (error.recoverable) {\n        await attemptRecovery(error, context);\n      }\n    }\n  }\n});\n\n\n\nSession Lifecycle#\n\nconst agent = new Agent({\n  hooks: {\n    // Called when new session starts\n    onSessionStart: async (sessionId, context) => {\n      console.log('New session started:', sessionId);\n      \n      // Initialize session-specific data\n      context.setState('sessionStartTime', Date.now());\n      context.setState('messageCount', 0);\n      \n      // Load user preferences\n      const user = await loadUserPreferences(context.user?.id);\n      context.setState('userPreferences', user);\n    },\n    \n    // Called when session ends\n    onSessionEnd: async (sessionId, context) => {\n      const startTime = context.getState('sessionStartTime');\n      const messageCount = context.getState('messageCount');\n      const duration = Date.now() - startTime;\n      \n      console.log(`Session ${sessionId} ended. Duration: ${duration}ms, Messages: ${messageCount}`);\n      \n      // Save session analytics\n      await saveSessionAnalytics({\n        sessionId,\n        duration,\n        messageCount,\n        userId: context.user?.id\n      });\n    }\n  }\n});\n\n\n\nMessage Processing Hooks#\n\n\nMessage Transformation#\n\nconst agent = new Agent({\n  hooks: {\n    // Preprocess user messages\n    beforeMessage: async (message, context) => {\n      // Add timestamp\n      message.timestamp = Date.now();\n      \n      // Content filtering\n      if (containsInappropriateContent(message.content)) {\n        throw new Error('Message contains inappropriate content');\n      }\n      \n      // Language detection\n      const language = detectLanguage(message.content);\n      message.metadata = { ...message.metadata, language };\n      \n      // Increment message counter\n      const count = context.getState('messageCount') || 0;\n      context.setState('messageCount', count + 1);\n      \n      return message;\n    },\n    \n    // Process assistant responses\n    afterMessage: async (userMessage, assistantResponse, context) => {\n      // Log conversation\n      await logConversation({\n        sessionId: context.sessionId,\n        userMessage: userMessage.content,\n        assistantResponse,\n        timestamp: Date.now()\n      });\n      \n      // Update user engagement metrics\n      await updateEngagementMetrics(context.user?.id, {\n        messageLength: userMessage.content.length,\n        responseLength: assistantResponse.length,\n        responseTime: Date.now() - userMessage.timestamp\n      });\n    },\n    \n    // Handle streaming responses\n    onMessageDelta: async (delta, accumulated, context) => {\n      // Real-time content filtering\n      if (containsInappropriateContent(accumulated)) {\n        context.emit({\n          type: 'content_filter_triggered',\n          data: { reason: 'inappropriate_content' }\n        });\n        \n        // Stop streaming\n        return { stop: true };\n      }\n      \n      // Real-time translation for international users\n      if (context.user?.language !== 'en') {\n        const translatedDelta = await translateText(delta, context.user.language);\n        return { delta: translatedDelta };\n      }\n      \n      return { delta };\n    }\n  }\n});\n\n\n\nTool Execution Hooks#\n\n\nTool Call Monitoring#\n\nconst agent = new Agent({\n  hooks: {\n    // Before tool execution\n    beforeToolCall: async (toolCall, context) => {\n      const startTime = Date.now();\n      \n      // Log tool usage\n      console.log(`Executing tool: ${toolCall.function.name}`);\n      console.log('Arguments:', toolCall.function.arguments);\n      \n      // Check permissions\n      if (!hasToolPermission(context.user, toolCall.function.name)) {\n        throw new Error(`User does not have permission to use ${toolCall.function.name}`);\n      }\n      \n      // Rate limiting\n      const toolUsage = context.getState(`tool_usage_${toolCall.function.name}`) || [];\n      const recentUsage = toolUsage.filter(time => Date.now() - time < 60000); // Last minute\n      \n      if (recentUsage.length >= 10) {\n        throw new Error(`Rate limit exceeded for ${toolCall.function.name}`);\n      }\n      \n      // Update usage tracking\n      recentUsage.push(startTime);\n      context.setState(`tool_usage_${toolCall.function.name}`, recentUsage);\n      context.setState(`tool_start_${toolCall.id}`, startTime);\n      \n      // Emit monitoring event\n      context.emit({\n        type: 'tool_execution_start',\n        data: {\n          toolName: toolCall.function.name,\n          arguments: toolCall.function.arguments,\n          startTime\n        }\n      });\n      \n      return toolCall;\n    },\n    \n    // After tool execution\n    afterToolCall: async (toolCall, result, context) => {\n      const startTime = context.getState(`tool_start_${toolCall.id}`);\n      const duration = Date.now() - startTime;\n      \n      // Log execution results\n      console.log(`Tool ${toolCall.function.name} completed in ${duration}ms`);\n      console.log('Success:', result.success);\n      \n      // Record metrics\n      await recordToolMetrics({\n        toolName: toolCall.function.name,\n        duration,\n        success: result.success,\n        userId: context.user?.id,\n        sessionId: context.sessionId\n      });\n      \n      // Handle errors\n      if (!result.success) {\n        await handleToolError({\n          toolName: toolCall.function.name,\n          error: result.error,\n          arguments: toolCall.function.arguments,\n          context\n        });\n      }\n      \n      // Emit completion event\n      context.emit({\n        type: 'tool_execution_complete',\n        data: {\n          toolName: toolCall.function.name,\n          duration,\n          success: result.success,\n          resultLength: result.content?.length || 0\n        }\n      });\n    },\n    \n    // Handle tool errors\n    onToolError: async (error, toolCall, context) => {\n      console.error(`Tool ${toolCall.function.name} failed:`, error.message);\n      \n      // Attempt automatic retry for transient errors\n      if (isTransientError(error) && !toolCall.retryAttempt) {\n        console.log('Retrying tool call...');\n        \n        // Mark as retry attempt\n        toolCall.retryAttempt = true;\n        \n        // Retry after delay\n        await new Promise(resolve => setTimeout(resolve, 1000));\n        return { retry: true };\n      }\n      \n      // Log persistent failures\n      await logToolFailure({\n        toolName: toolCall.function.name,\n        error: error.message,\n        arguments: toolCall.function.arguments,\n        sessionId: context.sessionId\n      });\n      \n      return { retry: false };\n    }\n  }\n});\n\n\n\nContext Engineering Hooks#\n\n\nContext Management#\n\nconst agent = new Agent({\n  hooks: {\n    // Before context compression\n    beforeContextCompression: async (context, messages) => {\n      console.log(`Compressing context: ${messages.length} messages`);\n      \n      // Save full context before compression\n      await saveContextSnapshot({\n        sessionId: context.sessionId,\n        messages,\n        timestamp: Date.now()\n      });\n      \n      // Custom importance scoring\n      return messages.map(message => ({\n        ...message,\n        importance: calculateImportanceScore(message, context)\n      }));\n    },\n    \n    // After context compression\n    afterContextCompression: async (originalMessages, compressedMessages, context) => {\n      const compressionRatio = compressedMessages.length / originalMessages.length;\n      \n      console.log(`Context compressed: ${originalMessages.length} â†’ ${compressedMessages.length} (${(compressionRatio * 100).toFixed(1)}%)`);\n      \n      // Log compression metrics\n      await logCompressionMetrics({\n        sessionId: context.sessionId,\n        originalLength: originalMessages.length,\n        compressedLength: compressedMessages.length,\n        compressionRatio,\n        timestamp: Date.now()\n      });\n      \n      // Alert if compression ratio is too aggressive\n      if (compressionRatio < 0.3) {\n        console.warn('High compression ratio detected. Consider adjusting compression settings.');\n      }\n    },\n    \n    // Context limit reached\n    onContextLimitReached: async (context, messages) => {\n      console.warn('Context limit reached. Initiating emergency compression.');\n      \n      // Emergency context preservation\n      const criticalMessages = messages.filter(msg => \n        msg.role === 'system' || \n        msg.metadata?.critical === true\n      );\n      \n      await saveEmergencyContext({\n        sessionId: context.sessionId,\n        criticalMessages,\n        allMessages: messages,\n        timestamp: Date.now()\n      });\n      \n      // Emit alert\n      context.emit({\n        type: 'context_limit_alert',\n        data: {\n          messageCount: messages.length,\n          criticalMessageCount: criticalMessages.length\n        }\n      });\n    }\n  }\n});\n\n\n\nCustom Hook Implementation#\n\n\nPlugin System#\n\n// Define a plugin interface\ninterface AgentPlugin {\n  name: string;\n  version: string;\n  hooks: Partial<AgentHooks>;\n  install?: (agent: Agent) => Promise<void>;\n  uninstall?: (agent: Agent) => Promise<void>;\n}\n\n// Analytics plugin\nconst analyticsPlugin: AgentPlugin = {\n  name: 'analytics',\n  version: '1.0.0',\n  hooks: {\n    onSessionStart: async (sessionId, context) => {\n      await analytics.track('session_started', {\n        sessionId,\n        userId: context.user?.id,\n        timestamp: Date.now()\n      });\n    },\n    \n    afterMessage: async (userMessage, response, context) => {\n      await analytics.track('message_processed', {\n        sessionId: context.sessionId,\n        messageLength: userMessage.content.length,\n        responseLength: response.length,\n        timestamp: Date.now()\n      });\n    },\n    \n    afterToolCall: async (toolCall, result, context) => {\n      await analytics.track('tool_used', {\n        toolName: toolCall.function.name,\n        success: result.success,\n        sessionId: context.sessionId,\n        timestamp: Date.now()\n      });\n    }\n  },\n  \n  install: async (agent) => {\n    console.log('Analytics plugin installed');\n    await analytics.initialize(agent.config.analytics);\n  },\n  \n  uninstall: async (agent) => {\n    console.log('Analytics plugin uninstalled');\n    await analytics.cleanup();\n  }\n};\n\n// Use plugin\nconst agent = new Agent({\n  plugins: [analyticsPlugin]\n});\n\n\n\nConditional Hooks#\n\nconst agent = new Agent({\n  hooks: {\n    // Development-only hooks\n    ...(process.env.NODE_ENV === 'development' && {\n      beforeMessage: async (message, context) => {\n        console.log('ðŸ” Debug - Processing message:', message.content);\n        return message;\n      },\n      \n      afterToolCall: async (toolCall, result, context) => {\n        console.log('ðŸ”§ Debug - Tool result:', {\n          tool: toolCall.function.name,\n          success: result.success,\n          resultLength: result.content?.length\n        });\n      }\n    }),\n    \n    // Production-only hooks\n    ...(process.env.NODE_ENV === 'production' && {\n      onError: async (error, context) => {\n        await sendErrorToSentry(error, {\n          sessionId: context.sessionId,\n          userId: context.user?.id,\n          agentName: context.agent.name\n        });\n      }\n    }),\n    \n    // User-specific hooks\n    beforeMessage: async (message, context) => {\n      // Premium user features\n      if (context.user?.tier === 'premium') {\n        message.metadata = {\n          ...message.metadata,\n          priority: 'high',\n          features: ['advanced_tools', 'priority_processing']\n        };\n      }\n      \n      return message;\n    }\n  }\n});\n\n\n\nAdvanced Hook Patterns#\n\n\nHook Composition#\n\n// Compose multiple hooks\nfunction composeHooks<T extends (...args: any[]) => any>(\n  ...hooks: T[]\n): T {\n  return ((...args: Parameters<T>) => {\n    return hooks.reduce(async (prev, hook) => {\n      await prev;\n      return hook(...args);\n    }, Promise.resolve());\n  }) as T;\n}\n\nconst loggingHook = async (message: Message, context: HookContext) => {\n  console.log('Logging:', message.content);\n};\n\nconst analyticsHook = async (message: Message, context: HookContext) => {\n  await analytics.track('message', { length: message.content.length });\n};\n\nconst validationHook = async (message: Message, context: HookContext) => {\n  if (!message.content.trim()) {\n    throw new Error('Empty message not allowed');\n  }\n};\n\nconst agent = new Agent({\n  hooks: {\n    beforeMessage: composeHooks(validationHook, loggingHook, analyticsHook)\n  }\n});\n\n\n\nAsync Hook Patterns#\n\nconst agent = new Agent({\n  hooks: {\n    // Parallel execution\n    afterMessage: async (userMessage, response, context) => {\n      await Promise.all([\n        logToDatabase(userMessage, response, context),\n        sendToAnalytics(userMessage, response, context),\n        updateUserProfile(context.user, response),\n        generateSummary(context.sessionId, response)\n      ]);\n    },\n    \n    // Sequential with error handling\n    beforeToolCall: async (toolCall, context) => {\n      try {\n        // Step 1: Validate permissions\n        await validatePermissions(toolCall, context.user);\n        \n        // Step 2: Check rate limits\n        await checkRateLimit(toolCall.function.name, context.user);\n        \n        // Step 3: Log usage\n        await logToolUsage(toolCall, context);\n        \n        return toolCall;\n      } catch (error) {\n        // Handle validation errors\n        context.emit({\n          type: 'tool_validation_failed',\n          data: { error: error.message, toolName: toolCall.function.name }\n        });\n        throw error;\n      }\n    }\n  }\n});\n\n\n\nTesting Hooks#\n\n\nUnit Testing#\n\n\n\ndescribe('Agent Hooks', () => {\n  let agent: Agent;\n  let mockContext: HookContext;\n  \n  beforeEach(() => {\n    agent = createMockAgent();\n    mockContext = createMockContext({\n      sessionId: 'test-session',\n      user: { id: 'test-user' }\n    });\n  });\n  \n  it('should log messages before processing', async () => {\n    const logSpy = jest.spyOn(console, 'log');\n    \n    const hooks = {\n      beforeMessage: async (message: Message, context: HookContext) => {\n        console.log('Processing:', message.content);\n        return message;\n      }\n    };\n    \n    agent.setHooks(hooks);\n    \n    const message = { role: 'user', content: 'Hello' };\n    await agent.hooks.beforeMessage?.(message, mockContext);\n    \n    expect(logSpy).toHaveBeenCalledWith('Processing:', 'Hello');\n  });\n  \n  it('should handle hook errors gracefully', async () => {\n    const hooks = {\n      beforeMessage: async (message: Message, context: HookContext) => {\n        throw new Error('Hook error');\n      }\n    };\n    \n    agent.setHooks(hooks);\n    \n    const message = { role: 'user', content: 'Hello' };\n    \n    await expect(agent.hooks.beforeMessage?.(message, mockContext))\n      .rejects.toThrow('Hook error');\n  });\n});\n\n\n\nIntegration Testing#\n\ndescribe('Hook Integration', () => {\n  it('should execute hooks in correct order', async () => {\n    const executionOrder: string[] = [];\n    \n    const agent = new Agent({\n      hooks: {\n        beforeMessage: async (message, context) => {\n          executionOrder.push('beforeMessage');\n          return message;\n        },\n        \n        beforeToolCall: async (toolCall, context) => {\n          executionOrder.push('beforeToolCall');\n          return toolCall;\n        },\n        \n        afterToolCall: async (toolCall, result, context) => {\n          executionOrder.push('afterToolCall');\n        },\n        \n        afterMessage: async (userMessage, response, context) => {\n          executionOrder.push('afterMessage');\n        }\n      },\n      tools: [testTool]\n    });\n    \n    await agent.query('Use the test tool');\n    \n    expect(executionOrder).toEqual([\n      'beforeMessage',\n      'beforeToolCall', \n      'afterToolCall',\n      'afterMessage'\n    ]);\n  });\n});\n\n\n\nBest Practices#\n\n\n1. Hook Design#\n\n * Keep hooks focused and lightweight\n * Handle errors gracefully\n * Use async/await for asynchronous operations\n * Return modified data when appropriate\n\n\n2. Performance#\n\n * Avoid blocking operations in critical hooks\n * Use Promise.all() for parallel operations\n * Implement timeouts for external calls\n * Cache expensive computations\n\n\n3. Error Handling#\n\n * Always handle hook errors\n * Provide fallback behavior\n * Log errors for debugging\n * Don't let hook errors break agent operation\n\n\n4. Testing#\n\n * Unit test hooks in isolation\n * Test hook composition and ordering\n * Mock external dependencies\n * Test error scenarios\n\n\nNext Steps#\n\n * Examples - See real-world hook implementations\n * Agent Protocol - Understand event handling in hooks\n * Server - Use hooks in server environments","routePath":"/guide/advanced/agent-hooks","lang":"en","toc":[{"text":"Overview","id":"overview","depth":2,"charIndex":211},{"text":"Basic Hook Usage","id":"basic-hook-usage","depth":2,"charIndex":580},{"text":"Defining Hooks","id":"defining-hooks","depth":3,"charIndex":600},{"text":"Hook Context","id":"hook-context","depth":3,"charIndex":1564},{"text":"Lifecycle Hooks","id":"lifecycle-hooks","depth":2,"charIndex":1997},{"text":"Agent Lifecycle","id":"agent-lifecycle","depth":3,"charIndex":2016},{"text":"Session Lifecycle","id":"session-lifecycle","depth":3,"charIndex":3103},{"text":"Message Processing Hooks","id":"message-processing-hooks","depth":2,"charIndex":4168},{"text":"Message Transformation","id":"message-transformation","depth":3,"charIndex":4196},{"text":"Tool Execution Hooks","id":"tool-execution-hooks","depth":2,"charIndex":6185},{"text":"Tool Call Monitoring","id":"tool-call-monitoring","depth":3,"charIndex":6209},{"text":"Context Engineering Hooks","id":"context-engineering-hooks","depth":2,"charIndex":9593},{"text":"Context Management","id":"context-management","depth":3,"charIndex":9622},{"text":"Custom Hook Implementation","id":"custom-hook-implementation","depth":2,"charIndex":11833},{"text":"Plugin System","id":"plugin-system","depth":3,"charIndex":11863},{"text":"Conditional Hooks","id":"conditional-hooks","depth":3,"charIndex":13309},{"text":"Advanced Hook Patterns","id":"advanced-hook-patterns","depth":2,"charIndex":14556},{"text":"Hook Composition","id":"hook-composition","depth":3,"charIndex":14582},{"text":"Async Hook Patterns","id":"async-hook-patterns","depth":3,"charIndex":15443},{"text":"Testing Hooks","id":"testing-hooks","depth":2,"charIndex":16545},{"text":"Unit Testing","id":"unit-testing","depth":3,"charIndex":16562},{"text":"Integration Testing","id":"integration-testing","depth":3,"charIndex":17791},{"text":"Best Practices","id":"best-practices","depth":2,"charIndex":18797},{"text":"1. Hook Design","id":"1-hook-design","depth":3,"charIndex":18815},{"text":"2. Performance","id":"2-performance","depth":3,"charIndex":18988},{"text":"3. Error Handling","id":"3-error-handling","depth":3,"charIndex":19172},{"text":"4. Testing","id":"4-testing","depth":3,"charIndex":19327},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":19466}],"frontmatter":{"title":"Agent Hooks","description":"Extend and customize agent behavior with powerful hook system"},"version":""},{"title":"Agent Protocol","content":"#\n\nTarko's Agent Protocol defines standardized formats for agent communication,\nenabling seamless integration between components and making Context Engineering\nmore manageable.\n\n\nOverview#\n\nThe Agent Protocol consists of two main components:\n\n 1. Event Stream: Internal communication between agent components\n 2. Server Protocol: HTTP/SSE/WebSocket APIs for external integration\n\n\nEvent Stream Protocol#\n\nThe Event Stream is the core communication mechanism within Tarko agents.\n\n\nEvent Structure#\n\nAll events follow a consistent structure:\n\ninterface AgentEvent {\n  id: string;           // Unique event identifier\n  type: string;         // Event type\n  timestamp: number;    // Unix timestamp\n  sessionId: string;    // Session identifier\n  data: any;           // Event-specific data\n  metadata?: {         // Optional metadata\n    source?: string;   // Event source component\n    version?: string;  // Protocol version\n    traceId?: string;  // Distributed tracing ID\n  };\n}\n\n\n\nCore Event Types#\n\nUser Events#\n\n// User message\n{\n  type: 'user_message',\n  data: {\n    content: string | MessageContent[]; // Text or multimodal content\n    role: 'user';\n  }\n}\n\n// User query (alias for user_message)\n{\n  type: 'user_query',\n  data: {\n    query: string | MessageContent[];\n  }\n}\n\n\nAssistant Events#\n\n// Assistant message start\n{\n  type: 'assistant_message_start',\n  data: {\n    role: 'assistant';\n  }\n}\n\n// Assistant message delta (streaming)\n{\n  type: 'assistant_message_delta',\n  data: {\n    delta: string;\n    accumulated?: string; // Full content so far\n  }\n}\n\n// Assistant message complete\n{\n  type: 'assistant_message',\n  data: {\n    content: string;\n    role: 'assistant';\n    finishReason: 'stop' | 'length' | 'tool_calls';\n  }\n}\n\n\nTool Events#\n\n// Tool call initiated\n{\n  type: 'tool_call',\n  data: {\n    id: string;\n    name: string;\n    arguments: Record<string, any>;\n    type: 'function';\n  }\n}\n\n// Tool execution start\n{\n  type: 'tool_execution_start',\n  data: {\n    toolCallId: string;\n    name: string;\n  }\n}\n\n// Tool execution delta (streaming tools)\n{\n  type: 'tool_execution_delta',\n  data: {\n    toolCallId: string;\n    delta: string;\n    accumulated?: string;\n  }\n}\n\n// Tool execution result\n{\n  type: 'tool_result',\n  data: {\n    toolCallId: string;\n    name: string;\n    content: string;\n    success: boolean;\n    error?: string;\n  }\n}\n\n\nSystem Events#\n\n// Session started\n{\n  type: 'session_start',\n  data: {\n    sessionId: string;\n    agentName: string;\n    timestamp: number;\n  }\n}\n\n// Session ended\n{\n  type: 'session_end',\n  data: {\n    sessionId: string;\n    duration: number;\n    messageCount: number;\n  }\n}\n\n// Error occurred\n{\n  type: 'error',\n  data: {\n    error: string;\n    code?: string;\n    details?: any;\n    recoverable: boolean;\n  }\n}\n\n// Context compression\n{\n  type: 'context_compressed',\n  data: {\n    originalLength: number;\n    compressedLength: number;\n    compressionRatio: number;\n    strategy: string;\n  }\n}\n\n\n\nEvent Stream Usage#\n\nListening to Events#\n\n\n\nconst agent = new Agent({\n  // ... configuration\n});\n\n// Listen to specific event types\nagent.on('assistant_message', (event) => {\n  console.log('Assistant response:', event.data.content);\n});\n\nagent.on('tool_call', (event) => {\n  console.log('Tool called:', event.data.name, event.data.arguments);\n});\n\nagent.on('error', (event) => {\n  console.error('Agent error:', event.data.error);\n});\n\n// Listen to all events\nagent.on('*', (event) => {\n  console.log('Event:', event.type, event.data);\n});\n\n\nEmitting Custom Events#\n\n// Emit custom events from tools or hooks\nagent.emit({\n  type: 'custom_metric',\n  data: {\n    metric: 'response_time',\n    value: 1250,\n    unit: 'ms'\n  }\n});\n\n\nEvent Filtering#\n\n// Filter events by type\nconst toolEvents = agent.getEventStream()\n  .filter(event => event.type.startsWith('tool_'));\n\n// Filter events by session\nconst sessionEvents = agent.getEventStream()\n  .filter(event => event.sessionId === 'specific-session');\n\n// Filter events by time range\nconst recentEvents = agent.getEventStream()\n  .filter(event => event.timestamp > Date.now() - 3600000); // Last hour\n\n\n\nServer Protocol#\n\nThe Server Protocol defines HTTP/SSE/WebSocket APIs for external integration.\n\n\nHTTP REST API#\n\nSession Management#\n\n# Create session\nPOST /api/v1/sessions/create\nContent-Type: application/json\n\n{\n  \"name\": \"My Session\",\n  \"tags\": [\"tag1\", \"tag2\"]\n}\n\n# Response\n{\n  \"sessionId\": \"sess_123\",\n  \"createdAt\": 1622548800000\n}\n\n\n# Execute query\nPOST /api/v1/sessions/query\nContent-Type: application/json\n\n{\n  \"sessionId\": \"sess_123\",\n  \"query\": \"Hello, how can you help?\"\n}\n\n# Response\n{\n  \"response\": \"Hello! I'm here to help...\",\n  \"events\": [\n    {\n      \"type\": \"user_message\",\n      \"data\": { \"content\": \"Hello, how can you help?\" }\n    },\n    {\n      \"type\": \"assistant_message\",\n      \"data\": { \"content\": \"Hello! I'm here to help...\" }\n    }\n  ]\n}\n\n\nEvent History#\n\n# Get session events\nGET /api/v1/sessions/events?sessionId=sess_123&limit=50&offset=0\n\n# Response\n{\n  \"events\": [\n    {\n      \"id\": \"evt_1\",\n      \"type\": \"user_message\",\n      \"timestamp\": 1622548800000,\n      \"sessionId\": \"sess_123\",\n      \"data\": { \"content\": \"Hello\" }\n    }\n  ],\n  \"total\": 125,\n  \"hasMore\": true\n}\n\n\n\nServer-Sent Events (SSE)#\n\nFor real-time streaming:\n\n# Streaming query\nPOST /api/v1/sessions/query/stream\nContent-Type: application/json\nAccept: text/event-stream\n\n{\n  \"sessionId\": \"sess_123\",\n  \"query\": \"Tell me a story\"\n}\n\n\nSSE Response:\n\nevent: user_message\ndata: {\"id\":\"evt_1\",\"type\":\"user_message\",\"data\":{\"content\":\"Tell me a story\"}}\n\nevent: assistant_message_start\ndata: {\"id\":\"evt_2\",\"type\":\"assistant_message_start\",\"data\":{}}\n\nevent: assistant_message_delta\ndata: {\"id\":\"evt_3\",\"type\":\"assistant_message_delta\",\"data\":{\"delta\":\"Once upon\"}}\n\nevent: assistant_message_delta\ndata: {\"id\":\"evt_4\",\"type\":\"assistant_message_delta\",\"data\":{\"delta\":\" a time\"}}\n\nevent: assistant_message\ndata: {\"id\":\"evt_5\",\"type\":\"assistant_message\",\"data\":{\"content\":\"Once upon a time...\"}}\n\n\n\nWebSocket Protocol#\n\nFor bidirectional real-time communication:\n\nconst socket = new WebSocket('ws://localhost:8888/ws');\n\n// Connect to session\nsocket.send(JSON.stringify({\n  type: 'join_session',\n  sessionId: 'sess_123'\n}));\n\n// Send query\nsocket.send(JSON.stringify({\n  type: 'send_query',\n  sessionId: 'sess_123',\n  query: 'Hello!'\n}));\n\n// Receive events\nsocket.onmessage = (event) => {\n  const agentEvent = JSON.parse(event.data);\n  console.log('Received:', agentEvent.type, agentEvent.data);\n};\n\n// Abort query\nsocket.send(JSON.stringify({\n  type: 'abort_query',\n  sessionId: 'sess_123'\n}));\n\n\n\nProtocol Extensions#\n\n\nCustom Event Types#\n\nDefine custom events for your application:\n\n// Define custom event types\ninterface CustomEvents {\n  'user_feedback': {\n    rating: number;\n    comment?: string;\n  };\n  'tool_performance': {\n    toolName: string;\n    executionTime: number;\n    success: boolean;\n  };\n}\n\n// Use with type safety\nagent.on('user_feedback', (event) => {\n  console.log('User rating:', event.data.rating);\n});\n\nagent.emit({\n  type: 'tool_performance',\n  data: {\n    toolName: 'web_search',\n    executionTime: 1250,\n    success: true\n  }\n});\n\n\n\nProtocol Versioning#\n\n// Specify protocol version\nconst agent = new Agent({\n  protocol: {\n    version: '1.0',\n    extensions: ['custom-events', 'performance-metrics']\n  }\n});\n\n// Version-aware event handling\nagent.on('*', (event) => {\n  const version = event.metadata?.version || '1.0';\n  \n  if (version === '1.0') {\n    // Handle v1.0 events\n  } else if (version === '2.0') {\n    // Handle v2.0 events\n  }\n});\n\n\n\nIntegration Examples#\n\n\nReact Integration#\n\n\n\nfunction AgentChat({ sessionId }: { sessionId: string }) {\n  const [events, setEvents] = useState<AgentEvent[]>([]);\n  const [isLoading, setIsLoading] = useState(false);\n  \n  useEffect(() => {\n    const eventSource = new EventSource(\n      `/api/v1/sessions/events/stream?sessionId=${sessionId}`\n    );\n    \n    eventSource.onmessage = (event) => {\n      const agentEvent = JSON.parse(event.data);\n      setEvents(prev => [...prev, agentEvent]);\n      \n      if (agentEvent.type === 'assistant_message') {\n        setIsLoading(false);\n      }\n    };\n    \n    return () => eventSource.close();\n  }, [sessionId]);\n  \n  const sendMessage = async (message: string) => {\n    setIsLoading(true);\n    \n    await fetch('/api/v1/sessions/query', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ sessionId, query: message })\n    });\n  };\n  \n  return (\n    <div>\n      {events.map(event => (\n        <EventDisplay key={event.id} event={event} />\n      ))}\n      {isLoading && <LoadingIndicator />}\n      <MessageInput onSend={sendMessage} />\n    </div>\n  );\n}\n\n\n\nCLI Integration#\n\n\n\n\nconst agent = new Agent({ /* config */ });\n\n// Display events in CLI\nagent.on('user_message', (event) => {\n  console.log(chalk.blue('User:'), event.data.content);\n});\n\nagent.on('assistant_message_delta', (event) => {\n  process.stdout.write(chalk.green(event.data.delta));\n});\n\nagent.on('assistant_message', (event) => {\n  console.log(); // New line after complete message\n});\n\nagent.on('tool_call', (event) => {\n  console.log(chalk.yellow(`ðŸ”§ Using ${event.data.name}...`));\n});\n\nagent.on('tool_result', (event) => {\n  if (event.data.success) {\n    console.log(chalk.green('âœ… Tool completed'));\n  } else {\n    console.log(chalk.red('âŒ Tool failed:'), event.data.error);\n  }\n});\n\nagent.on('error', (event) => {\n  console.error(chalk.red('Error:'), event.data.error);\n});\n\n\n\nMonitoring Integration#\n\n\n\n\nconst metrics = createPrometheusMetrics();\nconst agent = new Agent({ /* config */ });\n\n// Track metrics from events\nagent.on('assistant_message', (event) => {\n  metrics.responseCount.inc();\n  metrics.responseLength.observe(event.data.content.length);\n});\n\nagent.on('tool_call', (event) => {\n  metrics.toolCallCount.inc({ tool: event.data.name });\n});\n\nagent.on('tool_result', (event) => {\n  const duration = Date.now() - event.timestamp;\n  metrics.toolExecutionDuration.observe(\n    { tool: event.data.name, success: event.data.success },\n    duration\n  );\n});\n\nagent.on('error', (event) => {\n  metrics.errorCount.inc({ type: event.data.code || 'unknown' });\n});\n\n\n\nBest Practices#\n\n\n1. Event Design#\n\n * Use consistent event naming conventions\n * Include all necessary data in event payload\n * Add metadata for debugging and tracing\n * Version your event schemas\n\n\n2. Error Handling#\n\n * Always include error context in error events\n * Use structured error codes\n * Provide actionable error messages\n * Implement proper error recovery\n\n\n3. Performance#\n\n * Batch events when possible\n * Use appropriate event filtering\n * Implement event compression for large payloads\n * Monitor event processing latency\n\n\n4. Security#\n\n * Sanitize event data before transmission\n * Implement proper authentication for event streams\n * Use encryption for sensitive event data\n * Audit event access patterns\n\n\nDebugging and Monitoring#\n\n\nEvent Inspection#\n\n// Enable debug logging\nconst agent = new Agent({\n  debug: {\n    events: true,\n    level: 'verbose'\n  }\n});\n\n// Export event stream for analysis\nconst events = agent.getEventHistory();\nfs.writeFileSync('events.json', JSON.stringify(events, null, 2));\n\n// Real-time event monitoring\nagent.on('*', (event) => {\n  if (process.env.NODE_ENV === 'development') {\n    console.log(`[${event.type}]`, event.data);\n  }\n});\n\n\n\nProtocol Validation#\n\n\n\n// Validate events against schema\nagent.on('*', (event) => {\n  const validation = validateEvent(event, EventSchema);\n  if (!validation.valid) {\n    console.warn('Invalid event:', validation.errors);\n  }\n});\n\n\n\nNext Steps#\n\n * Agent Hooks - Extend protocol behavior\n * Server - Implement server protocol\n * Examples - See protocol integration examples","routePath":"/guide/advanced/agent-protocol","lang":"en","toc":[{"text":"Overview","id":"overview","depth":2,"charIndex":178},{"text":"Event Stream Protocol","id":"event-stream-protocol","depth":2,"charIndex":380},{"text":"Event Structure","id":"event-structure","depth":3,"charIndex":480},{"text":"Core Event Types","id":"core-event-types","depth":3,"charIndex":982},{"text":"User Events","id":"user-events","depth":4,"charIndex":1001},{"text":"Assistant Events","id":"assistant-events","depth":4,"charIndex":1281},{"text":"Tool Events","id":"tool-events","depth":4,"charIndex":1740},{"text":"System Events","id":"system-events","depth":4,"charIndex":2361},{"text":"Event Stream Usage","id":"event-stream-usage","depth":3,"charIndex":2960},{"text":"Listening to Events","id":"listening-to-events","depth":4,"charIndex":2981},{"text":"Emitting Custom Events","id":"emitting-custom-events","depth":4,"charIndex":3502},{"text":"Event Filtering","id":"event-filtering","depth":4,"charIndex":3688},{"text":"Server Protocol","id":"server-protocol","depth":2,"charIndex":4111},{"text":"HTTP REST API","id":"http-rest-api","depth":3,"charIndex":4209},{"text":"Session Management","id":"session-management","depth":4,"charIndex":4225},{"text":"Event History","id":"event-history","depth":4,"charIndex":4882},{"text":"Server-Sent Events (SSE)","id":"server-sent-events-sse","depth":3,"charIndex":5221},{"text":"WebSocket Protocol","id":"websocket-protocol","depth":3,"charIndex":6004},{"text":"Protocol Extensions","id":"protocol-extensions","depth":2,"charIndex":6605},{"text":"Custom Event Types","id":"custom-event-types","depth":3,"charIndex":6628},{"text":"Protocol Versioning","id":"protocol-versioning","depth":3,"charIndex":7169},{"text":"Integration Examples","id":"integration-examples","depth":2,"charIndex":7583},{"text":"React Integration","id":"react-integration","depth":3,"charIndex":7607},{"text":"CLI Integration","id":"cli-integration","depth":3,"charIndex":8740},{"text":"Monitoring Integration","id":"monitoring-integration","depth":3,"charIndex":9534},{"text":"Best Practices","id":"best-practices","depth":2,"charIndex":10228},{"text":"1. Event Design","id":"1-event-design","depth":3,"charIndex":10246},{"text":"2. Error Handling","id":"2-error-handling","depth":3,"charIndex":10428},{"text":"3. Performance","id":"3-performance","depth":3,"charIndex":10600},{"text":"4. Security","id":"4-security","depth":3,"charIndex":10770},{"text":"Debugging and Monitoring","id":"debugging-and-monitoring","depth":2,"charIndex":10956},{"text":"Event Inspection","id":"event-inspection","depth":3,"charIndex":10984},{"text":"Protocol Validation","id":"protocol-validation","depth":3,"charIndex":11419},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":11653}],"frontmatter":{"title":"Agent Protocol","description":"Understand Tarko's standardized communication protocols"},"version":""},{"title":"Agent Snapshot","content":"#\n\nAgent Snapshot is a powerful feature that allows you to capture the complete\nstate of an Agent at runtime and replay it later. This is essential for\ndebugging, testing, and ensuring deterministic Agent behavior.\n\n\nWhat is Agent Snapshot?#\n\nAn Agent Snapshot captures:\n\n * Complete conversation history\n * Current context state\n * Tool call history and results\n * Agent configuration\n * Environment state\n\n\nCreating Snapshots#\n\n\nAutomatic Snapshots#\n\nEnable automatic snapshot creation:\n\n\n\nconst agent = new Agent({\n  ...config,\n  snapshot: {\n    enabled: true,\n    interval: 'on_tool_call', // or 'on_message', 'manual'\n    storage: {\n      type: 'file',\n      path: './snapshots'\n    }\n  }\n});\n\n\n\nManual Snapshots#\n\nCreate snapshots programmatically:\n\n// Create a snapshot\nconst snapshot = await agent.createSnapshot({\n  name: 'debug-session-1',\n  description: 'Before problematic tool call'\n});\n\nconsole.log('Snapshot created:', snapshot.id);\n\n\n\nSnapshot Structure#\n\nA snapshot contains:\n\ninterface AgentSnapshot {\n  id: string;\n  timestamp: string;\n  name?: string;\n  description?: string;\n  \n  // Agent state\n  context: {\n    messages: Message[];\n    length: number;\n    metadata: Record<string, any>;\n  };\n  \n  // Configuration\n  config: AgentConfig;\n  \n  // Environment\n  environment: {\n    variables: Record<string, string>;\n    workingDirectory: string;\n    platform: string;\n  };\n  \n  // Tool state\n  tools: {\n    available: ToolDefinition[];\n    history: ToolCall[];\n  };\n}\n\n\n\nReplaying Snapshots#\n\n\nLoad and Replay#\n\n\n\n// Load snapshot\nconst snapshot = await loadSnapshot('./snapshots/debug-session-1.json');\n\n// Create agent from snapshot\nconst agent = Agent.fromSnapshot(snapshot);\n\n// Continue conversation from snapshot state\nconst response = await agent.chat('What happened next?');\n\n\n\nReplay with Modifications#\n\n// Load snapshot and modify configuration\nconst snapshot = await loadSnapshot('./snapshots/debug-session-1.json');\n\n// Override model settings for testing\nsnapshot.config.model.temperature = 0.1;\nsnapshot.config.model.model = 'gpt-4';\n\nconst agent = Agent.fromSnapshot(snapshot);\n\n\n\nTesting with Snapshots#\n\n\nSnapshot-Based Testing#\n\n\n\n\ntest('should handle file operations correctly', async () => {\n  // Load pre-recorded snapshot\n  const snapshot = await loadSnapshot('./test-snapshots/file-ops.json');\n  const agent = Agent.fromSnapshot(snapshot);\n  \n  // Replay the scenario\n  const response = await agent.chat('Create a new file called test.txt');\n  \n  // Assert expected behavior\n  expect(response).toContain('File created successfully');\n});\n\n\n\nRegression Testing#\n\n// Capture baseline behavior\nconst baselineSnapshot = await agent.createSnapshot({\n  name: 'baseline-v1.0'\n});\n\n// Later, test against baseline\nconst currentSnapshot = await agent.createSnapshot({\n  name: 'current-test'\n});\n\n// Compare snapshots\nconst diff = compareSnapshots(baselineSnapshot, currentSnapshot);\nif (diff.hasChanges) {\n  console.warn('Behavior changed:', diff.changes);\n}\n\n\n\nSnapshot Management#\n\n\nList Snapshots#\n\nconst snapshots = await agent.listSnapshots();\nsnapshots.forEach(snapshot => {\n  console.log(`${snapshot.name} (${snapshot.timestamp})`);\n});\n\n\n\nDelete Snapshots#\n\n// Delete specific snapshot\nawait agent.deleteSnapshot('debug-session-1');\n\n// Clean up old snapshots\nawait agent.cleanupSnapshots({\n  olderThan: '7d',\n  keepLatest: 10\n});\n\n\n\nBest Practices#\n\n\nWhen to Create Snapshots#\n\n * Before complex operations\n * After successful tool calls\n * When debugging issues\n * For regression testing\n\n\nNaming Conventions#\n\n// Use descriptive names\nconst snapshot = await agent.createSnapshot({\n  name: 'before-file-upload-v2.1',\n  description: 'State before implementing new file upload logic'\n});\n\n\n\nStorage Considerations#\n\n// Configure appropriate storage\nconst agent = new Agent({\n  snapshot: {\n    storage: {\n      type: 'redis', // For production\n      url: 'redis://localhost:6379',\n      ttl: 86400 // 24 hours\n    },\n    compression: true, // Reduce storage size\n    maxSnapshots: 100  // Limit storage usage\n  }\n});\n\n\n\nDebugging with Snapshots#\n\n\nCapture Problem State#\n\nagent.on('error', async (error) => {\n  // Automatically create snapshot on error\n  const snapshot = await agent.createSnapshot({\n    name: `error-${Date.now()}`,\n    description: `Error: ${error.message}`\n  });\n  \n  console.log('Error snapshot saved:', snapshot.id);\n});\n\n\n\nStep-by-Step Debugging#\n\n// Load problematic snapshot\nconst snapshot = await loadSnapshot('./snapshots/error-123.json');\nconst agent = Agent.fromSnapshot(snapshot);\n\n// Enable detailed logging\nagent.setLogLevel('debug');\n\n// Replay with debugging\nconst response = await agent.chat('Continue from here');\n","routePath":"/guide/advanced/agent-snapshot","lang":"en","toc":[{"text":"What is Agent Snapshot?","id":"what-is-agent-snapshot","depth":2,"charIndex":216},{"text":"Creating Snapshots","id":"creating-snapshots","depth":2,"charIndex":408},{"text":"Automatic Snapshots","id":"automatic-snapshots","depth":3,"charIndex":430},{"text":"Manual Snapshots","id":"manual-snapshots","depth":3,"charIndex":700},{"text":"Snapshot Structure","id":"snapshot-structure","depth":2,"charIndex":950},{"text":"Replaying Snapshots","id":"replaying-snapshots","depth":2,"charIndex":1489},{"text":"Load and Replay","id":"load-and-replay","depth":3,"charIndex":1512},{"text":"Replay with Modifications","id":"replay-with-modifications","depth":3,"charIndex":1804},{"text":"Testing with Snapshots","id":"testing-with-snapshots","depth":2,"charIndex":2115},{"text":"Snapshot-Based Testing","id":"snapshot-based-testing","depth":3,"charIndex":2141},{"text":"Regression Testing","id":"regression-testing","depth":3,"charIndex":2583},{"text":"Snapshot Management","id":"snapshot-management","depth":2,"charIndex":2995},{"text":"List Snapshots","id":"list-snapshots","depth":3,"charIndex":3018},{"text":"Delete Snapshots","id":"delete-snapshots","depth":3,"charIndex":3180},{"text":"Best Practices","id":"best-practices","depth":2,"charIndex":3375},{"text":"When to Create Snapshots","id":"when-to-create-snapshots","depth":3,"charIndex":3393},{"text":"Naming Conventions","id":"naming-conventions","depth":3,"charIndex":3533},{"text":"Storage Considerations","id":"storage-considerations","depth":3,"charIndex":3732},{"text":"Debugging with Snapshots","id":"debugging-with-snapshots","depth":2,"charIndex":4060},{"text":"Capture Problem State","id":"capture-problem-state","depth":3,"charIndex":4088},{"text":"Step-by-Step Debugging","id":"step-by-step-debugging","depth":3,"charIndex":4386}],"frontmatter":{"title":"Agent Snapshot","description":"Capture and replay Agent state for debugging and testing"},"version":""},{"title":"Context Engineering","content":"#\n\nContext Engineering is Tarko's core capability for building agents capable of\nlong-running operations. It manages context windows and optimizes memory usage\nthrough intelligent message history management.\n\n\nWhat is Context Engineering?#\n\nTraditional agents struggle with long-running tasks due to context window\nlimitations. Tarko's Context Engineering solves this through:\n\n * Message History Management: Intelligent conversion of event streams to LLM\n   context\n * Image Limiting: Controls the number of images in context to prevent overflow\n * Context Awareness: Configurable context management for multimodal content\n * Event Stream Processing: Maintains conversation structure for optimal LLM\n   context\n\n\nKey Features#\n\n\n1. Context Awareness Configuration#\n\nConfigure how the agent manages context and multimodal content:\n\n\n\nconst agent = new Agent({\n  context: {\n    maxImagesCount: 5, // Limit images in context (default: 5)\n  }\n});\n\n\n\n2. Message History Management#\n\nThe MessageHistory class automatically converts event streams to message\nhistory:\n\n// From multimodal/tarko/agent/src/agent/message-history.ts\nconst messageHistory = new MessageHistory(\n  eventStream,\n  5 // maxImagesCount - limits images to prevent context overflow\n);\n\nconst messages = messageHistory.toMessageHistory(\n  toolCallEngine,\n  systemPrompt,\n  tools\n);\n\n\n\n3. Image Context Management#\n\nControl how images are handled in long conversations:\n\nconst agent = new Agent({\n  context: {\n    maxImagesCount: 10, // Allow up to 10 images in context\n  }\n});\n\n\nHow it works:\n\n * Images beyond the limit are replaced with text placeholders\n * Newest images are preserved, oldest are omitted\n * Maintains context structure while reducing token usage\n\n\nConfiguration Options#\n\n\nContext Awareness Configuration#\n\nBased on the actual AgentContextAwarenessOptions interface:\n\ninterface AgentContextAwarenessOptions {\n  /**\n   * Maximum number of images to include in context\n   * When exceeded, oldest images are replaced with text placeholders\n   * @default 5\n   */\n  maxImagesCount?: number;\n}\n\n\n\nAgent Configuration#\n\nconst agent = new Agent({\n  context: {\n    maxImagesCount: 10, // Limit images in context\n  },\n  // Other agent options...\n});\n\n\n\nBest Practices#\n\n\n1. Configure Image Limits Appropriately#\n\nFor text-heavy conversations:\n\nconst agent = new Agent({\n  context: {\n    maxImagesCount: 3, // Keep fewer images for text focus\n  },\n});\n\n\nFor visual analysis tasks:\n\nconst agent = new Agent({\n  context: {\n    maxImagesCount: 15, // Allow more images for visual context\n  },\n});\n\n\n\n2. Monitor Context Usage#\n\nUse event stream to track context changes:\n\nconst response = await agent.run({\n  input: \"Analyze these images\",\n  stream: true,\n});\n\nfor await (const event of response) {\n  if (event.type === 'user_message' || event.type === 'environment_input') {\n    console.log('Context updated with:', event.content);\n  }\n}\n\n\n\n3. Handle Multimodal Content#\n\n// Environment input with images\nconst response = await agent.run({\n  input: \"What do you see?\",\n  environmentInput: {\n    content: [\n      { type: 'text', text: 'Current screen:' },\n      { type: 'image_url', image_url: { url: 'data:image/png;base64,...' } }\n    ],\n    description: 'Screen capture'\n  }\n});\n\n\n\nAdvanced Usage#\n\n\nCustom Message History Processing#\n\nExtend the MessageHistory class for custom context management:\n\n\n\nclass CustomMessageHistory extends MessageHistory {\n  constructor(eventStream, maxImagesCount = 5) {\n    super(eventStream, maxImagesCount);\n  }\n\n  // Override to add custom system prompt with time\n  getSystemPromptWithTime(instructions: string): string {\n    const customTime = new Date().toLocaleString('en-US', {\n      timeZone: 'America/New_York'\n    });\n    return `${instructions}\\n\\nCurrent time (EST): ${customTime}`;\n  }\n}\n\n\n\nWorking with Event Streams#\n\nAccess and manipulate the event stream for custom context logic:\n\nconst agent = new Agent({ /* options */ });\n\n// Get the event stream\nconst eventStream = agent.getEventStream();\n\n// Access events\nconst events = eventStream.getEvents();\nconsole.log(`Total events: ${events.length}`);\n\n// Filter specific event types\nconst userMessages = events.filter(e => e.type === 'user_message');\nconst toolCalls = events.filter(e => e.type === 'tool_call');\n\n\n\nIntegration with Agent Hooks#\n\nUse Agent Hooks to customize context behavior:\n\nconst agent = new Agent({\n  hooks: {\n    onBeforeToolCall: async (context) => {\n      // Log context before tool execution\n      console.log('Context before tool call:', context.messages.length);\n    },\n    \n    onAfterToolCall: async (context) => {\n      // Monitor context growth after tool execution\n      console.log('Context after tool call:', context.messages.length);\n    },\n    \n    onRetrieveTools: async (tools) => {\n      // Filter tools based on context size\n      const eventStream = agent.getEventStream();\n      const events = eventStream.getEvents();\n      \n      if (events.length > 50) {\n        // Reduce tools for large contexts\n        return tools.slice(0, 3);\n      }\n      return tools;\n    }\n  }\n});\n\n\n\nPerformance Considerations#\n\n\nMemory Usage#\n\n * Configure maxImagesCount based on available memory\n * Monitor event stream size for long-running conversations\n * Consider disposing agents after extended use\n\n\nContext Window Management#\n\n * Images consume significant token space\n * Text placeholders maintain context structure\n * Balance between context richness and token limits\n\n\nBest Practices#\n\n * Use environment input for transient context\n * Limit images for text-focused tasks\n * Monitor event stream growth in production\n\n\nDebugging Context Issues#\n\n\nEnable Debug Logging#\n\n\n\nconst agent = new Agent({\n  logLevel: LogLevel.DEBUG, // Enable detailed logging\n});\n\n\n\nContext Inspection#\n\n// Get event stream for analysis\nconst eventStream = agent.getEventStream();\nconst events = eventStream.getEvents();\n\nconsole.log('Total events:', events.length);\nconsole.log('Event types:', [...new Set(events.map(e => e.type))]);\n\n// Count images in context\nconst imageCount = events.reduce((count, event) => {\n  if (event.type === 'user_message' && Array.isArray(event.content)) {\n    return count + event.content.filter(part => \n      typeof part === 'object' && part.type === 'image_url'\n    ).length;\n  }\n  return count;\n}, 0);\n\nconsole.log('Images in context:', imageCount);\n\n// Export events for analysis\nconst fs = require('fs');\nfs.writeFileSync('events-dump.json', JSON.stringify(events, null, 2));\n\n\n\nReal-World Examples#\n\n\nVisual Analysis Agent#\n\nconst visualAgent = new Agent({\n  context: {\n    maxImagesCount: 20, // Allow many images for visual tasks\n  },\n  instructions: 'You are a visual analysis expert. Analyze images and provide detailed insights.',\n});\n\n\n\nText-Focused Assistant#\n\nconst textAssistant = new Agent({\n  context: {\n    maxImagesCount: 2, // Minimal images for text focus\n  },\n  instructions: 'You are a writing assistant focused on text analysis and generation.',\n});\n\n\n\nLong-Running Conversation Agent#\n\nconst conversationAgent = new Agent({\n  context: {\n    maxImagesCount: 8, // Balanced for mixed content\n  },\n  instructions: 'You are a helpful assistant for extended conversations.',\n});\n\n// Monitor context growth\nsetInterval(() => {\n  const events = conversationAgent.getEventStream().getEvents();\n  console.log(`Context events: ${events.length}`);\n}, 60000); // Check every minute\n\n\n\nNext Steps#\n\n * Tool Call Engine - Learn about tool integration\n * Agent Protocol - Understand communication standards\n * Agent Hooks - Extend agent behavior","routePath":"/guide/advanced/context-engineering","lang":"en","toc":[{"text":"What is Context Engineering?","id":"what-is-context-engineering","depth":2,"charIndex":209},{"text":"Key Features","id":"key-features","depth":2,"charIndex":713},{"text":"1. Context Awareness Configuration","id":"1-context-awareness-configuration","depth":3,"charIndex":729},{"text":"2. Message History Management","id":"2-message-history-management","depth":3,"charIndex":946},{"text":"3. Image Context Management","id":"3-image-context-management","depth":3,"charIndex":1347},{"text":"Configuration Options","id":"configuration-options","depth":2,"charIndex":1730},{"text":"Context Awareness Configuration","id":"context-awareness-configuration","depth":3,"charIndex":1755},{"text":"Agent Configuration","id":"agent-configuration","depth":3,"charIndex":2073},{"text":"Best Practices","id":"best-practices","depth":2,"charIndex":2225},{"text":"1. Configure Image Limits Appropriately","id":"1-configure-image-limits-appropriately","depth":3,"charIndex":2243},{"text":"2. Monitor Context Usage","id":"2-monitor-context-usage","depth":3,"charIndex":2568},{"text":"3. Handle Multimodal Content","id":"3-handle-multimodal-content","depth":3,"charIndex":2909},{"text":"Advanced Usage","id":"advanced-usage","depth":2,"charIndex":3252},{"text":"Custom Message History Processing","id":"custom-message-history-processing","depth":3,"charIndex":3270},{"text":"Working with Event Streams","id":"working-with-event-streams","depth":3,"charIndex":3807},{"text":"Integration with Agent Hooks","id":"integration-with-agent-hooks","depth":2,"charIndex":4285},{"text":"Performance Considerations","id":"performance-considerations","depth":2,"charIndex":5092},{"text":"Memory Usage","id":"memory-usage","depth":3,"charIndex":5122},{"text":"Context Window Management","id":"context-window-management","depth":3,"charIndex":5301},{"text":"Best Practices","id":"best-practices-1","depth":3,"charIndex":5474},{"text":"Debugging Context Issues","id":"debugging-context-issues","depth":2,"charIndex":5624},{"text":"Enable Debug Logging","id":"enable-debug-logging","depth":3,"charIndex":5652},{"text":"Context Inspection","id":"context-inspection","depth":3,"charIndex":5765},{"text":"Real-World Examples","id":"real-world-examples","depth":2,"charIndex":6498},{"text":"Visual Analysis Agent","id":"visual-analysis-agent","depth":3,"charIndex":6521},{"text":"Text-Focused Assistant","id":"text-focused-assistant","depth":3,"charIndex":6763},{"text":"Long-Running Conversation Agent","id":"long-running-conversation-agent","depth":3,"charIndex":6991},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":7412}],"frontmatter":{"title":"Context Engineering","description":"Master long-running agent operations with advanced context management"},"version":""},{"title":"Configuration","content":"#\n\nTarko Agents are configured through the AgentOptions interface that defines the\nAgent's behavior, capabilities, and runtime settings.\n\n\nBasic Configuration#\n\nBased on real examples from multimodal/tarko/agent/examples/:\n\n\n\nconst agent = new Agent({\n  // Agent identity\n  name: 'MyAgent',\n  id: 'my-agent-instance',\n  \n  // System instructions\n  instructions: 'You are a helpful assistant...',\n  \n  // Model configuration\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  \n  // Tools\n  tools: [],\n  \n  // Logging\n  logLevel: LogLevel.DEBUG,\n});\n\n\n\nConfiguration Options#\n\nBased on the actual AgentOptions interface from\nmultimodal/tarko/agent-interface/src/agent-options.ts:\n\n\nAgent Identity#\n\n{\n  id?: string,              // Unique agent ID\n  name?: string,            // Agent name for identification\n  instructions?: string,    // System prompt (replaces default)\n}\n\n\n\nModel Configuration#\n\n{\n  model?: {\n    provider: 'volcengine' | 'openai' | 'anthropic',\n    id: string,             // Model ID (e.g., 'gpt-4o', 'ep-20250510145437-5sxhs')\n    apiKey?: string,        // API key (or use environment variables)\n  },\n  temperature?: number,     // 0-1, default: 0.7\n  maxTokens?: number,       // Max tokens per request, default: 1000\n  top_p?: number,          // Nucleus sampling parameter\n}\n\n\n\nTools Configuration#\n\n{\n  tools?: Tool[],                    // Array of tool instances\n  toolCallEngine?: ToolCallEngineType, // 'native' | 'prompt_engineering' | 'structured_outputs'\n  tool?: {                          // Tool filtering options\n    include?: string[],             // Include tools matching these names\n    exclude?: string[],             // Exclude tools matching these names\n  },\n}\n\n\n\nExecution Control#\n\n{\n  maxIterations?: number,   // Max agent loop iterations, default: 1000\n}\n\n\n\nContext Management#\n\n{\n  context?: {\n    maxImagesCount?: number,  // Max images to keep in context\n  },\n}\n\n\n\nAdvanced Features#\n\n{\n  thinking?: LLMReasoningOptions,     // Reasoning/thinking options\n  enableStreamingToolCallEvents?: boolean, // Enable streaming tool call events\n  initialEvents?: AgentEventStream.Event[], // Restore conversation context\n}\n\n\n\nWorkspace and Environment#\n\n{\n  workspace?: string,       // Directory for filesystem operations\n  sandboxUrl?: string,      // Sandbox URL for tool execution\n}\n\n\n\nMonitoring and Logging#\n\n{\n  logLevel?: LogLevel,      // DEBUG | INFO | WARN | ERROR\n  metric?: {\n    enable?: boolean,       // Enable metric collection (TTFT, TTLT, etc.)\n  },\n}\n\n\n\nEnvironment Variables#\n\nCommon environment variables for Tarko Agents:\n\n# Model Provider API Keys\nOPENAI_API_KEY=your_openai_key\nANTHROPIC_API_KEY=your_anthropic_key\nARK_API_KEY=your_volcengine_key        # For Volcengine/Doubao models\n\n# Development settings\nNODE_ENV=development\n\n\n\nExample .env file#\n\n# .env\nARK_API_KEY=your-volcengine-api-key\nOPENAI_API_KEY=sk-your-openai-key\nANTHROPIC_API_KEY=your-anthropic-key\n\n\n\nReal Configuration Examples#\n\n\nBasic Agent with Tools#\n\nFrom multimodal/tarko/agent/examples/tool-calls/basic.ts:\n\n\n\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  tools: [locationTool, weatherTool],\n  logLevel: LogLevel.DEBUG,\n});\n\n\n\nStreaming Configuration#\n\nFrom multimodal/tarko/agent/examples/streaming/tool-calls.ts:\n\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  tools: [locationTool, weatherTool],\n  toolCallEngine: 'native',\n  enableStreamingToolCallEvents: true,\n});\n\n\n\nDifferent Model Providers#\n\n// Volcengine/Doubao\nconst volcengineAgent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n});\n\n// OpenAI\nconst openaiAgent = new Agent({\n  model: {\n    provider: 'openai',\n    id: 'gpt-4o',\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n// Anthropic\nconst anthropicAgent = new Agent({\n  model: {\n    provider: 'anthropic',\n    id: 'claude-3-5-sonnet-20241022',\n    apiKey: process.env.ANTHROPIC_API_KEY,\n  },\n});\n\n\n\nAdvanced Configuration#\n\n\nContext and Performance Tuning#\n\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  maxIterations: 50,        // Limit reasoning loops\n  maxTokens: 2000,         // Limit response length\n  temperature: 0.3,        // More deterministic responses\n  context: {\n    maxImagesCount: 5,     // Limit images in context\n  },\n  metric: {\n    enable: true,          // Enable performance metrics\n  },\n});\n\n\n\nTool Call Engine Selection#\n\n// For models with native function calling\nconst nativeAgent = new Agent({\n  toolCallEngine: 'native',\n  tools: [myTool],\n});\n\n// For models without native function calling\nconst promptAgent = new Agent({\n  toolCallEngine: 'prompt_engineering',\n  tools: [myTool],\n});\n\n// For structured output parsing\nconst structuredAgent = new Agent({\n  toolCallEngine: 'structured_outputs',\n  tools: [myTool],\n});\n\n\n\nValidation and Error Handling#\n\ntry {\n  const agent = new Agent({\n    model: {\n      provider: 'volcengine',\n      id: 'ep-20250510145437-5sxhs',\n      apiKey: process.env.ARK_API_KEY,\n    },\n  });\n  \n  const response = await agent.run('Hello!');\n  console.log(response);\n} catch (error) {\n  console.error('Agent configuration or execution error:', error);\n}\n","routePath":"/guide/basic/configuration","lang":"en","toc":[{"text":"Basic Configuration","id":"basic-configuration","depth":2,"charIndex":138},{"text":"Configuration Options","id":"configuration-options","depth":2,"charIndex":617},{"text":"Agent Identity","id":"agent-identity","depth":3,"charIndex":746},{"text":"Model Configuration","id":"model-configuration","depth":3,"charIndex":942},{"text":"Tools Configuration","id":"tools-configuration","depth":3,"charIndex":1370},{"text":"Execution Control","id":"execution-control","depth":3,"charIndex":1775},{"text":"Context Management","id":"context-management","depth":3,"charIndex":1874},{"text":"Advanced Features","id":"advanced-features","depth":3,"charIndex":1984},{"text":"Workspace and Environment","id":"workspace-and-environment","depth":3,"charIndex":2235},{"text":"Monitoring and Logging","id":"monitoring-and-logging","depth":3,"charIndex":2399},{"text":"Environment Variables","id":"environment-variables","depth":2,"charIndex":2583},{"text":"Example .env file","id":"example-env-file","depth":3,"charIndex":2867},{"text":"Real Configuration Examples","id":"real-configuration-examples","depth":2,"charIndex":3004},{"text":"Basic Agent with Tools","id":"basic-agent-with-tools","depth":3,"charIndex":3035},{"text":"Streaming Configuration","id":"streaming-configuration","depth":3,"charIndex":3336},{"text":"Different Model Providers","id":"different-model-providers","depth":3,"charIndex":3679},{"text":"Advanced Configuration","id":"advanced-configuration","depth":2,"charIndex":4209},{"text":"Context and Performance Tuning","id":"context-and-performance-tuning","depth":3,"charIndex":4235},{"text":"Tool Call Engine Selection","id":"tool-call-engine-selection","depth":3,"charIndex":4727},{"text":"Validation and Error Handling","id":"validation-and-error-handling","depth":2,"charIndex":5160}],"frontmatter":{"title":"Configuration","description":"Configure your Tarko Agent"},"version":""},{"title":"Event Stream","content":"#\n\nTarko is built on an event-driven architecture where all Agent interactions are\nrepresented as events in a stream. This enables powerful capabilities like\nreal-time monitoring, debugging, and context management.\n\n\nEvent Types#\n\nTarko defines several core event types:\n\n\nUser Events#\n\n{\n  type: 'user_message',\n  data: {\n    content: 'Hello, can you help me?',\n    timestamp: '2025-01-01T00:00:00Z'\n  }\n}\n\n\n\nAgent Events#\n\n{\n  type: 'agent_message',\n  data: {\n    content: 'I\\'d be happy to help!',\n    timestamp: '2025-01-01T00:00:01Z'\n  }\n}\n\n\n\nTool Events#\n\n{\n  type: 'tool_call',\n  data: {\n    name: 'search',\n    parameters: { query: 'weather today' },\n    timestamp: '2025-01-01T00:00:02Z'\n  }\n}\n\n{\n  type: 'tool_result',\n  data: {\n    name: 'search',\n    result: { temperature: 72, condition: 'sunny' },\n    timestamp: '2025-01-01T00:00:03Z'\n  }\n}\n\n\n\nSystem Events#\n\n{\n  type: 'context_updated',\n  data: {\n    reason: 'compression',\n    newLength: 8000,\n    timestamp: '2025-01-01T00:00:04Z'\n  }\n}\n\n\n\nListening to Events#\n\nSubscribe to events from your Agent:\n\n\n\nconst agent = new Agent(config);\n\n// Listen to all events\nagent.on('event', (event) => {\n  console.log('Event:', event.type, event.data);\n});\n\n// Listen to specific event types\nagent.on('tool_call', (event) => {\n  console.log('Tool called:', event.data.name);\n});\n\nagent.on('agent_message', (event) => {\n  console.log('Agent response:', event.data.content);\n});\n\n\n\nEvent Stream Processing#\n\nProcess events in real-time:\n\nconst eventProcessor = {\n  async processEvent(event) {\n    switch (event.type) {\n      case 'tool_call':\n        // Log tool usage\n        await logToolUsage(event.data);\n        break;\n        \n      case 'agent_message':\n        // Update UI\n        await updateUI(event.data.content);\n        break;\n        \n      case 'error':\n        // Handle errors\n        await handleError(event.data);\n        break;\n    }\n  }\n};\n\nagent.on('event', eventProcessor.processEvent);\n\n\n\nServer-Sent Events (SSE)#\n\nFor web applications, events can be streamed via SSE:\n\n// Server\napp.get('/agent/stream', (req, res) => {\n  res.writeHead(200, {\n    'Content-Type': 'text/event-stream',\n    'Cache-Control': 'no-cache',\n    'Connection': 'keep-alive'\n  });\n\n  agent.on('event', (event) => {\n    res.write(`data: ${JSON.stringify(event)}\\n\\n`);\n  });\n});\n\n\n// Client\nconst eventSource = new EventSource('/agent/stream');\n\neventSource.onmessage = (event) => {\n  const agentEvent = JSON.parse(event.data);\n  handleAgentEvent(agentEvent);\n};\n\n\n\nEvent Persistence#\n\nEvents can be persisted for replay and analysis:\n\nconst agent = new Agent({\n  ...config,\n  persistence: {\n    enabled: true,\n    storage: 'file', // or 'redis', 'mongodb'\n    path: './agent-events.jsonl'\n  }\n});\n\n\n\nEvent Filtering#\n\nFilter events based on criteria:\n\nagent.on('event', (event) => {\n  // Only process tool-related events\n  if (event.type.startsWith('tool_')) {\n    processToolEvent(event);\n  }\n});\n","routePath":"/guide/basic/event-stream","lang":"en","toc":[{"text":"Event Types","id":"event-types","depth":2,"charIndex":216},{"text":"User Events","id":"user-events","depth":3,"charIndex":272},{"text":"Agent Events","id":"agent-events","depth":3,"charIndex":409},{"text":"Tool Events","id":"tool-events","depth":3,"charIndex":547},{"text":"System Events","id":"system-events","depth":3,"charIndex":858},{"text":"Listening to Events","id":"listening-to-events","depth":2,"charIndex":1008},{"text":"Event Stream Processing","id":"event-stream-processing","depth":2,"charIndex":1435},{"text":"Server-Sent Events (SSE)","id":"server-sent-events-sse","depth":2,"charIndex":1967},{"text":"Event Persistence","id":"event-persistence","depth":2,"charIndex":2518},{"text":"Event Filtering","id":"event-filtering","depth":2,"charIndex":2753}],"frontmatter":{"title":"Event Stream","description":"Understanding Tarko's event-driven architecture"},"version":""},{"title":"Model Provider","content":"#\n\nTarko follows the OpenAI Compatible protocol to connect to any LLM provider,\nincluding Volcengine, OpenAI, Anthropic, Gemini, and more.\n\n\nConfiguration#\n\nConfigure your model provider in the Agent configuration:\n\n\n\nconst agent = new Agent({\n  model: {\n    provider: 'openai',\n    apiKey: process.env.OPENAI_API_KEY,\n    model: 'gpt-4'\n  }\n});\n\n\n\nSupported Providers#\n\n\nOpenAI#\n\n{\n  provider: 'openai',\n  apiKey: 'your-api-key',\n  model: 'gpt-4'\n}\n\n\n\nAnthropic#\n\n{\n  provider: 'anthropic',\n  apiKey: 'your-api-key',\n  model: 'claude-3-sonnet'\n}\n\n\n\nVolcengine#\n\n{\n  provider: 'volcengine',\n  apiKey: 'your-api-key',\n  model: 'doubao-pro'\n}\n\n\n\nCustom Provider#\n\nYou can also use any OpenAI-compatible endpoint:\n\n{\n  provider: 'custom',\n  baseURL: 'https://your-endpoint.com/v1',\n  apiKey: 'your-api-key',\n  model: 'your-model'\n}\n","routePath":"/guide/basic/model-provider","lang":"en","toc":[{"text":"Configuration","id":"configuration","depth":2,"charIndex":140},{"text":"Supported Providers","id":"supported-providers","depth":2,"charIndex":348},{"text":"OpenAI","id":"openai","depth":3,"charIndex":371},{"text":"Anthropic","id":"anthropic","depth":3,"charIndex":452},{"text":"Volcengine","id":"volcengine","depth":3,"charIndex":549},{"text":"Custom Provider","id":"custom-provider","depth":2,"charIndex":643}],"frontmatter":{"title":"Model Provider","description":"Connect to different LLM providers with Tarko"},"version":""},{"title":"Tool Call Engine","content":"#\n\nTarko's Tool Call Engine determines how the Agent processes and executes tool\ncalls. Different engines provide compatibility with various LLM providers and\nuse cases.\n\n\nOverview#\n\nThe Tool Call Engine handles:\n\n * Function Call Parsing: How tool calls are extracted from LLM responses\n * Provider Compatibility: Works with models that have different tool calling\n   capabilities\n * Execution Strategy: How tools are invoked and results processed\n * Error Handling: Managing failed tool calls and retries\n\n\nAvailable Engine Types#\n\nBased on the actual ToolCallEngineType from the source code:\n\n\n1. Native Engine#\n\nBest for: Models with native function calling support (GPT-4, Claude 3.5, etc.)\n\n\n\nconst agent = new Agent({\n  toolCallEngine: 'native',\n  model: {\n    provider: 'openai',\n    id: 'gpt-4o',\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n  tools: [weatherTool],\n});\n\n\nHow it works:\n\n * Uses the model's built-in function calling capabilities\n * Sends tools as function definitions in the API request\n * Parses structured function call responses\n * Most reliable and efficient for supported models\n\n\n2. Prompt Engineering Engine#\n\nBest for: Models without native function calling or custom parsing needs\n\nconst agent = new Agent({\n  toolCallEngine: 'prompt_engineering',\n  model: {\n    provider: 'volcengine', \n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  tools: [weatherTool],\n});\n\n\nHow it works:\n\n * Embeds tool descriptions in the system prompt\n * Instructs the model to output tool calls in a specific format\n * Parses tool calls from the text response using regex/patterns\n * Provides fallback compatibility for any text-based model\n\n\n3. Structured Outputs Engine#\n\nBest for: Models that support structured output but not function calling\n\nconst agent = new Agent({\n  toolCallEngine: 'structured_outputs',\n  model: {\n    provider: 'anthropic',\n    id: 'claude-3-5-sonnet-20241022', \n    apiKey: process.env.ANTHROPIC_API_KEY,\n  },\n  tools: [weatherTool],\n});\n\n\nHow it works:\n\n * Uses structured output schemas to enforce tool call format\n * More reliable than prompt engineering for parsing\n * Reduces parsing errors and improves consistency\n * Works with models that support JSON schema constraints\n\n\nEngine Selection Guide#\n\n\nAutomatic Selection#\n\nTarko can automatically select the best engine for your model:\n\n// Tarko will choose the optimal engine based on the model provider\nconst agent = new Agent({\n  // toolCallEngine not specified - auto-selected\n  model: {\n    provider: 'openai',\n    id: 'gpt-4o',\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n  tools: [weatherTool],\n});\n\n\n\nManual Selection#\n\nChoose explicitly based on your needs:\n\n// Force prompt engineering for custom control\nconst agent = new Agent({\n  toolCallEngine: 'prompt_engineering',\n  model: {\n    provider: 'openai', // Even for OpenAI, use prompt engineering\n    id: 'gpt-4o',\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n  tools: [weatherTool],\n});\n\n\n\nEngine Comparison#\n\nENGINE               RELIABILITY   PERFORMANCE   COMPATIBILITY   USE CASE\nnative               â­â­â­â­â­         â­â­â­â­â­         â­â­â­             Production with supported models\nstructured_outputs   â­â­â­â­          â­â­â­â­          â­â­â­â­            Models with schema support\nprompt_engineering   â­â­â­           â­â­â­           â­â­â­â­â­           Universal compatibility\n\n\nReal Examples from Source Code#\n\n\nBasic Tool Call Engine Usage#\n\nFrom multimodal/tarko/agent/examples/tool-calls/basic.ts:\n\n\n\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  tools: [locationTool, weatherTool],\n  logLevel: LogLevel.DEBUG,\n  // toolCallEngine will be auto-selected based on model capabilities\n});\n\n\n\nStreaming with Tool Call Engine#\n\nFrom multimodal/tarko/agent/examples/streaming/tool-calls.ts:\n\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  tools: [locationTool, weatherTool],\n  toolCallEngine: 'native',\n  enableStreamingToolCallEvents: true,\n});\n\n\n\nDebugging Tool Call Engines#\n\n\nEnable Debug Logging#\n\n\n\nconst agent = new Agent({\n  toolCallEngine: 'prompt_engineering',\n  logLevel: LogLevel.DEBUG, // See detailed tool call parsing\n  tools: [weatherTool],\n});\n\n\n\nMonitor Tool Call Events#\n\nconst response = await agent.run({\n  input: \"What's the weather?\",\n  stream: true,\n});\n\nfor await (const event of response) {\n  if (event.type === 'tool_call') {\n    console.log('Tool called:', event.toolCall.function.name);\n  }\n  if (event.type === 'tool_result') {\n    console.log('Tool result:', event.result);\n  }\n}\n\n\n\nTroubleshooting#\n\n\nCommon Issues#\n\nTool calls not being detected:\n\n * Check if the model supports the selected engine type\n * Try switching to prompt_engineering for broader compatibility\n * Verify tool descriptions are clear and specific\n\nParsing errors with prompt engineering:\n\n * The model may not be following the expected format\n * Try structured_outputs if the model supports schemas\n * Simplify tool parameter schemas\n\nPerformance issues:\n\n * native engine is fastest for supported models\n * prompt_engineering adds parsing overhead\n * Consider caching for expensive tool operations\n\n\nEngine Selection Decision Tree#\n\nDoes your model support native function calling?\nâ”œâ”€ Yes â†’ Use 'native' (recommended)\nâ””â”€ No\n   â”œâ”€ Does it support structured outputs?\n   â”‚  â”œâ”€ Yes â†’ Use 'structured_outputs'\n   â”‚  â””â”€ No â†’ Use 'prompt_engineering'\n   â””â”€ Need custom parsing logic?\n      â””â”€ Consider implementing custom engine\n\n\n\nNext Steps#\n\n * Tools - Learn how to create tools\n * Configuration - Configure tool call engines\n * Event Stream - Monitor tool call events","routePath":"/guide/basic/tool-call-engine","lang":"en","toc":[{"text":"Overview","id":"overview","depth":2,"charIndex":171},{"text":"Available Engine Types","id":"available-engine-types","depth":2,"charIndex":508},{"text":"1. Native Engine","id":"1-native-engine","depth":3,"charIndex":596},{"text":"2. Prompt Engineering Engine","id":"2-prompt-engineering-engine","depth":3,"charIndex":1111},{"text":"3. Structured Outputs Engine","id":"3-structured-outputs-engine","depth":3,"charIndex":1685},{"text":"Engine Selection Guide","id":"engine-selection-guide","depth":2,"charIndex":2252},{"text":"Automatic Selection","id":"automatic-selection","depth":3,"charIndex":2278},{"text":"Manual Selection","id":"manual-selection","depth":3,"charIndex":2637},{"text":"Engine Comparison","id":"engine-comparison","depth":2,"charIndex":2981},{"text":"Real Examples from Source Code","id":"real-examples-from-source-code","depth":2,"charIndex":3356},{"text":"Basic Tool Call Engine Usage","id":"basic-tool-call-engine-usage","depth":3,"charIndex":3390},{"text":"Streaming with Tool Call Engine","id":"streaming-with-tool-call-engine","depth":3,"charIndex":3767},{"text":"Debugging Tool Call Engines","id":"debugging-tool-call-engines","depth":2,"charIndex":4118},{"text":"Enable Debug Logging","id":"enable-debug-logging","depth":3,"charIndex":4149},{"text":"Monitor Tool Call Events","id":"monitor-tool-call-events","depth":3,"charIndex":4333},{"text":"Troubleshooting","id":"troubleshooting","depth":2,"charIndex":4683},{"text":"Common Issues","id":"common-issues","depth":3,"charIndex":4702},{"text":"Engine Selection Decision Tree","id":"engine-selection-decision-tree","depth":3,"charIndex":5276},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":5602}],"frontmatter":{"title":"Tool Call Engine","description":"Understanding Tarko's Tool Call Engine types and selection"},"version":""},{"title":"Tools","content":"#\n\nTools are the core capabilities that enable your Agent to interact with the\nexternal world. Tarko uses the Tool class to define structured function calls\nwith type-safe parameters.\n\n\nTool Definition#\n\nBased on the actual Tool class from\nmultimodal/tarko/agent-interface/src/tool.ts:\n\n\n\nconst tool = new Tool({\n  id: string,                     // Unique tool identifier\n  description: string,            // What the tool does\n  parameters: ZodSchema,          // Zod schema for parameters\n  function: (input) => any        // Implementation function\n});\n\n\n\nReal Examples from Source Code#\n\n\nLocation Tool#\n\nFrom multimodal/tarko/agent/examples/tool-calls/basic.ts:\n\nconst locationTool = new Tool({\n  id: 'getCurrentLocation',\n  description: \"Get user's current location\",\n  parameters: z.object({}),\n  function: async () => {\n    return { location: 'Boston' };\n  },\n});\n\n\n\nWeather Tool#\n\nFrom multimodal/tarko/agent/examples/tool-calls/basic.ts:\n\nconst weatherTool = new Tool({\n  id: 'getWeather',\n  description: 'Get weather information for a specified location',\n  parameters: z.object({\n    location: z.string().describe('Location name, such as city name'),\n  }),\n  function: async (input) => {\n    const { location } = input;\n    return {\n      location,\n      temperature: '70Â°F (21Â°C)',\n      condition: 'Sunny',\n      precipitation: '10%',\n      humidity: '45%',\n      wind: '5 mph',\n    };\n  },\n});\n\n\n\nCreating Custom Tools#\n\n\nSimple Tool#\n\nconst calculatorTool = new Tool({\n  id: 'calculate',\n  description: 'Perform basic mathematical calculations',\n  parameters: z.object({\n    expression: z.string().describe('Mathematical expression like \"2 + 2\"'),\n  }),\n  function: async ({ expression }) => {\n    // Simple evaluation (use a proper math library in production)\n    try {\n      const result = Function(`\"use strict\"; return (${expression})`)();\n      return { result, expression };\n    } catch (error) {\n      return { error: 'Invalid expression', expression };\n    }\n  },\n});\n\n\n\nFile System Tool#\n\nconst readFileTool = new Tool({\n  id: 'readFile',\n  description: 'Read contents of a text file',\n  parameters: z.object({\n    path: z.string().describe('File path to read'),\n    encoding: z.string().default('utf8').describe('File encoding'),\n  }),\n  function: async ({ path, encoding }) => {\n    const fs = await import('fs/promises');\n    try {\n      const content = await fs.readFile(path, encoding);\n      return { content, path, size: content.length };\n    } catch (error) {\n      return { error: error.message, path };\n    }\n  },\n});\n\n\n\nHTTP Request Tool#\n\nconst httpTool = new Tool({\n  id: 'httpRequest',\n  description: 'Make HTTP requests to APIs',\n  parameters: z.object({\n    url: z.string().url().describe('URL to request'),\n    method: z.enum(['GET', 'POST', 'PUT', 'DELETE']).default('GET'),\n    headers: z.record(z.string()).optional().describe('HTTP headers'),\n    body: z.string().optional().describe('Request body (JSON string)'),\n  }),\n  function: async ({ url, method, headers, body }) => {\n    try {\n      const response = await fetch(url, {\n        method,\n        headers: {\n          'Content-Type': 'application/json',\n          ...headers,\n        },\n        body: body ? JSON.stringify(JSON.parse(body)) : undefined,\n      });\n      \n      const responseBody = await response.text();\n      return {\n        status: response.status,\n        statusText: response.statusText,\n        headers: Object.fromEntries(response.headers),\n        body: responseBody,\n      };\n    } catch (error) {\n      return { error: error.message, url };\n    }\n  },\n});\n\n\n\nUsing Tools with Agent#\n\n\n\n// Define your tools\nconst tools = [locationTool, weatherTool, calculatorTool];\n\n// Create agent with tools\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  tools,\n  logLevel: LogLevel.DEBUG,\n});\n\n// Run agent with tools\nconst response = await agent.run('What is 15 * 23 and what\\'s the weather like?');\nconsole.log(response);\n\n\n\nTool Call Engines#\n\nTarko supports different tool call engines:\n\nconst agent = new Agent({\n  tools: [weatherTool],\n  toolCallEngine: 'native',              // Use model's native function calling\n  // or\n  toolCallEngine: 'prompt_engineering',  // Use prompt-based approach\n  // or  \n  toolCallEngine: 'structured_outputs',  // Use structured output parsing\n});\n\n\n\nError Handling in Tools#\n\nconst robustTool = new Tool({\n  id: 'robustOperation',\n  description: 'A tool that handles errors gracefully',\n  parameters: z.object({\n    input: z.string(),\n  }),\n  function: async ({ input }) => {\n    try {\n      // Your tool logic here\n      const result = await someOperation(input);\n      return { success: true, result };\n    } catch (error) {\n      // Return error information instead of throwing\n      return {\n        success: false,\n        error: error.message,\n        input,\n      };\n    }\n  },\n});\n\n\n\nTesting Tools#\n\nYou can test tools independently:\n\n// Test a tool directly\nconst result = await weatherTool.function({ location: 'Boston' });\nconsole.log('Tool result:', result);\n\n// Check tool schema\nconsole.log('Tool has Zod schema:', weatherTool.hasZodSchema());\nconsole.log('Tool has JSON schema:', weatherTool.hasJsonSchema());\n","routePath":"/guide/basic/tools","lang":"en","toc":[{"text":"Tool Definition","id":"tool-definition","depth":2,"charIndex":185},{"text":"Real Examples from Source Code","id":"real-examples-from-source-code","depth":2,"charIndex":559},{"text":"Location Tool","id":"location-tool","depth":3,"charIndex":593},{"text":"Weather Tool","id":"weather-tool","depth":3,"charIndex":875},{"text":"Creating Custom Tools","id":"creating-custom-tools","depth":2,"charIndex":1412},{"text":"Simple Tool","id":"simple-tool","depth":3,"charIndex":1437},{"text":"File System Tool","id":"file-system-tool","depth":3,"charIndex":1995},{"text":"HTTP Request Tool","id":"http-request-tool","depth":3,"charIndex":2556},{"text":"Using Tools with Agent","id":"using-tools-with-agent","depth":2,"charIndex":3588},{"text":"Tool Call Engines","id":"tool-call-engines","depth":2,"charIndex":4040},{"text":"Error Handling in Tools","id":"error-handling-in-tools","depth":2,"charIndex":4404},{"text":"Testing Tools","id":"testing-tools","depth":2,"charIndex":4946}],"frontmatter":{"title":"Tools","description":"Adding tools to your Tarko Agent"},"version":""},{"title":"Troubleshooting","content":"#\n\nCommon issues and solutions when working with Tarko Agents.\n\n\nInstallation Issues#\n\n\nNode.js Version#\n\nProblem: Installation fails with Node.js version errors.\n\nSolution: Ensure you're using Node.js 18 or later:\n\nnode --version  # Should be 18.0.0 or higher\nnpm --version   # Should be 8.0.0 or higher\n\n\n\nPackage Installation#\n\nProblem: npm install fails with dependency conflicts.\n\nSolution: Clear cache and reinstall:\n\nnpm cache clean --force\nrm -rf node_modules package-lock.json\nnpm install\n\n\n\nRuntime Issues#\n\n\nAgent Won't Start#\n\nProblem: Agent fails to start with configuration errors.\n\nSolution: Check your tarko.config.ts:\n\n// Ensure all required fields are present\nexport default defineConfig({\n  agent: {\n    name: 'MyAgent',        // Required\n    systemPrompt: '...',    // Required\n  },\n  modelProvider: {\n    provider: 'openai',     // Required\n    apiKey: process.env.OPENAI_API_KEY, // Required\n  },\n});\n\n\n\nAPI Key Issues#\n\nProblem: \"Invalid API key\" or authentication errors.\n\nSolution: Verify environment variables:\n\n# Check if API key is set\necho $OPENAI_API_KEY\n\n# Set API key if missing\nexport OPENAI_API_KEY=\"your-api-key-here\"\n\n\n\nPort Already in Use#\n\nProblem: \"Port 3000 is already in use\" error.\n\nSolution: Use a different port:\n\n# Option 1: Kill existing process\nlsof -ti:3000 | xargs kill -9\n\n# Option 2: Use different port\nAGENT_PORT=3001 tarko run\n\n\n\nTool Issues#\n\n\nTool Not Found#\n\nProblem: \"Tool 'xyz' not found\" error.\n\nSolution: Ensure tool is properly registered:\n\n\n\nexport default defineConfig({\n  tools: [\n    searchTool(),  // Make sure tool is included\n  ],\n});\n\n\n\nBrowser Tool Issues#\n\nProblem: Browser tool fails to launch.\n\nSolution: Install browser dependencies:\n\n# For Ubuntu/Debian\nsudo apt-get install -y chromium-browser\n\n# For macOS\nbrew install chromium\n\n# Or use headless mode\nBROWSER_HEADLESS=true tarko run\n\n\n\nFile System Permissions#\n\nProblem: File system tool can't access files.\n\nSolution: Check file permissions and workspace configuration:\n\nexport default defineConfig({\n  tools: [\n    fileSystemTool({\n      allowedPaths: ['/path/to/workspace'],  // Specify allowed paths\n      readonly: false,                       // Allow write operations\n    }),\n  ],\n});\n\n\n\nPerformance Issues#\n\n\nSlow Response Times#\n\nProblem: Agent responses are very slow.\n\nSolution: Optimize configuration:\n\nexport default defineConfig({\n  modelProvider: {\n    provider: 'openai',\n    model: 'gpt-4o-mini',  // Use faster model\n    temperature: 0.1,      // Lower temperature for faster responses\n    maxTokens: 1000,       // Limit response length\n  },\n  agent: {\n    maxIterations: 5,      // Limit thinking loops\n    timeout: 30000,        // 30 second timeout\n  },\n});\n\n\n\nMemory Usage#\n\nProblem: High memory consumption.\n\nSolution: Configure context limits:\n\nexport default defineConfig({\n  agent: {\n    maxContextLength: 8000,    // Limit context size\n    contextStrategy: 'sliding', // Use sliding window\n  },\n});\n\n\n\nDevelopment Issues#\n\n\nHot Reload Not Working#\n\nProblem: Changes don't trigger reload in development mode.\n\nSolution: Check file watching:\n\n# Increase file watch limit (Linux)\necho fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf\nsudo sysctl -p\n\n# Restart development server\nnpm run dev\n\n\n\nTypeScript Errors#\n\nProblem: TypeScript compilation errors.\n\nSolution: Check tsconfig.json and dependencies:\n\n# Install type definitions\nnpm install --save-dev @types/node\n\n# Check TypeScript version\nnpx tsc --version\n\n# Compile manually to see errors\nnpx tsc --noEmit\n\n\n\nDebugging#\n\n\nEnable Debug Logging#\n\n# Set log level to debug\nAGENT_LOG_LEVEL=debug tarko run\n\n# Or in configuration\nexport default defineConfig({\n  agent: {\n    logLevel: 'debug',\n  },\n});\n\n\n\nInspect Agent State#\n\n\n\nexport default defineConfig({\n  hooks: {\n    onBeforeToolCall: (context) => {\n      console.log('Tool call:', context.toolName, context.args);\n    },\n    onAfterToolCall: (context) => {\n      console.log('Tool result:', context.result);\n    },\n  },\n});\n\n\n\nNetwork Issues#\n\n# Test API connectivity\ncurl -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n     https://api.openai.com/v1/models\n\n# Check proxy settings\necho $HTTP_PROXY\necho $HTTPS_PROXY\n\n\n\nGetting Help#\n\n\nLog Files#\n\nCheck log files for detailed error information:\n\n# Default log location\ntail -f ~/.tarko/logs/agent.log\n\n# Or custom log location\ntail -f ./logs/tarko.log\n\n\n\nCommon Error Codes#\n\nERROR CODE     DESCRIPTION             SOLUTION\nECONNREFUSED   Connection refused      Check network/API endpoint\nENOTFOUND      DNS resolution failed   Check internet connection\nEACCES         Permission denied       Check file/directory permissions\nEMFILE         Too many open files     Increase file descriptor limit\n\n\nCommunity Support#\n\n * GitHub Issues\n * Documentation\n * Discord Community\n\n\nNext Steps#\n\nIf you're still experiencing issues:\n\n 1. Check the Configuration Guide\n 2. Review Agent Hooks for debugging\n 3. Explore Agent Hooks for debugging","routePath":"/guide/basic/troubleshooting","lang":"en","toc":[{"text":"Installation Issues","id":"installation-issues","depth":2,"charIndex":64},{"text":"Node.js Version","id":"nodejs-version","depth":3,"charIndex":87},{"text":"Package Installation","id":"package-installation","depth":3,"charIndex":307},{"text":"Runtime Issues","id":"runtime-issues","depth":2,"charIndex":500},{"text":"Agent Won't Start","id":"agent-wont-start","depth":3,"charIndex":518},{"text":"API Key Issues","id":"api-key-issues","depth":3,"charIndex":926},{"text":"Port Already in Use","id":"port-already-in-use","depth":3,"charIndex":1156},{"text":"Tool Issues","id":"tool-issues","depth":2,"charIndex":1383},{"text":"Tool Not Found","id":"tool-not-found","depth":3,"charIndex":1398},{"text":"Browser Tool Issues","id":"browser-tool-issues","depth":3,"charIndex":1606},{"text":"File System Permissions","id":"file-system-permissions","depth":3,"charIndex":1864},{"text":"Performance Issues","id":"performance-issues","depth":2,"charIndex":2223},{"text":"Slow Response Times","id":"slow-response-times","depth":3,"charIndex":2245},{"text":"Memory Usage","id":"memory-usage","depth":3,"charIndex":2711},{"text":"Development Issues","id":"development-issues","depth":2,"charIndex":2958},{"text":"Hot Reload Not Working","id":"hot-reload-not-working","depth":3,"charIndex":2980},{"text":"TypeScript Errors","id":"typescript-errors","depth":3,"charIndex":3264},{"text":"Debugging","id":"debugging","depth":2,"charIndex":3536},{"text":"Enable Debug Logging","id":"enable-debug-logging","depth":3,"charIndex":3549},{"text":"Inspect Agent State","id":"inspect-agent-state","depth":3,"charIndex":3728},{"text":"Network Issues","id":"network-issues","depth":3,"charIndex":4008},{"text":"Getting Help","id":"getting-help","depth":2,"charIndex":4199},{"text":"Log Files","id":"log-files","depth":3,"charIndex":4215},{"text":"Common Error Codes","id":"common-error-codes","depth":3,"charIndex":4385},{"text":"Community Support","id":"community-support","depth":3,"charIndex":4729},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":4806}],"frontmatter":{"title":"Troubleshooting","description":"Common issues and solutions for Tarko agents"},"version":""},{"title":"UI Integration","content":"#\n\nTarko provides flexible UI integration options to build user interfaces for your\nagents using modern web technologies.\n\n\nIntegration Options#\n\n\n1. Tarko Agent UI (Recommended)#\n\nThe official web UI implementation that works out-of-the-box with any Tarko\nAgent:\n\nnpm install @tarko/agent-ui\n\n\nFeatures:\n\n * Real-time agent communication\n * Built-in chat interface\n * Tool execution visualization\n * Event stream monitoring\n * Responsive design\n\n\n2. Custom Web UI#\n\nBuild your own web interface using the Agent Protocol:\n\n\n\nconst client = new AgentClient({\n  endpoint: 'http://localhost:3000',\n});\n\n// Send message to agent\nconst response = await client.sendMessage('Hello, agent!');\n\n\n\n3. Native Applications#\n\nIntegrate with desktop or mobile applications using HTTP/WebSocket APIs.\n\n\nArchitecture Overview#\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Frontend UI   â”‚â—„â”€â”€â–ºâ”‚  Tarko Agent     â”‚â—„â”€â”€â–ºâ”‚  LLM Provider   â”‚\nâ”‚                 â”‚    â”‚  Server          â”‚    â”‚                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ â€¢ Chat Interfaceâ”‚    â”‚ â€¢ Agent Protocol â”‚    â”‚ â€¢ OpenAI        â”‚\nâ”‚ â€¢ Tool Outputs  â”‚    â”‚ â€¢ Event Stream   â”‚    â”‚ â€¢ Anthropic     â”‚\nâ”‚ â€¢ Real-time     â”‚    â”‚ â€¢ Tool Execution â”‚    â”‚ â€¢ Volcengine    â”‚\nâ”‚   Updates       â”‚    â”‚ â€¢ Context Mgmt   â”‚    â”‚ â€¢ Others        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\nQuick Start with Tarko Agent UI#\n\nThe fastest way to get a web UI for your agent:\n\n\n1. Install Dependencies#\n\nnpm install @tarko/agent-ui\n\n\n\n2. Basic Setup#\n\n\nimport '@tarko/agent-ui/styles.css';\n\nfunction App() {\n  return (\n    <AgentUI\n      endpoint=\"http://localhost:3000\"\n      title=\"My Agent\"\n      theme=\"light\"\n    />\n  );\n}\n\nexport default App;\n\n\n\n3. Start Your Agent Server#\n\ntarko run --server\n\n\nYour web UI will connect to the agent automatically!\n\n\nCommunication Protocols#\n\n\nHTTP API#\n\nRESTful API for basic agent interactions:\n\n// Send message\nPOST /api/chat\n{\n  \"message\": \"Hello, agent!\",\n  \"sessionId\": \"session-123\"\n}\n\n// Get session history\nGET /api/sessions/session-123/messages\n\n\n\nWebSocket#\n\nReal-time bidirectional communication:\n\nconst ws = new WebSocket('ws://localhost:3000/ws');\n\nws.onmessage = (event) => {\n  const data = JSON.parse(event.data);\n  console.log('Agent event:', data);\n};\n\n\n\nServer-Sent Events (SSE)#\n\nStreaming responses for real-time updates:\n\nconst eventSource = new EventSource('/api/stream/session-123');\n\neventSource.onmessage = (event) => {\n  const data = JSON.parse(event.data);\n  console.log('Stream update:', data);\n};\n\n\n\nEvent Stream#\n\nTarko uses a standardized event stream format for real-time communication:\n\ninterface AgentEvent {\n  type: 'message' | 'tool_call' | 'tool_result' | 'thinking' | 'error';\n  timestamp: string;\n  sessionId: string;\n  data: any;\n}\n\n\n\nEvent Types#\n\nEVENT TYPE    DESCRIPTION                DATA\nmessage       Agent response message     { content: string, role: 'assistant' }\ntool_call     Tool execution started     { name: string, args: object }\ntool_result   Tool execution completed   { result: any, success: boolean }\nthinking      Agent reasoning process    { content: string }\nerror         Error occurred             { message: string, code?: string }\n\n\nCustom Web UI Development#\n\n\nReact Integration#\n\nBuild a custom React interface:\n\n\n\n\nconst CustomAgentUI = () => {\n  const [client] = useState(() => new AgentClient({\n    endpoint: 'http://localhost:3000'\n  }));\n  const [messages, setMessages] = useState([]);\n  const [input, setInput] = useState('');\n  const [loading, setLoading] = useState(false);\n\n  const sendMessage = async () => {\n    if (!input.trim()) return;\n    \n    setLoading(true);\n    const userMessage = { role: 'user', content: input };\n    setMessages(prev => [...prev, userMessage]);\n    setInput('');\n\n    try {\n      const response = await client.sendMessage(input);\n      const assistantMessage = { role: 'assistant', content: response.content };\n      setMessages(prev => [...prev, assistantMessage]);\n    } catch (error) {\n      console.error('Error sending message:', error);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"agent-ui\">\n      <div className=\"messages\">\n        {messages.map((msg, idx) => (\n          <div key={idx} className={`message ${msg.role}`}>\n            {msg.content}\n          </div>\n        ))}\n      </div>\n      <div className=\"input-area\">\n        <input\n          value={input}\n          onChange={(e) => setInput(e.target.value)}\n          onKeyPress={(e) => e.key === 'Enter' && sendMessage()}\n          placeholder=\"Type your message...\"\n          disabled={loading}\n        />\n        <button onClick={sendMessage} disabled={loading}>\n          {loading ? 'Sending...' : 'Send'}\n        </button>\n      </div>\n    </div>\n  );\n};\n\n\n\nVue.js Integration#\n\n<template>\n  <div class=\"agent-ui\">\n    <div class=\"messages\">\n      <div\n        v-for=\"(message, index) in messages\"\n        :key=\"index\"\n        :class=\"`message ${message.role}`\"\n      >\n        {{ message.content }}\n      </div>\n    </div>\n    <div class=\"input-area\">\n      <input\n        v-model=\"input\"\n        @keyup.enter=\"sendMessage\"\n        placeholder=\"Type your message...\"\n        :disabled=\"loading\"\n      />\n      <button @click=\"sendMessage\" :disabled=\"loading\">\n        {{ loading ? 'Sending...' : 'Send' }}\n      </button>\n    </div>\n  </div>\n</template>\n\n<script>\n\n\nexport default {\n  data() {\n    return {\n      client: new AgentClient({ endpoint: 'http://localhost:3000' }),\n      messages: [],\n      input: '',\n      loading: false\n    };\n  },\n  methods: {\n    async sendMessage() {\n      if (!this.input.trim()) return;\n      \n      this.loading = true;\n      this.messages.push({ role: 'user', content: this.input });\n      const message = this.input;\n      this.input = '';\n\n      try {\n        const response = await this.client.sendMessage(message);\n        this.messages.push({ role: 'assistant', content: response.content });\n      } catch (error) {\n        console.error('Error:', error);\n      } finally {\n        this.loading = false;\n      }\n    }\n  }\n};\n</script>\n\n\n\nReal-time Features#\n\n\nWebSocket Connection#\n\nImplement real-time communication:\n\nclass AgentWebSocket {\n  private ws: WebSocket;\n  private eventHandlers: Map<string, Function[]> = new Map();\n\n  constructor(endpoint: string) {\n    this.ws = new WebSocket(endpoint.replace('http', 'ws') + '/ws');\n    this.setupEventHandlers();\n  }\n\n  private setupEventHandlers() {\n    this.ws.onmessage = (event) => {\n      const data = JSON.parse(event.data);\n      const handlers = this.eventHandlers.get(data.type) || [];\n      handlers.forEach(handler => handler(data));\n    };\n\n    this.ws.onopen = () => {\n      console.log('WebSocket connected');\n    };\n\n    this.ws.onclose = () => {\n      console.log('WebSocket disconnected');\n      // Implement reconnection logic\n    };\n  }\n\n  on(eventType: string, handler: Function) {\n    if (!this.eventHandlers.has(eventType)) {\n      this.eventHandlers.set(eventType, []);\n    }\n    this.eventHandlers.get(eventType)!.push(handler);\n  }\n\n  sendMessage(message: string) {\n    this.ws.send(JSON.stringify({ type: 'message', content: message }));\n  }\n}\n\n// Usage\nconst agentWS = new AgentWebSocket('http://localhost:3000');\n\nagentWS.on('message', (data) => {\n  console.log('Received message:', data.content);\n});\n\nagentWS.on('tool_call', (data) => {\n  console.log('Tool called:', data.name, data.args);\n});\n\nagentWS.on('tool_result', (data) => {\n  console.log('Tool result:', data.result);\n});\n\n\n\nServer-Sent Events#\n\nAlternative approach using SSE:\n\nclass AgentEventSource {\n  private eventSource: EventSource;\n  private sessionId: string;\n\n  constructor(endpoint: string, sessionId: string) {\n    this.sessionId = sessionId;\n    this.eventSource = new EventSource(`${endpoint}/api/stream/${sessionId}`);\n    this.setupEventHandlers();\n  }\n\n  private setupEventHandlers() {\n    this.eventSource.onmessage = (event) => {\n      const data = JSON.parse(event.data);\n      this.handleEvent(data);\n    };\n\n    this.eventSource.onerror = (error) => {\n      console.error('SSE error:', error);\n    };\n  }\n\n  private handleEvent(data: any) {\n    switch (data.type) {\n      case 'message':\n        this.onMessage(data);\n        break;\n      case 'tool_call':\n        this.onToolCall(data);\n        break;\n      case 'tool_result':\n        this.onToolResult(data);\n        break;\n    }\n  }\n\n  onMessage(data: any) {\n    // Override in subclass or pass callback\n  }\n\n  onToolCall(data: any) {\n    // Override in subclass or pass callback\n  }\n\n  onToolResult(data: any) {\n    // Override in subclass or pass callback\n  }\n\n  close() {\n    this.eventSource.close();\n  }\n}\n\n\n\nUI Components#\n\n\nChat Interface#\n\nBasic chat component structure:\n\ninterface ChatMessage {\n  id: string;\n  role: 'user' | 'assistant';\n  content: string;\n  timestamp: Date;\n  toolCalls?: ToolCall[];\n}\n\ninterface ToolCall {\n  id: string;\n  name: string;\n  args: object;\n  result?: any;\n  status: 'pending' | 'success' | 'error';\n}\n\n\n\nTool Execution Visualization#\n\n\n\ninterface ToolExecutionProps {\n  toolCall: {\n    name: string;\n    args: object;\n    result?: any;\n    status: 'pending' | 'success' | 'error';\n    startTime: Date;\n    endTime?: Date;\n  };\n}\n\nconst ToolExecution: React.FC<ToolExecutionProps> = ({ toolCall }) => {\n  const duration = toolCall.endTime \n    ? toolCall.endTime.getTime() - toolCall.startTime.getTime()\n    : null;\n\n  return (\n    <div className={`tool-execution ${toolCall.status}`}>\n      <div className=\"tool-header\">\n        <span className=\"tool-name\">{toolCall.name}</span>\n        <span className=\"tool-status\">{toolCall.status}</span>\n        {duration && (\n          <span className=\"tool-duration\">{duration}ms</span>\n        )}\n      </div>\n      \n      <details className=\"tool-args\">\n        <summary>Arguments</summary>\n        <pre>{JSON.stringify(toolCall.args, null, 2)}</pre>\n      </details>\n      \n      {toolCall.result && (\n        <details className=\"tool-result\">\n          <summary>Result</summary>\n          <pre>{JSON.stringify(toolCall.result, null, 2)}</pre>\n        </details>\n      )}\n    </div>\n  );\n};\n\n\n\nThinking Process Display#\n\nconst ThinkingProcess: React.FC<{ thoughts: string[] }> = ({ thoughts }) => {\n  return (\n    <div className=\"thinking-process\">\n      <div className=\"thinking-header\">\n        <span>ðŸ¤” Agent is thinking...</span>\n      </div>\n      <div className=\"thoughts\">\n        {thoughts.map((thought, idx) => (\n          <div key={idx} className=\"thought\">\n            {thought}\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n};\n\n\n\nStyling and Theming#\n\n\nCSS Variables#\n\n:root {\n  --agent-primary: #007bff;\n  --agent-secondary: #6c757d;\n  --agent-success: #28a745;\n  --agent-danger: #dc3545;\n  --agent-warning: #ffc107;\n  --agent-info: #17a2b8;\n  \n  --agent-bg: #ffffff;\n  --agent-text: #333333;\n  --agent-border: #e9ecef;\n  \n  --agent-message-user-bg: #007bff;\n  --agent-message-user-text: #ffffff;\n  --agent-message-assistant-bg: #f8f9fa;\n  --agent-message-assistant-text: #333333;\n}\n\n[data-theme=\"dark\"] {\n  --agent-bg: #1a1a1a;\n  --agent-text: #ffffff;\n  --agent-border: #333333;\n  \n  --agent-message-assistant-bg: #2d2d2d;\n  --agent-message-assistant-text: #ffffff;\n}\n\n\n\nComponent Styles#\n\n.agent-ui {\n  display: flex;\n  flex-direction: column;\n  height: 100vh;\n  background: var(--agent-bg);\n  color: var(--agent-text);\n}\n\n.messages {\n  flex: 1;\n  overflow-y: auto;\n  padding: 1rem;\n}\n\n.message {\n  margin-bottom: 1rem;\n  padding: 0.75rem 1rem;\n  border-radius: 0.5rem;\n  max-width: 80%;\n}\n\n.message.user {\n  background: var(--agent-message-user-bg);\n  color: var(--agent-message-user-text);\n  margin-left: auto;\n}\n\n.message.assistant {\n  background: var(--agent-message-assistant-bg);\n  color: var(--agent-message-assistant-text);\n}\n\n.input-area {\n  display: flex;\n  padding: 1rem;\n  border-top: 1px solid var(--agent-border);\n}\n\n.input-area input {\n  flex: 1;\n  padding: 0.75rem;\n  border: 1px solid var(--agent-border);\n  border-radius: 0.25rem;\n  margin-right: 0.5rem;\n}\n\n.input-area button {\n  padding: 0.75rem 1.5rem;\n  background: var(--agent-primary);\n  color: white;\n  border: none;\n  border-radius: 0.25rem;\n  cursor: pointer;\n}\n\n.input-area button:disabled {\n  opacity: 0.5;\n  cursor: not-allowed;\n}\n\n\n\nAuthentication & Security#\n\n\nAPI Keys#\n\nSecure API key authentication:\n\nconst client = new AgentClient({\n  endpoint: 'http://localhost:3000',\n  apiKey: process.env.TARKO_API_KEY,\n});\n\n\n\nSession Management#\n\nManage user sessions and context:\n\ninterface Session {\n  id: string;\n  userId?: string;\n  createdAt: Date;\n  lastActivity: Date;\n  context: AgentContext;\n}\n\n\n\nDeployment Considerations#\n\n\nCORS Configuration#\n\nFor web UIs, configure CORS in your agent server:\n\nexport default defineConfig({\n  server: {\n    cors: {\n      origin: ['http://localhost:3000', 'https://myapp.com'],\n      credentials: true,\n    },\n  },\n});\n\n\n\nReverse Proxy#\n\nUse a reverse proxy for production deployments:\n\nlocation /api/ {\n    proxy_pass http://localhost:3001/;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection 'upgrade';\n    proxy_set_header Host $host;\n    proxy_cache_bypass $http_upgrade;\n}\n\n\n\nEnvironment Configuration#\n\n// config.ts\nexport const config = {\n  apiEndpoint: process.env.REACT_APP_API_ENDPOINT || 'http://localhost:3000',\n  wsEndpoint: process.env.REACT_APP_WS_ENDPOINT || 'ws://localhost:3000',\n  apiKey: process.env.REACT_APP_API_KEY,\n};\n\n\n\nBuild and Deploy#\n\n# Build for production\nnpm run build\n\n# Deploy to static hosting\n# (Vercel, Netlify, AWS S3, etc.)\n\n\n\nDocker Deployment#\n\n# Dockerfile\nFROM node:18-alpine\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\n\nCOPY . .\nRUN npm run build\n\nFROM nginx:alpine\nCOPY --from=0 /app/build /usr/share/nginx/html\nCOPY nginx.conf /etc/nginx/nginx.conf\n\nEXPOSE 80\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n\n\n\nNext Steps#\n\n * Agent Protocol â†’\n * Event Stream â†’\n * Configuration â†’","routePath":"/guide/basic/ui-integration","lang":"en","toc":[{"text":"Integration Options","id":"integration-options","depth":2,"charIndex":123},{"text":"1. **Tarko Agent UI** (Recommended)","id":"1-tarko-agent-ui-recommended","depth":3,"charIndex":-1},{"text":"2. **Custom Web UI**","id":"2-custom-web-ui","depth":3,"charIndex":-1},{"text":"3. **Native Applications**","id":"3-native-applications","depth":3,"charIndex":-1},{"text":"Architecture Overview","id":"architecture-overview","depth":2,"charIndex":787},{"text":"Quick Start with Tarko Agent UI","id":"quick-start-with-tarko-agent-ui","depth":2,"charIndex":1417},{"text":"1. Install Dependencies","id":"1-install-dependencies","depth":3,"charIndex":1501},{"text":"2. Basic Setup","id":"2-basic-setup","depth":3,"charIndex":1558},{"text":"3. Start Your Agent Server","id":"3-start-your-agent-server","depth":3,"charIndex":1775},{"text":"Communication Protocols","id":"communication-protocols","depth":2,"charIndex":1880},{"text":"HTTP API","id":"http-api","depth":3,"charIndex":1907},{"text":"WebSocket","id":"websocket","depth":3,"charIndex":2121},{"text":"Server-Sent Events (SSE)","id":"server-sent-events-sse","depth":3,"charIndex":2336},{"text":"Event Stream","id":"event-stream","depth":2,"charIndex":2593},{"text":"Event Types","id":"event-types","depth":3,"charIndex":2839},{"text":"Custom Web UI Development","id":"custom-web-ui-development","depth":2,"charIndex":3265},{"text":"React Integration","id":"react-integration","depth":3,"charIndex":3294},{"text":"Vue.js Integration","id":"vuejs-integration","depth":3,"charIndex":4842},{"text":"Real-time Features","id":"real-time-features","depth":2,"charIndex":6167},{"text":"WebSocket Connection","id":"websocket-connection","depth":3,"charIndex":6189},{"text":"Server-Sent Events","id":"server-sent-events","depth":3,"charIndex":7594},{"text":"UI Components","id":"ui-components","depth":2,"charIndex":8759},{"text":"Chat Interface","id":"chat-interface","depth":3,"charIndex":8776},{"text":"Tool Execution Visualization","id":"tool-execution-visualization","depth":3,"charIndex":9092},{"text":"Thinking Process Display","id":"thinking-process-display","depth":3,"charIndex":10226},{"text":"Styling and Theming","id":"styling-and-theming","depth":2,"charIndex":10686},{"text":"CSS Variables","id":"css-variables","depth":3,"charIndex":10709},{"text":"Component Styles","id":"component-styles","depth":3,"charIndex":11330},{"text":"Authentication & Security","id":"authentication--security","depth":2,"charIndex":12374},{"text":"API Keys","id":"api-keys","depth":3,"charIndex":12403},{"text":"Session Management","id":"session-management","depth":3,"charIndex":12560},{"text":"Deployment Considerations","id":"deployment-considerations","depth":2,"charIndex":12740},{"text":"CORS Configuration","id":"cors-configuration","depth":3,"charIndex":12769},{"text":"Reverse Proxy","id":"reverse-proxy","depth":3,"charIndex":13001},{"text":"Environment Configuration","id":"environment-configuration","depth":3,"charIndex":13313},{"text":"Build and Deploy","id":"build-and-deploy","depth":3,"charIndex":13577},{"text":"Docker Deployment","id":"docker-deployment","depth":3,"charIndex":13698},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":13997}],"frontmatter":{"title":"UI Integration","description":"Build web interfaces for Tarko agents"},"version":""},{"title":"CLI Deployment","content":"#\n\nThe Tarko Agent CLI provides a simple way to deploy and run Tarko-based Agents\nin various environments. Use tarko run [agent] to create headless or headful\nAgent runtime environments.\n\n\nInstallation#\n\nInstall the Tarko CLI globally:\n\nnpm install -g @tarko/agent-cli\n\n\nOr use with npx:\n\nnpx @tarko/agent-cli run my-agent\n\n\n\nBasic Usage#\n\n\nRun an Agent#\n\n# Run agent in current directory\ntarko run\n\n# Run specific agent\ntarko run ./my-agent\n\n# Run with custom configuration\ntarko run --config ./custom-config.json\n\n\n\nDevelopment Mode#\n\n# Run in development mode with hot reload\ntarko run --dev\n\n# Run with debug logging\ntarko run --debug\n\n# Run with specific port\ntarko run --port 3001\n\n\n\nConfiguration#\n\n\nCLI Configuration File#\n\nCreate a tarko.config.js file:\n\nmodule.exports = {\n  name: 'MyAgent',\n  description: 'A helpful assistant',\n  \n  // Runtime configuration\n  runtime: {\n    port: 3000,\n    host: '0.0.0.0',\n    mode: 'production' // or 'development'\n  },\n  \n  // Model configuration\n  model: {\n    provider: 'openai',\n    apiKey: process.env.OPENAI_API_KEY,\n    model: 'gpt-4'\n  },\n  \n  // Tools\n  tools: [\n    '@tarko/tools/file-system',\n    '@tarko/tools/browser',\n    './custom-tools/weather'\n  ],\n  \n  // UI configuration\n  ui: {\n    enabled: true,\n    theme: 'default',\n    title: 'My Agent'\n  }\n};\n\n\n\nEnvironment Variables#\n\n# Model configuration\nexport TARKO_MODEL_PROVIDER=openai\nexport TARKO_MODEL_API_KEY=your-api-key\nexport TARKO_MODEL_NAME=gpt-4\n\n# Runtime configuration\nexport TARKO_PORT=3000\nexport TARKO_HOST=0.0.0.0\nexport TARKO_MODE=production\n\n# UI configuration\nexport TARKO_UI_ENABLED=true\nexport TARKO_UI_THEME=default\n\n\n\nDeployment Modes#\n\n\nHeadless Mode#\n\nRun without UI for API-only access:\n\ntarko run --headless\n\n\nConfiguration:\n\nmodule.exports = {\n  runtime: {\n    mode: 'headless',\n    api: {\n      enabled: true,\n      cors: true,\n      rateLimit: {\n        windowMs: 15 * 60 * 1000, // 15 minutes\n        max: 100 // limit each IP to 100 requests per windowMs\n      }\n    }\n  },\n  ui: {\n    enabled: false\n  }\n};\n\n\n\nHeadful Mode#\n\nRun with web UI:\n\ntarko run --ui\n\n\nConfiguration:\n\nmodule.exports = {\n  ui: {\n    enabled: true,\n    title: 'My Agent',\n    theme: 'default',\n    customization: {\n      logo: './assets/logo.png',\n      primaryColor: '#007bff',\n      layout: 'sidebar' // or 'topbar'\n    }\n  }\n};\n\n\n\nProduction Deployment#\n\n\nDocker#\n\nCreate a Dockerfile:\n\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json ./\nRUN npm ci --only=production\n\n# Copy agent code\nCOPY . .\n\n# Install Tarko CLI\nRUN npm install -g @tarko/agent-cli\n\nEXPOSE 3000\n\nCMD [\"tarko\", \"run\", \"--port\", \"3000\", \"--host\", \"0.0.0.0\"]\n\n\nBuild and run:\n\ndocker build -t my-agent .\ndocker run -p 3000:3000 -e OPENAI_API_KEY=your-key my-agent\n\n\n\nDocker Compose#\n\nversion: '3.8'\n\nservices:\n  agent:\n    build: .\n    ports:\n      - \"3000:3000\"\n    environment:\n      - TARKO_MODEL_PROVIDER=openai\n      - TARKO_MODEL_API_KEY=${OPENAI_API_KEY}\n      - TARKO_MODEL_NAME=gpt-4\n      - TARKO_MODE=production\n    volumes:\n      - ./data:/app/data\n    restart: unless-stopped\n\n  redis:\n    image: redis:alpine\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n    restart: unless-stopped\n\nvolumes:\n  redis_data:\n\n\n\nProcess Manager (PM2)#\n\n// ecosystem.config.js\nmodule.exports = {\n  apps: [{\n    name: 'my-agent',\n    script: 'tarko',\n    args: 'run --port 3000',\n    instances: 1,\n    autorestart: true,\n    watch: false,\n    max_memory_restart: '1G',\n    env: {\n      NODE_ENV: 'production',\n      TARKO_MODEL_PROVIDER: 'openai',\n      TARKO_MODEL_API_KEY: process.env.OPENAI_API_KEY\n    }\n  }]\n};\n\n\nDeploy:\n\nnpm install -g pm2\npm2 start ecosystem.config.js\npm2 save\npm2 startup\n\n\n\nMonitoring and Logging#\n\n\nHealth Checks#\n\n# Check agent status\ncurl http://localhost:3000/health\n\n# Check detailed status\ncurl http://localhost:3000/status\n\n\n\nLogging Configuration#\n\nmodule.exports = {\n  logging: {\n    level: 'info', // debug, info, warn, error\n    format: 'json', // json, text\n    output: {\n      console: true,\n      file: {\n        enabled: true,\n        path: './logs/agent.log',\n        maxSize: '10m',\n        maxFiles: 5\n      }\n    }\n  }\n};\n\n\n\nMetrics#\n\nEnable metrics collection:\n\nmodule.exports = {\n  metrics: {\n    enabled: true,\n    endpoint: '/metrics',\n    collectors: {\n      requests: true,\n      responses: true,\n      toolCalls: true,\n      errors: true\n    }\n  }\n};\n\n\n\nLoad Balancing#\n\n\nNginx Configuration#\n\nupstream tarko_agents {\n    server localhost:3000;\n    server localhost:3001;\n    server localhost:3002;\n}\n\nserver {\n    listen 80;\n    server_name my-agent.example.com;\n    \n    location / {\n        proxy_pass http://tarko_agents;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n\n\n\nTroubleshooting#\n\n\nCommon Issues#\n\nPort already in use:\n\n# Find process using port\nlsof -i :3000\n\n# Kill process\nkill -9 <PID>\n\n# Or use different port\ntarko run --port 3001\n\n\nPermission errors:\n\n# Run with sudo (not recommended)\nsudo tarko run\n\n# Or change port to non-privileged\ntarko run --port 8080\n\n\nMemory issues:\n\n# Increase Node.js memory limit\nNODE_OPTIONS=\"--max-old-space-size=4096\" tarko run\n\n\n\nDebug Mode#\n\n# Enable debug logging\nDEBUG=tarko:* tarko run --debug\n\n# Enable Node.js inspector\ntarko run --inspect\n\n# Enable verbose output\ntarko run --verbose\n","routePath":"/guide/deployment/cli","lang":"en","toc":[{"text":"Installation","id":"installation","depth":2,"charIndex":188},{"text":"Basic Usage","id":"basic-usage","depth":2,"charIndex":325},{"text":"Run an Agent","id":"run-an-agent","depth":3,"charIndex":340},{"text":"Development Mode","id":"development-mode","depth":3,"charIndex":517},{"text":"Configuration","id":"configuration","depth":2,"charIndex":689},{"text":"CLI Configuration File","id":"cli-configuration-file","depth":3,"charIndex":706},{"text":"Environment Variables","id":"environment-variables","depth":3,"charIndex":1319},{"text":"Deployment Modes","id":"deployment-modes","depth":2,"charIndex":1655},{"text":"Headless Mode","id":"headless-mode","depth":3,"charIndex":1675},{"text":"Headful Mode","id":"headful-mode","depth":3,"charIndex":2057},{"text":"Production Deployment","id":"production-deployment","depth":2,"charIndex":2354},{"text":"Docker","id":"docker","depth":3,"charIndex":2379},{"text":"Docker Compose","id":"docker-compose","depth":3,"charIndex":2784},{"text":"Process Manager (PM2)","id":"process-manager-pm2","depth":3,"charIndex":3264},{"text":"Monitoring and Logging","id":"monitoring-and-logging","depth":2,"charIndex":3733},{"text":"Health Checks","id":"health-checks","depth":3,"charIndex":3759},{"text":"Logging Configuration","id":"logging-configuration","depth":3,"charIndex":3892},{"text":"Metrics","id":"metrics","depth":3,"charIndex":4203},{"text":"Load Balancing","id":"load-balancing","depth":2,"charIndex":4439},{"text":"Nginx Configuration","id":"nginx-configuration","depth":3,"charIndex":4457},{"text":"Troubleshooting","id":"troubleshooting","depth":2,"charIndex":5098},{"text":"Common Issues","id":"common-issues","depth":3,"charIndex":5117},{"text":"Debug Mode","id":"debug-mode","depth":3,"charIndex":5505}],"frontmatter":{"title":"CLI Deployment","description":"Deploy Tarko Agents using the CLI"},"version":""},{"title":"Server","content":"#\n\nTarko Agent Server is a production-ready server component built on top of Tarko\nAgent Core. It provides session management, storage capabilities, and a\nstandardized HTTP/WebSocket API for agent interactions.\n\n\nInstallation#\n\nnpm install @tarko/agent-server\n\n\n\nQuick Start#\n\n\nUsing CLI#\n\nThe easiest way to start a server:\n\nnpx tarko serve my-agent.ts\n\n\n\nProgrammatic Usage#\n\n\n\n\nconst server = new AgentServer({\n  agent: myAgent,\n  port: 8888,\n  storage: {\n    type: 'sqlite',\n    path: '~/.tarko'\n  }\n});\n\nawait server.start();\nconsole.log('Server running on http://localhost:8888');\n\n\n\nCore Concepts#\n\n\nSession#\n\nRepresents a complete agent interaction context, containing:\n\n * Message history\n * Tool calls and results\n * Agent state information\n * Metadata (name, tags, timestamps)\n\n\nQuery#\n\nA single request executed within a session:\n\n * Text input\n * Multimodal content (text + images)\n * Streaming or non-streaming execution\n\n\nConfiguration#\n\n\nServer Options#\n\ninterface ServerConfig {\n  agent: Agent;\n  port?: number;\n  host?: string;\n  basePath?: string; // Default: '/api/v1'\n  cors?: CorsOptions;\n  storage?: StorageConfig;\n  auth?: AuthConfig;\n  sharing?: SharingConfig;\n}\n\n\n\nStorage Configuration#\n\ninterface StorageConfig {\n  type: 'memory' | 'file' | 'sqlite' | 'redis';\n  path?: string; // For file/sqlite storage\n  connectionString?: string; // For redis storage\n  options?: Record<string, any>;\n}\n\n\n\nExample Configuration#\n\nconst server = new AgentServer({\n  agent: myAgent,\n  port: 8888,\n  storage: {\n    type: 'sqlite',\n    path: '~/.tarko/sessions.db'\n  },\n  cors: {\n    origin: ['http://localhost:3000'],\n    credentials: true\n  },\n  auth: {\n    enabled: true,\n    provider: 'jwt',\n    secret: process.env.JWT_SECRET\n  }\n});\n\n\n\nSession Management API#\n\n\nCreate Session#\n\nPOST /api/v1/sessions/create\n\n\nResponse:\n\n{\n  \"sessionId\": \"unique-session-id\"\n}\n\n\n\nList Sessions#\n\nGET /api/v1/sessions\n\n\nResponse:\n\n{\n  \"sessions\": [\n    {\n      \"id\": \"session-id-1\",\n      \"createdAt\": 1622548800000,\n      \"updatedAt\": 1622548800000,\n      \"name\": \"Session Name\",\n      \"workspace\": \"/path/to/workspace\",\n      \"tags\": [\"tag1\", \"tag2\"]\n    }\n  ]\n}\n\n\n\nGet Session Details#\n\nGET /api/v1/sessions/details?sessionId=session-id\n\n\n\nUpdate Session#\n\nPOST /api/v1/sessions/update\n\n\nRequest:\n\n{\n  \"sessionId\": \"session-id\",\n  \"name\": \"New Session Name\",\n  \"tags\": [\"updated\", \"tags\"]\n}\n\n\n\nDelete Session#\n\nPOST /api/v1/sessions/delete\n\n\nRequest:\n\n{\n  \"sessionId\": \"session-id\"\n}\n\n\n\nQuery Execution API#\n\n\nStandard Query#\n\nPOST /api/v1/sessions/query\n\n\nText Query:\n\n{\n  \"sessionId\": \"session-id\",\n  \"query\": \"Hello, how can you help me?\"\n}\n\n\nMultimodal Query:\n\n{\n  \"sessionId\": \"session-id\",\n  \"query\": [\n    { \"type\": \"text\", \"text\": \"What's in this image?\" },\n    { \n      \"type\": \"image_url\", \n      \"image_url\": {\n        \"url\": \"data:image/jpeg;base64,...\"\n      }\n    }\n  ]\n}\n\n\n\nStreaming Query#\n\nPOST /api/v1/sessions/query/stream\n\n\nReturns Server-Sent Events (SSE) stream with real-time agent responses.\n\n\nAbort Query#\n\nPOST /api/v1/sessions/abort\n\n\nRequest:\n\n{\n  \"sessionId\": \"session-id\"\n}\n\n\n\nOne-shot API#\n\nFor simple use cases, execute queries without explicit session management:\n\n\nOne-shot Query#\n\nPOST /api/v1/oneshot/query\n\n\nRequest:\n\n{\n  \"query\": \"What's the weather like?\",\n  \"sessionName\": \"Weather Check\",\n  \"sessionTags\": [\"weather\", \"oneshot\"]\n}\n\n\n\nOne-shot Streaming#\n\nPOST /api/v1/oneshot/query/stream\n\n\n\nWebSocket API#\n\nFor real-time bidirectional communication:\n\n\n\nconst socket = io('http://localhost:8888');\n\n// Join a session\nsocket.emit('join-session', 'session-id');\n\n// Listen for agent events\nsocket.on('agent-event', (event) => {\n  console.log('Agent event:', event);\n});\n\n// Send a query\nsocket.emit('send-query', {\n  sessionId: 'session-id',\n  query: 'Hello!'\n});\n\n// Abort query\nsocket.emit('abort-query', { sessionId: 'session-id' });\n\n\n\nEvent Stream Format#\n\nTarko Server uses structured event streams following the Agent Protocol:\n\ninterface AgentEvent {\n  id: string;\n  type: string;\n  timestamp: number;\n  sessionId: string;\n  data: any;\n}\n\n\nExample Event Stream:\n\n[\n  {\n    \"id\": \"evt-1\",\n    \"type\": \"user_message\",\n    \"timestamp\": 1622548800000,\n    \"sessionId\": \"session-1\",\n    \"data\": { \"content\": \"Hello!\" }\n  },\n  {\n    \"id\": \"evt-2\",\n    \"type\": \"assistant_message_start\",\n    \"timestamp\": 1622548800100,\n    \"sessionId\": \"session-1\",\n    \"data\": {}\n  },\n  {\n    \"id\": \"evt-3\",\n    \"type\": \"assistant_message_delta\",\n    \"timestamp\": 1622548800150,\n    \"sessionId\": \"session-1\",\n    \"data\": { \"delta\": \"Hello! How\" }\n  },\n  {\n    \"id\": \"evt-4\",\n    \"type\": \"tool_call\",\n    \"timestamp\": 1622548800200,\n    \"sessionId\": \"session-1\",\n    \"data\": {\n      \"name\": \"get_weather\",\n      \"arguments\": { \"location\": \"San Francisco\" }\n    }\n  }\n]\n\n\n\nStorage Providers#\n\n\nMemory Storage (Default)#\n\nstorage: {\n  type: 'memory'\n  // Data lost on server restart\n}\n\n\n\nFile Storage#\n\nstorage: {\n  type: 'file',\n  path: '~/.tarko/sessions'\n}\n\n\n\nSQLite Storage#\n\nstorage: {\n  type: 'sqlite',\n  path: '~/.tarko/sessions.db'\n}\n\n\n\nRedis Storage#\n\nstorage: {\n  type: 'redis',\n  connectionString: 'redis://localhost:6379',\n  options: {\n    keyPrefix: 'tarko:',\n    db: 0\n  }\n}\n\n\n\nAuthentication#\n\n\nJWT Authentication#\n\nconst server = new AgentServer({\n  auth: {\n    enabled: true,\n    provider: 'jwt',\n    secret: process.env.JWT_SECRET,\n    expiresIn: '24h'\n  }\n});\n\n\n\nCustom Authentication#\n\nconst server = new AgentServer({\n  auth: {\n    enabled: true,\n    provider: 'custom',\n    authenticate: async (req) => {\n      const token = req.headers.authorization;\n      // Custom authentication logic\n      return { userId: 'user-123', permissions: ['read', 'write'] };\n    }\n  }\n});\n\n\n\nMiddleware Extensions#\n\nExtend server functionality with custom middleware:\n\n\n\nconst server = new AgentServer(config);\nconst app = server.getApp();\n\n// Add custom routes\napp.get('/custom/health', (req, res) => {\n  res.json({ status: 'custom-ok', timestamp: Date.now() });\n});\n\n// Add middleware\napp.use('/api/v1', express.json({ limit: '50mb' }));\n\n// Custom error handling\napp.use((error, req, res, next) => {\n  console.error('Server error:', error);\n  res.status(500).json({ error: 'Internal server error' });\n});\n\nawait server.start();\n\n\n\nDeployment#\n\n\nDocker Deployment#\n\nFROM node:18-alpine\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --production\n\nCOPY . .\nEXPOSE 8888\n\nCMD [\"npx\", \"tarko\", \"serve\", \"agent.ts\", \"--port\", \"8888\"]\n\n\n\nEnvironment Variables#\n\n# .env\nPORT=8888\nNODE_ENV=production\nJWT_SECRET=your-secret-key\nSTORAGE_TYPE=sqlite\nSTORAGE_PATH=/data/sessions.db\nOPENAI_API_KEY=your-api-key\n\n\n\nProduction Configuration#\n\n// production.config.ts\nexport default {\n  server: {\n    port: process.env.PORT || 8888,\n    storage: {\n      type: 'sqlite',\n      path: process.env.STORAGE_PATH || '/data/sessions.db'\n    },\n    auth: {\n      enabled: true,\n      provider: 'jwt',\n      secret: process.env.JWT_SECRET\n    },\n    cors: {\n      origin: process.env.ALLOWED_ORIGINS?.split(',') || ['https://your-domain.com'],\n      credentials: true\n    }\n  }\n};\n\n\n\nMonitoring and Logging#\n\n\nHealth Check#\n\nGET /api/v1/health\n\n\nResponse:\n\n{\n  \"status\": \"ok\",\n  \"timestamp\": 1622548800000,\n  \"uptime\": 3600,\n  \"memory\": {\n    \"used\": 123456789,\n    \"total\": 1073741824\n  }\n}\n\n\n\nCustom Logging#\n\nconst server = new AgentServer({\n  logging: {\n    level: 'info',\n    format: 'json',\n    transports: [\n      { type: 'console' },\n      { type: 'file', filename: 'tarko-server.log' }\n    ]\n  }\n});\n\n\n\nBest Practices#\n\n\n1. Session Management#\n\n * Implement session cleanup for old/inactive sessions\n * Use appropriate storage based on scale requirements\n * Consider session sharing and collaboration features\n\n\n2. Security#\n\n * Always enable authentication in production\n * Use HTTPS in production environments\n * Implement rate limiting for public APIs\n * Validate and sanitize all inputs\n\n\n3. Performance#\n\n * Use Redis for high-concurrency scenarios\n * Implement connection pooling for database storage\n * Monitor memory usage and implement cleanup\n * Use streaming for long-running queries\n\n\n4. Error Handling#\n\n * Implement comprehensive error logging\n * Provide meaningful error messages to clients\n * Handle agent timeouts gracefully\n * Implement circuit breakers for external dependencies\n\n\nNext Steps#\n\n * Agent Protocol - Understand the communication standards\n * Agent Hooks - Extend server behavior\n * Examples - See server integration examples","routePath":"/guide/deployment/server","lang":"en","toc":[{"text":"Installation","id":"installation","depth":2,"charIndex":212},{"text":"Quick Start","id":"quick-start","depth":2,"charIndex":262},{"text":"Using CLI","id":"using-cli","depth":3,"charIndex":277},{"text":"Programmatic Usage","id":"programmatic-usage","depth":3,"charIndex":356},{"text":"Core Concepts","id":"core-concepts","depth":2,"charIndex":589},{"text":"Session","id":"session","depth":3,"charIndex":606},{"text":"Query","id":"query","depth":3,"charIndex":789},{"text":"Configuration","id":"configuration","depth":2,"charIndex":936},{"text":"Server Options","id":"server-options","depth":3,"charIndex":953},{"text":"Storage Configuration","id":"storage-configuration","depth":3,"charIndex":1190},{"text":"Example Configuration","id":"example-configuration","depth":3,"charIndex":1420},{"text":"Session Management API","id":"session-management-api","depth":2,"charIndex":1752},{"text":"Create Session","id":"create-session","depth":3,"charIndex":1778},{"text":"List Sessions","id":"list-sessions","depth":3,"charIndex":1879},{"text":"Get Session Details","id":"get-session-details","depth":3,"charIndex":2166},{"text":"Update Session","id":"update-session","depth":3,"charIndex":2241},{"text":"Delete Session","id":"delete-session","depth":3,"charIndex":2395},{"text":"Query Execution API","id":"query-execution-api","depth":2,"charIndex":2488},{"text":"Standard Query","id":"standard-query","depth":3,"charIndex":2511},{"text":"Streaming Query","id":"streaming-query","depth":3,"charIndex":2890},{"text":"Abort Query","id":"abort-query","depth":3,"charIndex":3019},{"text":"One-shot API","id":"one-shot-api","depth":2,"charIndex":3108},{"text":"One-shot Query","id":"one-shot-query","depth":3,"charIndex":3200},{"text":"One-shot Streaming","id":"one-shot-streaming","depth":3,"charIndex":3376},{"text":"WebSocket API","id":"websocket-api","depth":2,"charIndex":3434},{"text":"Event Stream Format","id":"event-stream-format","depth":2,"charIndex":3880},{"text":"Storage Providers","id":"storage-providers","depth":2,"charIndex":4797},{"text":"Memory Storage (Default)","id":"memory-storage-default","depth":3,"charIndex":4818},{"text":"File Storage","id":"file-storage","depth":3,"charIndex":4911},{"text":"SQLite Storage","id":"sqlite-storage","depth":3,"charIndex":4986},{"text":"Redis Storage","id":"redis-storage","depth":3,"charIndex":5068},{"text":"Authentication","id":"authentication","depth":2,"charIndex":5215},{"text":"JWT Authentication","id":"jwt-authentication","depth":3,"charIndex":5233},{"text":"Custom Authentication","id":"custom-authentication","depth":3,"charIndex":5405},{"text":"Middleware Extensions","id":"middleware-extensions","depth":2,"charIndex":5720},{"text":"Deployment","id":"deployment","depth":2,"charIndex":6262},{"text":"Docker Deployment","id":"docker-deployment","depth":3,"charIndex":6276},{"text":"Environment Variables","id":"environment-variables","depth":3,"charIndex":6462},{"text":"Production Configuration","id":"production-configuration","depth":3,"charIndex":6632},{"text":"Monitoring and Logging","id":"monitoring-and-logging","depth":2,"charIndex":7090},{"text":"Health Check","id":"health-check","depth":3,"charIndex":7116},{"text":"Custom Logging","id":"custom-logging","depth":3,"charIndex":7301},{"text":"Best Practices","id":"best-practices","depth":2,"charIndex":7518},{"text":"1. Session Management","id":"1-session-management","depth":3,"charIndex":7536},{"text":"2. Security","id":"2-security","depth":3,"charIndex":7727},{"text":"3. Performance","id":"3-performance","depth":3,"charIndex":7908},{"text":"4. Error Handling","id":"4-error-handling","depth":3,"charIndex":8112},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":8315}],"frontmatter":{"title":"Server","description":"Build production-ready agent servers with Tarko Agent Server"},"version":""},{"title":"Architecture","content":"#\n\nTarko is designed with a clean three-layer architecture that separates concerns\nand enables flexible agent development.\n\n\nOverview#\n\ngraph TB\n    subgraph \"Engineering Layer\"\n        CLI[\"Agent CLI\"]\n        Server[\"Agent Server\"]\n        UI[\"Agent UI\"]\n    end\n    \n    subgraph \"Application Layer\"\n        AgentTARS[\"Agent TARS\"]\n        OmniAgent[\"Omni Agent\"]\n        GithubAgent[\"Github Agent\"]\n        CustomAgent[\"Custom Agent\"]\n    end\n    \n    subgraph \"Kernel Layer\"\n        ContextEng[\"Context Engineering\"]\n        ToolCall[\"Tool Call Engine\"]\n        EventStream[\"Event Stream\"]\n        AgentProtocol[\"Agent Protocol\"]\n        ModelProvider[\"Model Provider\"]\n        AgentHooks[\"Agent Hooks\"]\n    end\n    \n    CLI --> AgentTARS\n    Server --> OmniAgent\n    UI --> GithubAgent\n    \n    AgentTARS --> ContextEng\n    OmniAgent --> ToolCall\n    GithubAgent --> EventStream\n    CustomAgent --> AgentProtocol\n\n\n\n1. Engineering Layer#\n\nThe engineering layer provides production-ready solutions for deploying\nTarko-based agents.\n\n\nAgent CLI (@tarko/agent-cli)#\n\nPurpose: One-click agent development and deployment\n\nUse Cases:\n\n * Development: tarko run [agent] for local development\n * Production: One-click deployment to production environments\n\nExample:\n\n# Development\ntarko run my-agent.ts\n\n# Production deployment\ntarko deploy my-agent.ts --platform tars\n\n\n\nAgent Server (@tarko/agent-server)#\n\nPurpose: Node.js API for custom server integrations\n\nUse Cases:\n\n * Custom user authentication\n * Custom storage solutions\n * Integration with existing systems\n\nExample:\n\n\n\nconst server = new AgentServer({\n  agent: myAgent,\n  auth: customAuthProvider,\n  storage: customStorageProvider\n});\n\nserver.listen(3000);\n\n\n\nAgent UI (@tarko/agent-ui)#\n\nPurpose: Official web UI for Tarko Agent Protocol\n\nCustomization Levels:\n\n * L1: Static configuration (most scenarios)\n * L2: UI SDK-based development\n * L3: Build from scratch\n\n\n2. Application Layer#\n\nThe application layer contains Tarko-based agent implementations for specific\nuse cases.\n\n\nAgent TARS#\n\nPurpose: Open-source general-purpose multimodal agent Capabilities: Browser\nautomation, file system, command execution, search, MCP\n\n\nOmni Agent#\n\nPurpose: UI-TARS-2 specialized multimodal agent Capabilities: Same as Agent TARS\nbut optimized for Seed Agent integration\n\n\nGithub Agent#\n\nPurpose: Git workflow and coding agent Capabilities: Github workflow, code\nsearch, code generation, command execution\n\n\nCustom Agents#\n\nDevelopers can build custom agents using the Tarko kernel while maintaining\ncompatibility with the engineering layer.\n\n\n3. Kernel Layer#\n\nThe kernel layer solves core agent runtime challenges.\n\n\nContext Engineering#\n\nProblem: Building agents capable of long-running operations Solution: Advanced\ncontext management with automatic optimization\n\nFeatures:\n\n * Automatic context compression\n * Intelligent context windowing\n * State persistence across sessions\n * Memory optimization\n\n\nTool Call Engine#\n\nProblem: Different LLM providers have varying Tool Call support Solution:\nUnified interface following OpenAI Function Call protocol\n\nSupported Engines:\n\n * Native Function Call (OpenAI, Anthropic)\n * Custom parsers (Seed-1.5 VL)\n * Prompt Engineering (Kor-based)\n\n\nEvent Stream#\n\nProblem: Standard communication between agent components Solution: Unified event\nstream protocol\n\nBenefits:\n\n * Real-time agent state updates\n * Standardized debugging and monitoring\n * Easy UI integration\n\n\nAgent Protocol#\n\nProblem: Inconsistent agent interfaces Solution: Standard protocol definitions\n\nComponents:\n\n * Event Stream: Internal component communication\n * Server Protocol: HTTP/SSE/WebSocket APIs\n\n\nModel Provider#\n\nDesign: OpenAI Compatible protocol Supported Providers: Volcengine, OpenAI,\nAnthropic, Gemini\n\nBenefits:\n\n * Consistent interface across providers\n * Easy model switching for testing\n * Reduced architectural complexity\n\n\nAgent Hooks#\n\nPurpose: Extensible customization points Use Cases: Custom logging, monitoring,\nbehavior modification\n\n\nDesign Principles#\n\n\n1. Separation of Concerns#\n\nEach layer has clear responsibilities and minimal dependencies on other layers.\n\n\n2. Protocol-First Design#\n\nStandardized protocols enable interoperability and tooling ecosystem.\n\n\n3. OpenAI Compatibility#\n\nLeveraging existing standards reduces learning curve and increases\ncompatibility.\n\n\n4. Extensibility#\n\nHooks and protocols allow customization without core modifications.\n\n\nIntegration Points#\n\n\nAgent Development#\n\n\n\n// Application Layer\nconst myAgent = new Agent({\n  // Kernel Layer integration\n  contextEngineering: { /* config */ },\n  toolCallEngine: { /* config */ },\n  hooks: { /* custom hooks */ }\n});\n\n// Engineering Layer consumption\nexport default myAgent;\n\n\n\nProduction Deployment#\n\n# Engineering Layer handles deployment\ntarko run my-agent.ts --production\n\n\n\nNext Steps#\n\n * Context Engineering - Deep dive into context management\n * Tool Call Engine - Learn about tool integration\n * Agent Protocol - Understand communication standards","routePath":"/guide/get-started/architecture","lang":"en","toc":[{"text":"Overview","id":"overview","depth":2,"charIndex":124},{"text":"1. Engineering Layer","id":"1-engineering-layer","depth":2,"charIndex":921},{"text":"Agent CLI (`@tarko/agent-cli`)","id":"agent-cli-tarkoagent-cli","depth":3,"charIndex":-1},{"text":"Agent Server (`@tarko/agent-server`)","id":"agent-server-tarkoagent-server","depth":3,"charIndex":-1},{"text":"Agent UI (`@tarko/agent-ui`)","id":"agent-ui-tarkoagent-ui","depth":3,"charIndex":-1},{"text":"2. Application Layer","id":"2-application-layer","depth":2,"charIndex":1928},{"text":"Agent TARS","id":"agent-tars","depth":3,"charIndex":2042},{"text":"Omni Agent","id":"omni-agent","depth":3,"charIndex":2189},{"text":"Github Agent","id":"github-agent","depth":3,"charIndex":2326},{"text":"Custom Agents","id":"custom-agents","depth":3,"charIndex":2461},{"text":"3. Kernel Layer","id":"3-kernel-layer","depth":2,"charIndex":2597},{"text":"Context Engineering","id":"context-engineering","depth":3,"charIndex":2672},{"text":"Tool Call Engine","id":"tool-call-engine","depth":3,"charIndex":2960},{"text":"Event Stream","id":"event-stream","depth":3,"charIndex":3244},{"text":"Agent Protocol","id":"agent-protocol","depth":3,"charIndex":3467},{"text":"Model Provider","id":"model-provider","depth":3,"charIndex":3673},{"text":"Agent Hooks","id":"agent-hooks","depth":3,"charIndex":3911},{"text":"Design Principles","id":"design-principles","depth":2,"charIndex":4029},{"text":"1. Separation of Concerns","id":"1-separation-of-concerns","depth":3,"charIndex":4050},{"text":"2. Protocol-First Design","id":"2-protocol-first-design","depth":3,"charIndex":4160},{"text":"3. OpenAI Compatibility","id":"3-openai-compatibility","depth":3,"charIndex":4259},{"text":"4. Extensibility","id":"4-extensibility","depth":3,"charIndex":4369},{"text":"Integration Points","id":"integration-points","depth":2,"charIndex":4458},{"text":"Agent Development","id":"agent-development","depth":3,"charIndex":4480},{"text":"Production Deployment","id":"production-deployment","depth":3,"charIndex":4754},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":4855}],"frontmatter":{"title":"Architecture","description":"Understanding Tarko's three-layer architecture"},"version":""},{"title":"Introduction","content":"#\n\nTarko (Tool-augmented Agent Runtime Kernel, Open-source), pronounced /ËˆtÉ‘ËrkoÊŠ/,\nis a tool-call and event-stream driven Agent runtime framework with powerful\nContext Engineering capabilities.\n\n\nWhat is Tarko?#\n\nTarko provides:\n\n * Context Engineering: Build agents capable of long-running operations\n * Tool Call Engine: Support for multiple LLM providers with custom parsers\n * Event Stream Processing: Native streaming and Agent Protocol support\n * Agent Hooks: Powerful extension capabilities\n * Agent Protocol: Standard format definitions for agent lifecycle\n\n\nKey Features#\n\n\nðŸ”§ Tool Call Engine#\n\nSupport for multiple Tool Call engines including native Function Call, custom\nparsers, and models that don't support native Function Tool.\n\n\nðŸŒŠ Event Stream#\n\nBuilt-in event stream processing with native streaming support and standardized\nAgent Protocol.\n\n\nðŸ§  Context Engineering#\n\nAdvanced context management for long-running agent operations with automatic\ncontext optimization.\n\n\nðŸ”Œ Agent Hooks#\n\nExtensible hook system for customizing agent behavior at every stage of\nexecution.\n\n\nArchitecture Overview#\n\nTarko is built with a three-layer architecture:\n\n 1. Engineering Layer: CLI, Server, and UI components\n 2. Application Layer: Tarko-based Agent implementations\n 3. Kernel Layer: Core runtime with Context Engineering and Agent Protocol\n\n\nWho Uses Tarko?#\n\nTarko powers several production systems:\n\n * UI-TARS-2: Advanced UI automation\n * UI-TARS-desktop: Desktop automation\n * Agent TARS: General-purpose multimodal agent\n\n\nDocumentation Overview#\n\n\nGetting Started#\n\n * Quick Start - Create your first Tarko agent in minutes\n * Architecture - Understand Tarko's design principles\n * SDK Reference - Complete API reference and examples\n\n\nCore Concepts#\n\n * Configuration - Configure agents, models, and runtime settings\n * Model Providers - OpenAI, Anthropic, Volcengine, and custom providers\n * Tools - Create and register custom tools for your agents\n * Tool Call Engine - Native, prompt-engineering, and structured outputs\n * Event Stream - Real-time agent execution monitoring\n * Troubleshooting - Common issues and solutions\n\n\nAdvanced Features#\n\n * Agent Hooks - Customize agent behavior with lifecycle hooks\n * Agent Protocol - Standard communication protocol\n * Context Engineering - Long-running agent context management\n * Agent Snapshot - Save and replay agent execution states\n * Agent Snapshot - Save and replay agent execution states\n\n\nUI Integration#\n\n * UI Integration - Build web interfaces for your agents\n\n\nDeployment#\n\n * CLI Deployment - Command-line tools and scripts\n * Server Deployment - Production server setup\n\n\nAPI Reference#\n\n * Agent API - Complete Agent class reference\n * Hooks API - Agent lifecycle hooks\n * Tool Call Engine API - Tool execution engines\n * Context Engineering API - Context management\n * Agent Server API - Server endpoints and protocols\n\n\nExamples#\n\n * Getting Started - Basic usage examples\n * Custom Tools - Building domain-specific tools\n * Custom Hooks - Extending agent behavior\n * Server Integration - Web server integration\n * Protocol Integration - Custom protocol implementation\n\n\nQuick Navigation#\n\nNew to Tarko? Start with Quick Start\n\nBuilding agents? Check out SDK Reference and Tools\n\nNeed customization? Explore Agent Hooks and Context Engineering\n\nDeploying to production? See Server Deployment and Agent Snapshot\n\nBuilding UI? Start with UI Integration","routePath":"/guide/get-started/introduction","lang":"en","toc":[{"text":"What is Tarko?","id":"what-is-tarko","depth":2,"charIndex":196},{"text":"Key Features","id":"key-features","depth":2,"charIndex":567},{"text":"ðŸ”§ Tool Call Engine","id":"-tool-call-engine","depth":3,"charIndex":583},{"text":"ðŸŒŠ Event Stream","id":"-event-stream","depth":3,"charIndex":746},{"text":"ðŸ§  Context Engineering","id":"-context-engineering","depth":3,"charIndex":862},{"text":"ðŸ”Œ Agent Hooks","id":"-agent-hooks","depth":3,"charIndex":988},{"text":"Architecture Overview","id":"architecture-overview","depth":2,"charIndex":1090},{"text":"Who Uses Tarko?","id":"who-uses-tarko","depth":2,"charIndex":1351},{"text":"Documentation Overview","id":"documentation-overview","depth":2,"charIndex":1537},{"text":"Getting Started","id":"getting-started","depth":3,"charIndex":1563},{"text":"Core Concepts","id":"core-concepts","depth":3,"charIndex":1751},{"text":"Advanced Features","id":"advanced-features","depth":3,"charIndex":2145},{"text":"UI Integration","id":"ui-integration","depth":3,"charIndex":2463},{"text":"Deployment","id":"deployment","depth":3,"charIndex":2539},{"text":"API Reference","id":"api-reference","depth":3,"charIndex":2652},{"text":"Examples","id":"examples","depth":3,"charIndex":2903},{"text":"Quick Navigation","id":"quick-navigation","depth":2,"charIndex":3154}],"frontmatter":{"title":"Introduction","description":"Learn about Tarko, a tool-augmented agent runtime kernel"},"version":""},{"title":"Quick Start","content":"#\n\nGet up and running with Tarko in just a few minutes.\n\n\nPrerequisites#\n\n * Node.js 18+\n * npm or pnpm\n\n\nInstallation#\n\n\nCreate a New Agent (WIP)#\n\nðŸš§ Work in Progress: The fastest way to get started will be using the Tarko CLI:\n\nnpm create tarko  # Coming soon\n\n\n\nInstall Tarko Packages#\n\nFor now, install the core packages manually:\n\nnpm install @tarko/agent\n\n\n\nBasic Usage#\n\n\n1. Define Your Agent#\n\nCreate an agent.ts file based on the real examples:\n\n// From multimodal/tarko/agent/examples/tool-calls/basic.ts\n\n\nconst locationTool = new Tool({\n  id: 'getCurrentLocation',\n  description: \"Get user's current location\",\n  parameters: z.object({}),\n  function: async () => {\n    return { location: 'Boston' };\n  },\n});\n\nconst weatherTool = new Tool({\n  id: 'getWeather',\n  description: 'Get weather information for a specified location',\n  parameters: z.object({\n    location: z.string().describe('Location name, such as city name'),\n  }),\n  function: async (input) => {\n    const { location } = input;\n    return {\n      location,\n      temperature: '70Â°F (21Â°C)',\n      condition: 'Sunny',\n      precipitation: '10%',\n      humidity: '45%',\n      wind: '5 mph',\n    };\n  },\n});\n\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  tools: [locationTool, weatherTool],\n  logLevel: LogLevel.DEBUG,\n});\n\nexport default agent;\n\n\n\n2. Run Your Agent#\n\nRun your agent directly:\n\n// Run the agent\nconst response = await agent.run(\"How's the weather today?\");\nconsole.log(response);\n\n\n\n3. Streaming Example#\n\nFor streaming responses:\n\n// From multimodal/tarko/agent/examples/streaming/tool-calls.ts\nconst response = await agent.run({\n  input: \"How's the weather today?\",\n  stream: true,\n});\n\nfor await (const chunk of response) {\n  console.log(chunk);\n}\n\n\n\nEnvironment Variables#\n\nCreate a .env file with your API keys:\n\n# .env file\nARK_API_KEY=your-volcengine-api-key\nOPENAI_API_KEY=your-openai-api-key\nANTHROPIC_API_KEY=your-anthropic-api-key\n\n\n\nReal Examples#\n\nExplore working examples in the repository:\n\n * multimodal/tarko/agent/examples/tool-calls/basic.ts - Basic tool calls\n * multimodal/tarko/agent/examples/streaming/tool-calls.ts - Streaming with\n   tools\n * multimodal/tarko/agent/examples/model-providers/ - Different model providers\n\n\nNext Steps#\n\n * SDK Reference - Complete API reference\n * Architecture - Learn about Tarko's design\n * Tools - Create custom tools\n * Examples - Explore real-world examples\n\n\nTesting Examples#\n\nTo test the examples work:\n\n# Clone the repository\ngit clone https://github.com/bytedance/UI-TARS-desktop.git\ncd UI-TARS-desktop/multimodal/tarko/agent\n\n# Install dependencies\nnpm install\n\n# Run basic tool call example\nnpx tsx examples/tool-calls/basic.ts\n\n# Run streaming example\nnpx tsx examples/streaming/tool-calls.ts\n","routePath":"/guide/get-started/quick-start","lang":"en","toc":[{"text":"Prerequisites","id":"prerequisites","depth":2,"charIndex":57},{"text":"Installation","id":"installation","depth":2,"charIndex":105},{"text":"Create a New Agent (WIP)","id":"create-a-new-agent-wip","depth":3,"charIndex":121},{"text":"Install Tarko Packages","id":"install-tarko-packages","depth":3,"charIndex":265},{"text":"Basic Usage","id":"basic-usage","depth":2,"charIndex":364},{"text":"1. Define Your Agent","id":"1-define-your-agent","depth":3,"charIndex":379},{"text":"2. Run Your Agent","id":"2-run-your-agent","depth":3,"charIndex":1421},{"text":"3. Streaming Example","id":"3-streaming-example","depth":3,"charIndex":1572},{"text":"Environment Variables","id":"environment-variables","depth":2,"charIndex":1843},{"text":"Real Examples","id":"real-examples","depth":2,"charIndex":2034},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":2336},{"text":"Testing Examples","id":"testing-examples","depth":2,"charIndex":2511}],"frontmatter":{"title":"Quick Start","description":"Get started with Tarko in minutes"},"version":""},{"title":"SDK Reference","content":"#\n\nComprehensive guide to using the @tarko/agent SDK for building production-ready\nagents.\n\n\nInstallation#\n\nnpm install @tarko/agent\n# or\npnpm add @tarko/agent\n\n\n\nCore Imports#\n\n// Main Agent class\n\n\n// Tool definition\n\n\n// Type definitions\nimport type {\n  AgentOptions,\n  AgentModel\n} from '@tarko/agent';\n\n// Utilities\n\n\n\n\nAgent Class#\n\n\nConstructor#\n\nconst agent = new Agent(options: AgentOptions)\n\n\nAgentOptions Interface#\n\nBased on the actual interface from\nmultimodal/tarko/agent-interface/src/agent-options.ts:\n\ninterface AgentOptions {\n  // Core Configuration\n  id?: string;                    // Unique agent ID\n  name?: string;                  // Agent identifier\n  instructions?: string;          // System prompt\n  \n  // Model Configuration\n  model?: AgentModel;             // Model configuration\n  maxTokens?: number;            // Token limit per request (default: 1000)\n  temperature?: number;          // LLM temperature (default: 0.7)\n  top_p?: number;               // Top-p sampling\n  \n  // Tools\n  tools?: Tool[];                 // Available tools\n  toolCallEngine?: ToolCallEngineType; // Tool call engine type\n  \n  // Execution Control\n  maxIterations?: number;         // Max reasoning loops (default: 1000)\n  \n  // Context Management\n  context?: {\n    maxImagesCount?: number;      // Max images in context\n  };\n  \n  // Advanced Features\n  thinking?: LLMReasoningOptions; // Reasoning options\n  enableStreamingToolCallEvents?: boolean;\n  initialEvents?: AgentEventStream.Event[]; // Restore events\n  \n  // Workspace\n  workspace?: string;             // Workspace directory\n  \n  // Logging\n  logLevel?: LogLevel;           // Log level\n  metric?: {                     // Metric collection\n    enable?: boolean;\n  };\n}\n\n\n\nCore Methods#\n\nrun() - Execute Agent#\n\nBasic Usage:\n\n// Simple text input - from examples/tool-calls/basic.ts\nconst response = await agent.run(\"How's the weather today?\");\nconsole.log(response);\n\n\nWith Options:\n\n// Using AgentRunNonStreamingOptions\nconst runOptions = {\n  input: \"How's the weather today?\",\n};\nconst response = await agent.run(runOptions);\n\n\nStreaming:\n\n// From examples/streaming/tool-calls.ts\nconst response = await agent.run({\n  input: \"How's the weather today?\",\n  stream: true,\n});\n\nfor await (const chunk of response) {\n  console.log(chunk);\n}\n\n\nTool Definition#\n\nTools are defined using the Tool class and passed to the Agent constructor:\n\n// From examples/tool-calls/basic.ts\nconst weatherTool = new Tool({\n  id: 'getWeather',\n  description: 'Get weather information for a specified location',\n  parameters: z.object({\n    location: z.string().describe('Location name, such as city name'),\n  }),\n  function: async (input) => {\n    const { location } = input;\n    return {\n      location,\n      temperature: '70Â°F (21Â°C)',\n      condition: 'Sunny',\n      precipitation: '10%',\n      humidity: '45%',\n      wind: '5 mph',\n    };\n  },\n});\n\n// Tools are passed to Agent constructor\nconst agent = new Agent({\n  tools: [weatherTool],\n  // ... other options\n});\n\n\n\nTool Definition#\n\n\nTool Class#\n\nBased on the actual Tool class from\nmultimodal/tarko/agent-interface/src/tool.ts:\n\nconst tool = new Tool({\n  id: string;                     // Unique tool identifier\n  description: string;            // What the tool does\n  parameters: ZodSchema | JSONSchema7; // Zod schema or JSON schema\n  function: (input: TParams) => Promise<any> | any; // Implementation function\n});\n\n\n\nReal Examples from Source Code#\n\nLocation Tool:\n\n// From examples/tool-calls/basic.ts\nconst locationTool = new Tool({\n  id: 'getCurrentLocation',\n  description: \"Get user's current location\",\n  parameters: z.object({}),\n  function: async () => {\n    return { location: 'Boston' };\n  },\n});\n\n\nWeather Tool:\n\n// From examples/tool-calls/basic.ts\nconst weatherTool = new Tool({\n  id: 'getWeather',\n  description: 'Get weather information for a specified location',\n  parameters: z.object({\n    location: z.string().describe('Location name, such as city name'),\n  }),\n  function: async (input) => {\n    const { location } = input;\n    return {\n      location,\n      temperature: '70Â°F (21Â°C)',\n      condition: 'Sunny',\n      precipitation: '10%',\n      humidity: '45%',\n      wind: '5 mph',\n    };\n  },\n});\n\n\n\nEvent Stream#\n\n\nEvent Types#\n\nBased on multimodal/tarko/agent-interface/src/agent-event-stream.ts, the Agent\nuses an internal event stream system. Events are emitted during agent execution\nand can be accessed through streaming responses.\n\n\nStreaming Events#\n\n// From examples/streaming/tool-calls.ts\nconst response = await agent.run({\n  input: \"How's the weather today?\",\n  stream: true,\n});\n\n// Iterate through streaming events\nfor await (const chunk of response) {\n  console.log('Event:', chunk);\n  // Events include: user_message, assistant_message_chunk, tool_call, tool_result, etc.\n}\n\n\n\nAdvanced Configuration#\n\n\nTool Call Engines#\n\n// From actual source code - ToolCallEngineType options\nconst agent = new Agent({\n  toolCallEngine: 'native',              // Use model's native tool calling\n  // or\n  toolCallEngine: 'prompt_engineering',  // Use prompt-based tool calling\n  // or\n  toolCallEngine: 'structured_outputs'   // Use structured output parsing\n});\n\n\n\nContext Management#\n\nconst agent = new Agent({\n  context: {\n    maxImagesCount: 10,           // Max images to keep in context\n  },\n  maxIterations: 20,             // Allow more reasoning loops\n  maxTokens: 4000,              // Limit response length\n  temperature: 0.7,             // Control randomness\n});\n\n\n\nModel Configuration#\n\n// Different model providers\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  // or\n  model: {\n    provider: 'openai',\n    id: 'gpt-4o',\n    apiKey: process.env.OPENAI_API_KEY,\n  },\n});\n\n\n\nError Handling#\n\ntry {\n  const response = await agent.run('Complex task');\n  console.log(response);\n} catch (error) {\n  console.error('Agent execution error:', error);\n}\n\n\n\nReal Examples#\n\nBased on the actual examples in multimodal/tarko/agent/examples/:\n\n\nBasic Tool Calls#\n\n// From examples/tool-calls/basic.ts\n\n\nconst locationTool = new Tool({\n  id: 'getCurrentLocation',\n  description: \"Get user's current location\",\n  parameters: z.object({}),\n  function: async () => {\n    return { location: 'Boston' };\n  },\n});\n\nconst weatherTool = new Tool({\n  id: 'getWeather',\n  description: 'Get weather information for a specified location',\n  parameters: z.object({\n    location: z.string().describe('Location name, such as city name'),\n  }),\n  function: async (input) => {\n    const { location } = input;\n    return {\n      location,\n      temperature: '70Â°F (21Â°C)',\n      condition: 'Sunny',\n      precipitation: '10%',\n      humidity: '45%',\n      wind: '5 mph',\n    };\n  },\n});\n\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  tools: [locationTool, weatherTool],\n  logLevel: LogLevel.DEBUG,\n});\n\nconst response = await agent.run(\"How's the weather today?\");\nconsole.log(response);\n\n\n\nStreaming with Tool Calls#\n\n// From examples/streaming/tool-calls.ts\nconst agent = new Agent({\n  model: {\n    provider: 'volcengine',\n    id: 'ep-20250510145437-5sxhs',\n    apiKey: process.env.ARK_API_KEY,\n  },\n  tools: [locationTool, weatherTool],\n  toolCallEngine: 'native',\n  enableStreamingToolCallEvents: true,\n});\n\nconst response = await agent.run({\n  input: \"How's the weather today?\",\n  stream: true,\n});\n\nfor await (const chunk of response) {\n  console.log(chunk);\n}\n\n\n\nNext Steps#\n\n * Architecture â†’\n * Configuration â†’\n * Tools â†’\n * Agent Hooks â†’","routePath":"/guide/get-started/sdk","lang":"en","toc":[{"text":"Installation","id":"installation","depth":2,"charIndex":92},{"text":"Core Imports","id":"core-imports","depth":2,"charIndex":162},{"text":"Agent Class","id":"agent-class","depth":2,"charIndex":324},{"text":"Constructor","id":"constructor","depth":3,"charIndex":339},{"text":"AgentOptions Interface","id":"agentoptions-interface","depth":4,"charIndex":402},{"text":"Core Methods","id":"core-methods","depth":3,"charIndex":1747},{"text":"`run()` - Execute Agent","id":"run---execute-agent","depth":4,"charIndex":-1},{"text":"Tool Definition","id":"tool-definition","depth":4,"charIndex":2315},{"text":"Tool Definition","id":"tool-definition-1","depth":2,"charIndex":3029},{"text":"Tool Class","id":"tool-class","depth":3,"charIndex":3048},{"text":"Real Examples from Source Code","id":"real-examples-from-source-code","depth":3,"charIndex":3438},{"text":"Event Stream","id":"event-stream","depth":2,"charIndex":4245},{"text":"Event Types","id":"event-types","depth":3,"charIndex":4261},{"text":"Streaming Events","id":"streaming-events","depth":3,"charIndex":4485},{"text":"Advanced Configuration","id":"advanced-configuration","depth":2,"charIndex":4838},{"text":"Tool Call Engines","id":"tool-call-engines","depth":3,"charIndex":4864},{"text":"Context Management","id":"context-management","depth":3,"charIndex":5213},{"text":"Model Configuration","id":"model-configuration","depth":3,"charIndex":5526},{"text":"Error Handling","id":"error-handling","depth":2,"charIndex":5832},{"text":"Real Examples","id":"real-examples","depth":2,"charIndex":6005},{"text":"Basic Tool Calls","id":"basic-tool-calls","depth":3,"charIndex":6089},{"text":"Streaming with Tool Calls","id":"streaming-with-tool-calls","depth":3,"charIndex":7114},{"text":"Next Steps","id":"next-steps","depth":2,"charIndex":7593}],"frontmatter":{"title":"SDK Reference","description":"Complete SDK reference for Tarko agent development"},"version":""}]