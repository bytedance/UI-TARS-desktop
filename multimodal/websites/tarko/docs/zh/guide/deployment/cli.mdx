---
title: CLI 部署
description: 使用 CLI 部署 Tarko Agent
---

# CLI 部署

**Tarko Agent CLI** 提供了一个灵活的框架，用于在各种环境中部署和运行基于 Tarko 的 Agent。它支持从交互式开发到生产服务器的多种部署模式。

## 安装

全局安装 Tarko CLI：

```bash
npm install -g @tarko/agent-cli
```

或使用 npx：

```bash
npx @tarko/agent-cli run my-agent
```

## 核心命令

### `tarko` / `tarko run`

启动**交互式 Web UI** 进行实时对话和文件浏览：

```bash
# 启动交互式 Web UI（默认）
tarko

# 运行特定 Agent
tarko run ./my-agent.js

# 运行内置 Agent
tarko run agent-tars  # Agent TARS
tarko run omni-tars   # Omni-TARS
tarko run mcp-agent   # MCP Agent

# 使用自定义端口并自动打开浏览器
tarko run --port 8888 --open
```

### `tarko serve`

启动**无头 API 服务器**进行系统集成：

```bash
# 启动无头服务器
tarko serve

# 使用特定 Agent 启动服务器
tarko serve ./my-agent

# 使用自定义配置启动服务器
tarko serve --config ./custom-config.json --port 8888
# API 可在以下地址访问：http://localhost:8888/api/v1/
```

### `tarko run --headless`

**静默模式**执行，输出到 stdout，非常适合脚本使用：

```bash
# 直接输入，文本输出（默认）
tarko run --headless --input "分析当前目录结构"

# 管道输入
echo "总结这段代码" | tarko run --headless

# JSON 输出用于程序化使用
tarko run --headless --input "分析文件" --format json

# 包含调试日志
tarko run --headless --input "分析文件" --include-logs

# 禁用缓存进行全新执行
tarko run --headless --input "分析文件" --use-cache false
```

### `tarko request`

直接**LLM 请求**用于调试和测试：

```bash
# 基本请求
tarko request --provider openai --model gpt-4 --body '{"messages":[{"role":"user","content":"你好"}]}'

# 使用自定义 API 密钥和基础 URL
tarko request --provider openai --model gpt-4 --apiKey sk-xxx --baseURL https://api.openai.com/v1 --body request.json

# 流式模式
tarko request --provider openai --model gpt-4 --body request.json --stream

# 推理模式（支持的模型）
tarko request --provider openai --model o1-preview --body request.json --thinking

# 语义输出格式
tarko request --provider openai --model gpt-4 --body request.json --format semantic
```

### `tarko workspace`

**工作区管理**实用程序：

```bash
tarko workspace --init     # 初始化新工作区
tarko workspace --open     # 在 VSCode 中打开工作区
tarko workspace --enable   # 启用全局工作区
tarko workspace --disable  # 禁用全局工作区
tarko workspace --status   # 显示工作区状态
```

## 内置 Agent

Tarko CLI 包含几个可立即使用的内置 Agent：

- **`agent-tars`** - Agent TARS：高级任务自动化和推理系统
- **`omni-tars`** - Omni-TARS：具有综合能力的多模态 Agent
- **`mcp-agent`** - MCP Agent：用于工具集成的模型上下文协议 Agent

```bash
# 在任何模式下使用内置 Agent
tarko run agent-tars
tarko serve omni-tars --port 8888
tarko run mcp-agent --headless --input "列出可用工具"
```

## 配置

### 配置文件

支持多种格式，自动发现 `tarko.config.{ts,yaml,json}`：

```typescript
// tarko.config.ts
import { AgentAppConfig } from '@tarko/interface';

const config: AgentAppConfig = {
  model: {
    provider: 'openai',
    id: 'gpt-4',
    apiKey: process.env.OPENAI_API_KEY,
  },
  workspace: './workspace',
  server: { port: 8888 },
};

export default config;
```

```yaml
# tarko.config.yaml
model:
  provider: openai
  id: gpt-4
  apiKey: ${OPENAI_API_KEY}
workspace: ./workspace
server:
  port: 8888
```

```json
{
  "model": {
    "provider": "openai",
    "id": "gpt-4",
    "apiKey": "${OPENAI_API_KEY}"
  },
  "workspace": "./workspace",
  "server": {
    "port": 8888
  }
}
```

### CLI 选项

```bash
# 模型配置
tarko --model.provider openai --model.id gpt-4 --model.apiKey sk-xxx

# 服务器设置
tarko serve --port 3000

# 工作区路径
tarko --workspace ./my-workspace

# 调试模式
tarko --debug
```

### 环境变量

```bash
# 模型配置
export OPENAI_API_KEY=your-api-key
export ANTHROPIC_API_KEY=your-api-key

# 服务器配置
export TARKO_PORT=3000
export TARKO_HOST=0.0.0.0

# 调试设置
export DEBUG=tarko:*
```

### 配置优先级

1. **CLI 参数**（最高）
2. **工作区配置**
3. **用户配置文件**（`--config`）
4. **远程配置 URL**
5. **默认配置**（最低）

## 部署模式

### 交互式开发

用于开发和测试，带 Web UI：

```bash
# 启动带 UI（默认行为）
tarko run

# 使用特定 Agent 和端口
tarko run ./my-agent --port 8888 --open
```

### 无头服务器

用于生产 API 部署：

```bash
# 启动 API 服务器
tarko serve --port 3000

# 使用特定配置
tarko serve --config production.config.ts --port 3000
```

### 脚本模式

用于自动化和 CI/CD 流水线：

```bash
# 一次性执行
tarko run --headless --input "分析这个项目" --format json

# 管道处理
cat input.txt | tarko run --headless --format text > output.txt
```

## 生产部署

### Docker

创建 `Dockerfile`：

```dockerfile
FROM node:18-alpine

WORKDIR /app

# 复制包文件
COPY package*.json ./
RUN npm ci --only=production

# 复制 Agent 代码
COPY . .

# 安装 Tarko CLI
RUN npm install -g @tarko/agent-cli

EXPOSE 3000

# 生产部署使用 serve
CMD ["tarko", "serve", "--port", "3000"]
```

构建和运行：

```bash
docker build -t my-agent .
docker run -p 3000:3000 -e OPENAI_API_KEY=your-key my-agent
```

### Docker Compose

```yaml
version: '3.8'

services:
  agent:
    build: .
    ports:
      - "3000:3000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    volumes:
      - ./workspace:/app/workspace
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

volumes:
  redis_data:
```

### 进程管理器 (PM2)

```javascript
// ecosystem.config.js
module.exports = {
  apps: [{
    name: 'tarko-agent',
    script: 'tarko',
    args: 'serve --port 3000',
    instances: 1,
    autorestart: true,
    watch: false,
    max_memory_restart: '1G',
    env: {
      NODE_ENV: 'production',
      OPENAI_API_KEY: process.env.OPENAI_API_KEY
    },
    error_file: './logs/err.log',
    out_file: './logs/out.log',
    log_file: './logs/combined.log'
  }]
};
```

部署：

```bash
npm install -g pm2
pm2 start ecosystem.config.js
pm2 save
pm2 startup
```

### Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tarko-agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: tarko-agent
  template:
    metadata:
      labels:
        app: tarko-agent
    spec:
      containers:
      - name: tarko-agent
        image: my-agent:latest
        ports:
        - containerPort: 3000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-keys
              key: openai
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /api/v1/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: tarko-agent-service
spec:
  selector:
    app: tarko-agent
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: LoadBalancer
```

## 高级功能

### Tool 和 MCP Server 过滤

通过配置过滤可用的工具和 MCP 服务器：

```typescript
// 在配置中
const config = {
  tool: {
    include: ['file_*', 'web_*'],
    exclude: ['dangerous_*'],
  },
  mcpServer: {
    include: ['filesystem', 'browser'],
    exclude: ['experimental_*'],
  },
};
```

```bash
# 通过 CLI
tarko --tool.include "file_*,web_*" --tool.exclude "dangerous_*"
tarko --mcpServer.include "filesystem" --mcpServer.exclude "experimental_*"
```

### 事件系统

基于事件驱动架构监控 Agent 执行：

```typescript
const eventStream = agent.getEventStream();

// 订阅所有事件
eventStream.subscribe((event) => {
  console.log('事件:', event.type, event);
});

// 订阅特定事件类型
eventStream.subscribeToTypes(['tool_call', 'tool_result'], (event) => {
  console.log('工具事件:', event);
});
```

### 控制台拦截

在执行期间捕获和处理控制台输出：

```typescript
import { ConsoleInterceptor } from '@tarko/agent-cli';

const { result, logs } = await ConsoleInterceptor.run(
  async () => {
    return await agent.run('input');
  },
  {
    silent: true,    // 抑制输出
    capture: true,   // 捕获日志
  },
);
```

## 监控和日志

### 健康检查

```bash
# 检查服务器状态
curl http://localhost:3000/api/v1/health

# 检查详细状态
curl http://localhost:3000/api/v1/status
```

### 日志配置

```typescript
// 在配置中
const config = {
  logging: {
    level: 'info', // debug, info, warn, error
    format: 'json', // json, text
    output: {
      console: true,
      file: {
        enabled: true,
        path: './logs/agent.log',
        maxSize: '10m',
        maxFiles: 5
      }
    }
  }
};
```

### 指标收集

```typescript
// 启用指标
const config = {
  metrics: {
    enabled: true,
    endpoint: '/metrics',
    collectors: {
      requests: true,
      responses: true,
      toolCalls: true,
      errors: true
    }
  }
};
```

## 负载均衡

### Nginx 配置

```nginx
upstream tarko_agents {
    server localhost:3000;
    server localhost:3001;
    server localhost:3002;
}

server {
    listen 80;
    server_name my-agent.example.com;
    
    location / {
        proxy_pass http://tarko_agents;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        proxy_read_timeout 86400;
    }
}
```

## 故障排除

### 常见问题

**端口已被使用：**
```bash
# 查找使用端口的进程
lsof -i :3000

# 终止进程
kill -9 <PID>

# 或使用不同端口
tarko serve --port 8080
```

**权限错误：**
```bash
# 使用非特权端口
tarko serve --port 8080

# 或调整文件权限
chmod +x ./my-agent.js
```

**内存问题：**
```bash
# 增加 Node.js 内存限制
NODE_OPTIONS="--max-old-space-size=4096" tarko serve
```

**找不到 Agent：**
```bash
# 验证 Agent 路径
ls -la ./my-agent.js

# 使用绝对路径
tarko run /full/path/to/my-agent.js

# 检查内置 Agent
tarko run agent-tars
```

### 调试模式

```bash
# 启用调试日志
DEBUG=tarko:* tarko serve --debug

# 启用 Node.js 检查器
tarko serve --inspect

# 详细输出
tarko serve --debug --verbose

# 检查配置
tarko --debug --dry-run
```

### 性能优化

```bash
# 生产环境使用集群
NODE_ENV=production tarko serve --port 3000

# 启用缓存
tarko serve --cache-enabled

# 优化内存使用
NODE_OPTIONS="--max-old-space-size=2048 --gc-interval=100" tarko serve
```

## 下一步

- [Agent Server API](/guide/deployment/server) - 了解服务器架构
- [Agent 配置](/guide/basic/configuration) - 学习高级配置
- [Tool 集成](/guide/basic/tool-call-engine) - 为你的 Agent 添加自定义工具
- [示例](/examples/deployment) - 查看部署示例
