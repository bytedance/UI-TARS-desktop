---
title: Model Provider
description: Connect to different LLM providers with Tarko
---

# Model Provider

Tarko follows the **OpenAI Compatible** protocol to connect to any LLM provider, including Volcengine, OpenAI, Anthropic, Gemini, and more.

## Configuration

Configure your model provider in the Agent configuration:

```typescript
import { Agent } from '@tarko/agent';

const agent = new Agent({
  model: {
    provider: 'openai',
    id: 'gpt-4o',
    apiKey: process.env.OPENAI_API_KEY,
  }
});
```

## Supported Providers

### OpenAI

```typescript
{
  provider: 'openai',
  id: 'gpt-4o',
  apiKey: 'your-api-key',
}
```

### Anthropic

```typescript
{
  provider: 'anthropic',
  id: 'claude-3-5-sonnet-20241022',
  apiKey: 'your-api-key',
}
```

### Volcengine

```typescript
{
  provider: 'volcengine',
  id: 'doubao-seed-1-6-vision-250815',
  apiKey: 'your-api-key',
}
```

## Custom Provider

You can also use any OpenAI-compatible endpoint:

```typescript
{
  provider: 'openai',  // Use openai provider for custom endpoints
  baseURL: 'https://your-endpoint.com/v1',
  id: 'your-model-id',
  apiKey: 'your-api-key',
}
```
